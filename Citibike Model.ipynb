{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import cross_validation\n",
    "\n",
    "ROW_LIMIT = 10000\n",
    "COLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\n",
    "TARGET_STATION_ID = \"529\"\n",
    "\n",
    "\n",
    "def analyze(row_limit, threshold_out=1, tree_count=10, period_minutes=5, k_folds=5):\n",
    "    \"\"\"\n",
    "    We can tune the following parameters:\n",
    "    - number of rows we analyze\n",
    "    - number of folds in our standard k-fold cross-validation\n",
    "    - number of bicycles taken out in the period to be considered in the positive class\n",
    "    - number of trees in our random forest\n",
    "    - number of minutes in our period\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    df = pd.read_csv(\"data/july_thru_sept.csv\", usecols=COLUMNS)\n",
    "    # Convert to timestamps \n",
    "    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\n",
    "    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\n",
    "\n",
    "    # Convert int64index to datetime index\n",
    "    # Group using timegrouper and create new column for start period and stop period\n",
    "    df = df.set_index(pd.DatetimeIndex(df['starttime']))\n",
    "    start_time_group_by = df.groupby(pd.TimeGrouper('5Min'),as_index=False).apply(lambda x: x['starttime'])\n",
    "    df['start_period'] = start_time_group_by.index.get_level_values(0)\n",
    "\n",
    "    df = df.set_index(pd.DatetimeIndex(df['stoptime']))\n",
    "    stop_time_group_by = df.groupby(pd.TimeGrouper('{}Min'.format(period_minutes)),as_index=False).apply(lambda x: x['stoptime'])\n",
    "    df['stop_period'] = stop_time_group_by.index.get_level_values(0)\n",
    "\n",
    "    # Create two sub dataframes, grouping on and aggregating start data and then stop data\n",
    "    grouped_by = df.groupby(['start_period', 'start station id'])\n",
    "    df_start = pd.DataFrame({'started_count' : grouped_by.size()}).reset_index()\n",
    "    df_start.columns = [\"period\", \"station_id\", \"start_count\"]\n",
    "\n",
    "    grouped_by = df.groupby(['stop_period', 'end station id'])\n",
    "    df_stop = pd.DataFrame({'stopped_count' : grouped_by.size()}).reset_index()\n",
    "    df_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\n",
    "\n",
    "    # Combine these two dataframes and fill N/A values to 0\n",
    "    df_combined = pd.concat([df_start, df_stop])\n",
    "    df_combined = df_combined.fillna(0)\n",
    "\n",
    "    # Let's group on period and station_id and then sum up along start_count and stop_count\n",
    "    # And reset the multi-level index so we have a normal DataFrame\n",
    "    aggregate_data = df_combined.groupby(['period', 'station_id']).sum().reset_index()\n",
    "\n",
    "    # Let's construct a pivot table\n",
    "    pivoted = pd.pivot_table(\n",
    "        aggregate_data,\n",
    "        index=[\"period\"],\n",
    "        columns=[\"station_id\"],\n",
    "        aggfunc=np.sum,\n",
    "        fill_value=0)\n",
    "\n",
    "    # Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\n",
    "    deeper_cols = pivoted.columns.get_level_values(1)\n",
    "    top_level_cols = pivoted.columns.get_level_values(0)\n",
    "\n",
    "    # Flattening the columns\n",
    "    resultant_cols = []    \n",
    "    for i, station_id in enumerate(deeper_cols):\n",
    "        if top_level_cols[i] == \"start_count\":\n",
    "            resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\n",
    "        else:\n",
    "            resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\n",
    "    pivoted.columns = resultant_cols\n",
    "    pivoted = pivoted.reset_index()\n",
    "    print \"{} rows in the pivoted table\".format(len(pivoted))\n",
    "    X = pivoted.copy()\n",
    "    # Turn number of out in station TARGET_STATION_ID into 1s and 0s\n",
    "    answer_series = (\n",
    "        pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > threshold_out).apply(int)\n",
    "    X = X[:-1]\n",
    "    y = answer_series[1:]\n",
    "\n",
    "    classifier = RandomForestClassifier(n_estimators=tree_count)\n",
    "    scores = cross_validation.cross_val_score(\n",
    "        classifier,\n",
    "        X,\n",
    "        y,\n",
    "        cv=k_folds\n",
    "    )\n",
    "\n",
    "    end = time.time()\n",
    "    mean_accuracy = np.mean(scores)\n",
    "    print \"Rows: {}, k={}\".format(row_limit, k_folds)\n",
    "    print \"Mean accuracy: {}\".format(mean_accuracy)\n",
    "    print \"Standard deviation: {}\".format(np.std(scores))\n",
    "    print \"Took {}s\".format(end - start)\n",
    "    return mean_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6920 rows in the pivoted table\n",
      "Rows: 1000000, k=5\n",
      "Mean accuracy: 0.846800433839\n",
      "Standard deviation: 0.0135608201403\n",
      "Took 314.366345167s\n"
     ]
    }
   ],
   "source": [
    "analyze(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 trees\n",
      "140 rows in the pivoted table\n",
      "Rows: 10000, k=5\n",
      "Mean accuracy: 0.834920634921\n",
      "Standard deviation: 0.104557279717\n",
      "Took 18.0323660374s\n",
      "20 trees\n",
      "140 rows in the pivoted table\n",
      "Rows: 10000, k=5\n",
      "Mean accuracy: 0.863756613757\n",
      "Standard deviation: 0.115769081942\n",
      "Took 21.5619990826s\n",
      "40 trees\n",
      "140 rows in the pivoted table\n",
      "Rows: 10000, k=5\n",
      "Mean accuracy: 0.849470899471\n",
      "Standard deviation: 0.117887943647\n",
      "Took 25.3746700287s\n"
     ]
    }
   ],
   "source": [
    "counts = [10, 20, 40]\n",
    "accs = []\n",
    "for tc in counts:\n",
    "    print \"{} trees\".format(tc)\n",
    "    accs.append(analyze(10000, tree_count=tc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 trees\n",
      "140 rows in the pivoted table\n",
      "Rows: 10000, k=5\n",
      "Mean accuracy: 0.863492063492\n",
      "Standard deviation: 0.10181027118\n",
      "Took 59.6095778942s\n",
      "\n",
      "\n",
      "20 trees\n",
      "140 rows in the pivoted table\n",
      "Rows: 10000, k=5\n",
      "Mean accuracy: 0.834656084656\n",
      "Standard deviation: 0.0997954291739\n",
      "Took 62.9534199238s\n",
      "\n",
      "\n",
      "40 trees\n",
      "140 rows in the pivoted table\n",
      "Rows: 10000, k=5\n",
      "Mean accuracy: 0.871428571429\n",
      "Standard deviation: 0.132864823127\n",
      "Took 66.8124659061s\n",
      "\n",
      "\n",
      "100 trees\n",
      "140 rows in the pivoted table\n",
      "Rows: 10000, k=5\n",
      "Mean accuracy: 0.856878306878\n",
      "Standard deviation: 0.137190165921\n",
      "Took 71.0440227985s\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10acd0bd0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD7CAYAAABt0P8jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYkaJX0QkZpT4RURi5v8DdvLBXt4RCuwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10343a650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = [10, 20, 40, 100]\n",
    "accs = []\n",
    "for tc in counts:\n",
    "    print \"{} trees\".format(tc)\n",
    "    accs.append(analyze(10000, tree_count=tc))\n",
    "    print \"\\n\"\n",
    "plt.plot(counts, accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 rows in the pivoted table\n",
      "Rows: 10000, k=5\n",
      "Mean accuracy: 0.842328042328\n",
      "Standard deviation: 0.1161113492\n",
      "Took 186.666893005s\n",
      "\n",
      "\n",
      "140 rows in the pivoted table\n",
      "Rows: 10000, k=5\n",
      "Mean accuracy: 0.819923371648\n",
      "Standard deviation: 0.152777027106\n",
      "Took 190.342999935s\n",
      "\n",
      "\n",
      "140 rows in the pivoted table\n",
      "Rows: 10000, k=5\n",
      "Mean accuracy: 0.738779419814\n",
      "Standard deviation: 0.166961479106\n",
      "Took 194.119710922s\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10917fe10>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWxlBOPUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10acd5cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "thresholds = [1, 2, 3, 5]\n",
    "accs = []\n",
    "for to in thresholds:\n",
    "    accs.append(analyze(10000, tree_count=40, threshold_out=to))\n",
    "    print \"\\n\"\n",
    "plt.plot(thresholds, accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994 rows in the pivoted table\n",
      "Rows: 50000, k=5\n",
      "Mean accuracy: 0.84252063347\n",
      "Standard deviation: 0.174280565393\n",
      "Took 313.363794804s\n",
      "\n",
      "\n",
      "415 rows in the pivoted table\n",
      "Rows: 50000, k=5\n",
      "Mean accuracy: 0.876655052265\n",
      "Standard deviation: 0.0367909897328\n",
      "Took 328.793627977s\n",
      "\n",
      "\n",
      "394 rows in the pivoted table\n",
      "Rows: 50000, k=5\n",
      "Mean accuracy: 0.811608244077\n",
      "Standard deviation: 0.042031678653\n",
      "Took 344.247775793s\n",
      "\n",
      "\n",
      "391 rows in the pivoted table\n",
      "Rows: 50000, k=5\n",
      "Mean accuracy: 0.820654872554\n",
      "Standard deviation: 0.0339002512563\n",
      "Took 359.149614811s\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10b7515d0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEACAYAAABS29YJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109188350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = [2, 5, 10, 15]\n",
    "accs = []\n",
    "for length in lengths:\n",
    "    accs.append(analyze(50000, tree_count=40, threshold_out=1, period_minutes=length))\n",
    "    print \"\\n\"\n",
    "plt.plot(lengths, accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415 rows in the pivoted table\n",
      "Rows: 50000, k=5\n",
      "Mean accuracy: 0.864401858304\n",
      "Standard deviation: 0.0951605162627\n",
      "Took 438.220816851s\n",
      "\n",
      "\n",
      "415 rows in the pivoted table\n",
      "Rows: 50000, k=5\n",
      "Mean accuracy: 0.869396051103\n",
      "Standard deviation: 0.0486123422472\n",
      "Took 456.012518883s\n",
      "\n",
      "\n",
      "415 rows in the pivoted table\n",
      "Rows: 50000, k=5\n",
      "Mean accuracy: 0.874274099884\n",
      "Standard deviation: 0.0596159452359\n",
      "Took 474.407039881s\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-356896f34b18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0maccs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiod_minutes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3097\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3098\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3099\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3100\u001b[0m         \u001b[0mdraw_if_interactive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3101\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/matplotlib/axes/_axes.pyc\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must have same first dimension\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y can be no greater than 2-D\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEACAYAAABI5zaHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10acedf10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree_counts = [40, 100, 200]\n",
    "accs = []\n",
    "for tc in tree_counts:\n",
    "    accs.append(analyze(50000, tree_count=tc, threshold_out=1, period_minutes=5))\n",
    "    print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10a5bb2d0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEACAYAAABcXmojAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmY1nW9//HnSxBzYdFI3Ei5zMglQVTErUZBRUupc/VT\nyZOR5b5gluJydaLjuY5Zx44oUJQgiiLuiHQIQRsz0wABEQVZFGVJVFASFWSc9++Pz5fpbhpmhpl7\n+N4z83pc133x3e/3PczMez67IgIzMzOA7fIOwMzMSoeTgpmZVXFSMDOzKk4KZmZWxUnBzMyqOCmY\nmVmVOpOCpP6SFkpaLGlIDec7Snpc0lxJ8yUNyo53lzSn4LVO0hUF910uaUF2z81F/VRmZtYgqm2c\ngqQ2wKtAP2AlMBMYGBELCq65HmgfEddJ6pxd3yUiKgqu2S67v3dELJd0AnA9cFpEbJL0uYh4pwk+\nn5mZbYW6Sgq9gSURsSwiNgETgAHVrqkEOmTbHYA1hQkh0w9YGhHLs/2LgZuyZ+KEYGZWGupKCnsD\nywv2V2THCg0HDpK0CngRGFzDc84GxhfsHwB8RdLzksolHbF1YZuZWVOoKynUZw6M/sDsiNgL6AmM\nkNR+80lJ7YDTgQcL7mkL7BoRfYCrgQe2KmozM2sSbes4vxLoWrDflVRaKDQIuAkgIpZKeh3oDszK\nzp8KvFCtimgF8Eh2z0xJlZI+GxFrCh8syRMzmZk1QESoIffVVVKYBRwgab/sL/6zgEnVrnmT1GaA\npC6khPBawfmBwH3V7pkInJjd80WgXfWEsFlElPzrpz/9ae4xtIQYHafjLPVXc4mzMWotKUREhaTL\ngKlAG2B0RCyQdGF2fhRwIzBW0jxAwDURsTb7hb8zKWGcX+3RY4Axkl4CPgHObdSnMDOzoqir+oiI\nmAJMqXZsVMH234BTtnDvh0DnGo5vAr6ztcGamVnT8ojmIigrK8s7hDo1hxjBcRab4yyu5hJnY9Q6\neC1vkqKU4zMzK0WSiCZqaDYzs1bEScHMzKo4KZiZWRUnBTMzq+KkYGZmVZwUzMysipOCmZlVcVIw\nM7MqTgpmZlbFScHMzKo4KZiZWRUnBTMzq+KkYGZmVZwUzMysipOCmZlVcVIwM7MqTgpmZlbFScHM\nzKo4KZiZWRUnBTMzq+KkYGZmVZwUzMysipOCmZlVcVIwM7MqTgpmZlbFScHMrAVYvx5GjoRjj23c\nc+pMCpL6S1ooabGkITWc7yjpcUlzJc2XNCg73l3SnILXOklXVLv3R5IqJe3WuI9hZtY6LVsGP/4x\n7LsvTJ8O//3fjXte29pOSmoDDAf6ASuBmZImRcSCgssuBeZHxOmSOgOvSronIl4FDsues112/6MF\nz+4KnAS80biPYGbWukTAn/4Ew4bB00/D974Hs2ZBt26Nf3atSQHoDSyJiGUAkiYAA4DCpFAJdMi2\nOwBrIqKi2nP6AUsjYnnBsV8B1wCPNSx0M7PWZcMGuO++lAw2bIArroC774Zddinee9SVFPYGCn+R\nrwCOqnbNcOBxSauA9sCZNTznbGD85h1JA4AVETFP0lYHbWbWmqxaBb/+Nfz2t9CrF/z853DyybBd\nE7QK1/XIqMcz+gOzI2IvoCcwQlL7zScltQNOBx7M9ncCrgd+WvAMZwYzs2pmzIBzzoGDD4a1a1NV\n0ZQp0L9/0yQEqLuksBLoWrDflVRaKDQIuAkgIpZKeh3oDszKzp8KvBAR72T7+wP7AS9mpYR9gBck\n9Y6It6sHMHTo0KrtsrIyysrK6gjZzKz52rQJHn44VRH97W9w+eUwYgR06rTle8rLyykvLy/K+yti\ny4UBSW2BV4G+wCpgBjCwsKFZ0khgdUT8TFIX4AXg0IhYm52fAEyJiLu28B6vA4dvvr7auagtPjOz\nluLdd1P10MiR8IUvwODBcMYZ0KbN1j9LEhHRoBqYWksKEVEh6TJgKtAGGB0RCyRdmJ0fBdwIjJU0\nj1QNdE1BQtiZ1Mh8fm1v05DAzcxagpdeSqWChx+Gb34TJk+Gnj3zi6fWkkLeXFIws5bo00/TL/9h\nw+DVV+Hii+GCC2D33Yvz/CYrKZiZWfGsWwdjxsDw4dC5c6oi+ta3oF27vCP7BycFM7MmtmgR3H47\n3HsvnHJK+rdPn7yjqpmTgplZE4iAadNSFdHMmXD++TBvHuyzT96R1c5JwcysiD78EMaNg9tug7Zt\nUxXRQw/BjjvmHVn9OCmYmRXBG2+k8QRjxsBxx6XtsjJobpM2eOpsM7MGioBnnkmNxb16QUVFGoU8\ncSKccELzSwjgkoKZ2VbbuBEmTEjtBevXp4np7rwT2rev+95S53EKZmb19NZbaWK6UaOgR4/UXtCU\n8xA1VGPGKZTYRzEzKz2zZsF3vgMHHghvvw1PPQVTp8Jpp5VeQmgslxTMzGpQUQGPPJKqiFasgMsu\ng+9/H3ZrButEekSzmVmRrFkDv/td6j3UrRtcdRUMGJC6l7YGreRjmpnVbv78NLbgwQfT7KSPPZZ6\nFLU2Tgpm1mpVVsLvf5+qiF5+OU1Mt3AhdOmSd2T5cVIws1bn739PXUhvvx123TX1IjrzzNKamC4v\nTgpm1mosWZISwbhxcNJJadH7o49unoPMmkoL60xlZvbPImD6dDj99JQAdtoJXnwR7r8fjjnGCaE6\nlxTMrEX66CO4557UeAypiuj++1NSsC1zUjCzFmX58tSddPToVDK49Vbo29clgvpy9ZGZNXsR8Oyz\nqbG4Rw/YsAGeew4mTYJ+/ZwQtoZLCmbWbG3cCA88kLqUvv9+mpjujjugQ4e8I2u+PM2FmTU7q1fD\nb36TXoccktoLWuI8RA3lCfHMrFWYPRu++1340pdg1arUq2jaNPj6150QisVfRjMraRUVaTnL44+H\nb3wDDjoojTcYNQoOPjjv6FoetymYWUlauza1D4wYkRa7v/JK+OY3W8/EdHnxl9fMSsorr6SxBfff\nnwacPfwwHHFE3lG1Hk4KZpa7ykqYMiX1Ipo3Dy66CBYsgD32yDuy1sdJwcxy88EHMHZsmo+offvU\ni+iss2CHHfKOrPVyUjCzbe6111IiuPtuOPFEGDMGjj3Wg8xKgXsfmdk2EZHWNh4wAHr3hu23T11M\nH3wQjjvOCaFU1CspSOovaaGkxZKG1HC+o6THJc2VNF/SoOx4d0lzCl7rJF2RnfulpAWSXpT0iKSO\nRf1kZlYSPv449SLq0SOtc3zaafDGG/CLX8C+++YdnVVX54hmSW2AV4F+wEpgJjAwIhYUXHM90D4i\nrpPUObu+S0RUFFyzXXZ/74hYLukk4MmIqJT0c4CIuLbae3tEs1kztWIFjByZEkLv3qm9wPMQbRtN\nPaK5N7AkIpZFxCZgAjCg2jWVwObZRjoAawoTQqYfsDQilgNExLSIqMzO/RXYpyEfwMxKy/PPw9ln\nw6GHwvr1aaK6yZPTojZOCKWvPg3NewPLC/ZXAEdVu2Y48LikVUB74MwannM2MH4L73EecF89YjGz\nEvTJJ6lt4Lbb4N134fLL04jjjq4UbnbqkxTqU3/TH5gdESdI2h+YJqlHRHwAIKkdcDpQU3vEDcAn\nEVFjwhg6dGjVdllZGWVlZfUIx8y2hbffTr/8f/3rNB/RDTfA174GbdrkHVnrUl5eTnl5eVGeVZ82\nhT7A0Ijon+1fB1RGxM0F10wGboqIZ7P9J4EhETEr2x8AXLz5GQX3DQLOB/pGxIYa3tttCmYlaO7c\nNNBs4kT41rdSyeDQQ/OOyjZrTJtCfUoKs4ADJO0HrALOAgZWu+ZNUpvBs5K6AN2B1wrOD6Ra9ZCk\n/sDVwFdrSghmVlo+/RQeeywlg6VL4dJLYfFi6Nw578ismOq1noKkU4FbgTbA6Ii4SdKFABExStKe\nwFhgT0CkUsP47N6dgTeAbpurk7Lji4F2wNrs0HMRcUm193VJwSxn77+fehANHw577ZV6Ef3bv6Vx\nBlaaGlNS8CI7ZlajhQtTw/F996V2gsGD4cgj847K6qOpq4/MrJWorISpU1MV0Zw5cMEF8PLLqYRg\nrYOTgpmxfn2ah+i22+Azn0mlgokT07a1Lk4KZq3Y66+nRWzGjoWvfAV++9u0wpkHmbVenhDPrJWJ\ngKefTquYHXlkSgCzZsEjj6TE4ITQurmkYNZKbNgA48enKqKNG+GKK2DcONhll7wjs1Li3kdmLdyq\nVWliut/9Dnr1Su0FJ58M27meoMVq6gnxzKwZmjEDzjkHDjkE3nsvVRlNmQL9+zsh2Ja5+sisBdm0\nKS10P2wYvPVWWr9gxAjo1CnvyKy5cFIwawHefTf1HBo5Eg44AK65Bs44wxPT2dZzIdKsGZs3D37w\ng5QIli6F3/8e/vjH1LPICcEawiUFs2bm00/TojW33gqLFsHFF6d/P/e5vCOzlsBJwayZWLcOxoyB\n229PCWDw4DRtdbt2eUdmLYmTglmJW7QoJYJ774VTTkljDfr0yTsqa6mcFMxKUARMm5Z6Ec2cmSam\ne+kl2HvvvCOzls5JwayEfPhhGmV8223Qti1ceSU89BDsuGPekVlr4aRgVgLeeCMtYnPnnXDccWls\nQVmZ5yGybc9dUs1yEgHPPJMai3v1Sr2KZsxIU1afcIITguXDJQWzbWzjRpgwIbUXrF+fJqa7805o\n3z7vyMw8IZ7ZNvPWW/DrX8OoUdCzZ0oGnofImoInxDMrYbNmwXe+AwceCG+/nUYc/+EPcNppTghW\nelxSMGsCmzbBo4+mKqIVK9LEdD/4Aey6a96RWWvQmJKC2xTMimjNmrRuwYgR0K0bXHUVDBiQupea\nNQf+VjUrgvnz09iCBx9MSWDSJDjssLyjMtt6TgpmDVRZmWYlHTYMXnkFLroIFi6ELl3yjsys4ZwU\nzLbS3/+eupDefntqIxg8GM480xPTWcvgpGBWT0uWpEQwbhycdBLcfTccfbQHmVnL4g5xZrWIgOnT\n4fTTUwLYaSd48UW4/3445hgnBGt5XFIwq8FHH8E996TGY0hVRPffn5KCWUtWZ0lBUn9JCyUtljSk\nhvMdJT0uaa6k+ZIGZce7S5pT8Fon6Yrs3G6SpklaJOkJSV5W3ErC8uVw7bWw775pdbNhw9KU1eef\n74RgrUOtSUFSG2A40B84CBgo6cBql10KzI+InkAZcIukthHxakQcFhGHAYcDHwGPZvdcC0yLiC8C\nT2b7ZrmIgGefTY3FPXrAhg3w/POpW2nfvq4istalrpJCb2BJRCyLiE3ABGBAtWsqgQ7ZdgdgTURU\nVLumH7A0IpZn+2cAd2XbdwHfaEjwZo2xcWNqND7ySBg0KE1ZvWxZWvt4//3zjs4sH3W1KewNLC/Y\nXwEcVe2a4cDjklYB7YEza3jO2cD4gv0uEbE6214NuGe3bTOrV8NvfpNehxwCQ4d6HiKzzepKCvWZ\neKg/MDsiTpC0PzBNUo+I+ABAUjvgdOBf2iMAIiIkbfF9hg4dWrVdVlZGWVlZPUIy+1ezZ6c2gkmT\nUlXR9Olw8MF5R2XWeOXl5ZSXlxflWbVOiCepDzA0Ivpn+9cBlRFxc8E1k4GbIuLZbP9JYEhEzMr2\nBwAXb35GdmwhUBYRb0naE/hjRHyphvf3hHjWKBUVadGaYcPS6maXXpoajXfbLe/IzJpOU06INws4\nQNJ+wCrgLGBgtWveJLUZPCupC9AdeK3g/EDgvmr3TAK+C9yc/TuxAbGbbdHatXDHHWliuq5dU5fS\nb37TE9OZ1aXOqbMlnQrcCrQBRkfETZIuBIiIUdlf+mOBPQGRSg3js3t3Bt4Aum2uTsqO7wY8AHwe\nWAacGRHv1/DeLinYVnnllTS24P7704CzwYPh8MPzjsps22pMScHrKVizV1kJU6akKqJ589LEdBdd\nBHvskXdkZvnwegrWKn3wAYwdm+Yjat8+lQrOOgt22CHvyMyaLycFa3Zeey0lgrvvhhNPhDFj4Nhj\nPcjMrBjcM9uahQh46qm0gM1RR6VpqufMSYvaHHecE4JZsbikYCXt44/h3ntT4/Gnn8IVV8D48bDz\nznlHZtYyOSlYSVqxAkaOTN1Ke/eGW26Bfv1cIjBraq4+spLy3HNw9tlw6KGwfn2aqG7y5LSojROC\nWdNzScFKwgcfwCWXwJ//nHoRjRoFHTvmHZVZ6+OkYLmbOzfNRfSVr8DLL3vdArM8ufrIchORpqE4\n6aQ0U+kddzghmOXNJQXLxXvvwfe/n9Yv+Mtf4IAD8o7IzMAlBcvB88/DYYfBPvukhmUnBLPS4ZKC\nbTOVlfA//5O6l44aBd/wentmJcdJwbaJd96Bc8+FdetgxgzYd9+8IzKzmrj6yJpceXmqLurZE55+\n2gnBrJS5pGBN5tNP4cYbU1XR2LFwyil5R2RmdXFSsCaxciWccw60aZPWRt5zz7wjMrP6cPWRFd2U\nKWm1s7594YknnBDMmhOXFKxoNm2CG26A++6DBx5II5TNrHlxUrCiWLYsTWTXuXNa56Bz57wjMrOG\ncPWRNdrDD6fprc88EyZNckIwa85cUrAG27ABfvSj1IYweXJKDGbWvLmkYA2yaBH06QNvv516Fzkh\nmLUMTgq21caNg2OPhYsuSg3KnTrlHZGZFYurj6zePvwQLrssTWI3fTr06JF3RGZWbC4pWL3MmwdH\nHJHWQJg1ywnBrKVyUrBaRaRpKvr2heuuS9NV7LJL3lGZWVNx9ZFt0bp1cMEFsHAhPPMMfOlLeUdk\nZk3NJQWr0cyZ0KsXfPazaVEcJwSz1qHOpCCpv6SFkhZLGlLD+Y6SHpc0V9J8SYMKznWS9JCkBZJe\nkdQnO95T0vOS5kiaKenIon4qa7AI+N//ha99DW6+GUaOhB13zDsqM9tWFBFbPim1AV4F+gErgZnA\nwIhYUHDN9UD7iLhOUufs+i4RUSHpLuDpiBgjqS2wc0Ssk/QEcEtETJV0KnBNRJxQw/tHbfFZca1Z\nA4MGpbEHEyZAt255R2RmDSGJiFBD7q2rpNAbWBIRyyJiEzABGFDtmkqgQ7bdAViTJYSOwPERMQYg\nIioiYl3BPR2z7U6khGM5euaZtBBO9+5p2wnBrHWqq6F5b2B5wf4K4Khq1wwHHpe0CmgPnJkd7wa8\nI+lOoAfwAjA4Ij4CrgSmSvofUmI6ulGfwhrs00/hpptg+HAYPTpVG5lZ61VXUqhP3U1/YHZEnCBp\nf2CapB7Zs3sBl0XETEm3AtcC/wFcAlwZEY9K+n/AGOCkmh4+dOjQqu2ysjLKysrqEZLVx1tvwb//\ne5ryetYs2GefvCMys4YoLy+nvLy8KM+qq02hDzA0Ivpn+9cBlRFxc8E1k4GbIuLZbP9JYAipVPFc\nRHTLjh8PDImIr0t6PyI6ZccFvB8RHanGbQpNZ9o0+O534fzz4Sc/gbbunGzWYjRlm8Is4ABJ+0lq\nB5wFTKp2zZukhmgkdQG6A69FxFvAcklfzK7rC7ycba+S9NVs+0RgUUOCt61XUQHXX58alO+5B372\nMycEM/uHWn8dZA3GlwFTgTbA6IhYIOnC7Pwo4EZgrKR5gEg9idZmj7gcuDdLKEuB72XHzweGZT2S\nPgYuKPLnshq8+SYMHJhGJM+ZA7vvnndEZlZqaq0+ypurj4pn0qRUVXTVVXD11bCdhy2atViNqT5y\nxUELt3EjDBkCEyfCo4/CMcfkHZGZlTInhRZsyRI46yz4/OfTQji77ZZ3RGZW6lyJ0EJNmABHH50a\nlB95xAnBzOrHJYUW5qOPYPBgKC+HqVPTpHZmZvXlkkIL8soraa3kjz5K1UVOCGa2tZwUWoAIGDMG\nvvrV1Lvonnugffu8ozKz5sjVR83cBx/ARRfBiy+mKqODD847IjNrzlxSaMY2VxHtvDPMmOGEYGaN\n56TQDEXA7bfDKafAjTfCb38LO+2Ud1Rm1hK4+qiZee89OO+8NGXFc8/BF76Qd0Rm1pK4pNCMPPdc\nWghn333hL39xQjCz4nNJoRmorIRf/hJ+9atUVTSg+tp3ZmZF4qRQ4t5+G849N/UymjkzTVlhZtZU\nXH1Uwp56KlUX9eqVups6IZhZU3NJoQRVVMB//ifccQeMHQsnn5x3RGbWWjgplJiVK+Hb34btt0/j\nEPbYI++IzKw1cfVRCfn97+Hww1PJYOpUJwQz2/ZcUigBn3yS1k1+4AF48EE4/vi8IzKz1spJIWev\nvw5nn53WS549Gzp3zjsiM2vNXH2Uo4cegqOOSklh0iQnBDPLn0sKOdiwIU1xPXVqakc48si8IzIz\nS1xS2MYWLkylgzVrUnWRE4KZlRInhW3o7rtTI/Ill6Q1lDt2zDsiM7N/5uqjbWD9erj00rTmwVNP\nwZe/nHdEZmY1c0mhic2bB0ccAdttB7NmOSGYWWlzUmgiEfCb30DfvnDDDXDnnWmFNDOzUubqoybw\n/vtw/vmweDH8+c/QvXveEZmZ1Y9LCkU2Y0aa1XT33eH5550QzKx5qTMpSOovaaGkxZKG1HC+o6TH\nJc2VNF/SoIJznSQ9JGmBpFck9Sk4d3l2fL6km4v2iXJSWQm33AJf/3paEGfECPjMZ/KOysxs69Ra\nfSSpDTAc6AesBGZKmhQRCwouuxSYHxGnS+oMvCrpnoioAIYB/xcR35LUFtg5e+4JwBnAoRGxSdLn\niv/Rtp1334VBg9K/f/0rdOuWd0RmZg1TV0mhN7AkIpZFxCZgAlB9MchKoEO23QFYExEVkjoCx0fE\nGICIqIiIddl1FwM3Zc8kIt4pwmfJxZ/+lBbCOeggeOYZJwQza97qSgp7A8sL9ldkxwoNBw6StAp4\nERicHe8GvCPpTkmzJf1O0k7ZuQOAr0h6XlK5pCMa9zG2vU8/hRtvhDPPTOsm/+IXaQ0EM7PmrK6k\nEPV4Rn9gdkTsBfQERkhqT6qa6gWMjIhewIfAtdk9bYFdI6IPcDXwQEOCz8vf/pbWPHjySXjhBTj1\n1LwjMjMrjrq6pK4EuhbsdyWVFgoNAm4CiIilkl4HumfXrYiImdl1DwObG6pXAI9k98yUVCnpsxGx\npnoAQ4cOrdouKyujrKyszg/VlKZOTe0HF14IP/kJtGmTazhmZpSXl1NeXl6UZyliy4WBrHH4VaAv\nsAqYAQwsbGiWNBJYHRE/k9QFeIHUgLxW0p+AH0TEIklDgR0jYoikC4G9IuKnkr4ITI+If1mWXlLU\nFt+2tGkT/Md/wLhx6XXCCXlHZGZWM0lEhBpyb60lhazB+DJgKtAGGB0RC7Jf6kTEKOBGYKykeYCA\nayJibfaIy4F7JbUDlgLfy46PAcZIegn4BDi3IcFvK2+8AQMHpgnsZs9OYxDMzFqiWksKeSuFksLE\niamq6Mc/hh/9KM1hZGZWypqspNCabdwIV1+dVkR77DHo06fue8zMmjsnhRosXpyWyNx3X5gzB3bd\nNe+IzMy2DVeGVDN+PBxzDJx3Hjz8sBOCmbUuLilkPvoIrrgijVB+4ok0StnMrLVxSQF4+eW0VvKG\nDWkwmhOCmbVWrTopRMAdd0BZWepdNG4ctG+fd1RmZvlptdVHf/976mo6fz48/XSa0M7MrLVrlSWF\nF16Aww+HDh3SojhOCGZmSatKChFw223Qvz/813/BqFGw4455R2VmVjpaTfXR2rWpm+mKFWmZzP33\nzzsiM7PS0ypKCn/5S+pR1K0bPPusE4KZ2Za06JJCZSXcfDPcemvqZXT66XlHZGZW2lpsUli9Gs49\nFz78EGbNgq5d677HzKy1a5HVR08+Cb16pQFp5eVOCGZm9dWiSgoVFfCzn8Ho0XD33dCvX94RmZk1\nLy0mKaxYAd/+NuywQ1oIZ4898o7IzKz5aRHVR5MnwxFHpPEHU6c6IZiZNVSzLil88glcdx08+CA8\n9BAcd1zeEZmZNW/NNim89lpaCGePPdJCOJ/9bN4RmZk1f82y+uiBB+Coo1IbwmOPOSGYmRVLsyop\nfPwx/PCHMH06TJmS2hHMzKx4mk1JYeHCVDp4//00y6kTgplZ8TWLpHDXXXD88XD55XDffdCxY94R\nmZm1TCVffXTuuWmaiqeegi9/Oe9ozMxatpJPCttvDzNnws475x2JmVnLp4jIO4YtkhSlHJ+ZWSmS\nRESoIfc2izYFMzPbNpwUzMysSp1JQVJ/SQslLZY0pIbzHSU9LmmupPmSBhWc6yTpIUkLJL0iqU+1\ne38kqVLSbkX5NGZm1ii1JgVJbYDhQH/gIGCgpAOrXXYpMD8iegJlwC2SNjdgDwP+LyIOBA4FFhQ8\nuytwEvBGET5HrsrLy/MOoU7NIUZwnMXmOIurucTZGHWVFHoDSyJiWURsAiYAA6pdUwl0yLY7AGsi\nokJSR+D4iBgDEBEVEbGu4L5fAdc0+hOUgObwjdIcYgTHWWyOs7iaS5yNUVdS2BtYXrC/IjtWaDhw\nkKRVwIvA4Ox4N+AdSXdKmi3pd5J2ApA0AFgREfMa/QnMzKxo6koK9ekP2h+YHRF7AT2BEZLak8ZA\n9AJGRkQv4EPgWkk7AtcDPy14RoO6TpmZWZFFxBZfQB/gDwX71wFDql0zGTi2YP9J4AhgD+D1guPH\nZdceAqwGXs9em4BlwO41vH/45Zdffvm19a/afrfX9qprRPMs4ABJ+wGrgLOAgdWueRPoBzwrqQvQ\nHXgtItZKWi7pixGxKLvm5YiYD3TZfLOk14HDI2Jt9Tdv6OALMzNrmFqTQtZgfBkwFWgDjI6IBZIu\nzM6PAm4ExkqaR6oGuqbgF/zlwL2S2gFLge/V9DbF+ShmZtZYJT3NhZmZbVslNaJZUhtJcyQ9nu3v\nJmmapEWSnpDUqQRirD4g76gSjfOH2WDClySNl7RDKcQpaYyk1ZJeKji2xbgkXZcNnFwo6eQcY/xl\n9n/+oqRHsi7XucW4pTgLzv3LwNBSi1PS5dnXdL6km0sxTkk9JT2f/V6aKenIEoizq6Q/Sno5+9pd\nkR0vzs9RQxsjmuIFXAXcC0zK9n9Bqo4CGAL8vARivAs4L9tuC3QstThJ3YZfA3bI9u8HvlsKcQLH\nA4cBLxUcqzEu0oDJucD2wH7AEmC7nGI8afN7Az/PO8YtxZkd7wr8gdSRY7dSjBM4AZgGbJ/tf65E\n43wCOCWpa4vyAAADeElEQVTbPhX4YwnEuQfQM9veBXgVOLBYP0clU1KQtA9wGnAH/+iiegbplzDZ\nv9/IIbQqtQzIK6k4M22BnbLR5TuROgrkHmdEPAO8V+3wluIaANwXEZsiYhnpm7l3HjFGxLSIqMx2\n/wrsk2eMW4ozU9PA0FKL82LgpkiDYomId0o0zkrSH34AnYCVJRDnWxExN9teT5opYm+K9HNUMkkB\n+F/gatJ/wmZdImJ1tr2agl5LOalpQN7OlFicEbESuIXUM2wV8H5ETKPE4iywpbj2Ig2Y3KymwZN5\nOA/4v2y7pGKsZWBoScUJHAB8JauaKZe0eYHdUovzSuCXkt4Efknqlg8lEmfWM/Qw0h8qRfk5Komk\nIOnrwNsRMYctDGSLVA7Ku1W8xgF5hReUQpySdiX91bAf6RtiF0n/XnhNKcRZk3rElffX9gbgk4gY\nX8tlucSoNGPA1gwMzfNr2RbYNSL6kP4YfKCWa/OM8xLgyoj4PPBDYEwt127TOCXtAjwMDI6ID/4p\nkEb8HJVEUgCOAc7IxizcB5woaRywWtIeAJL2BN7OMUZIGXZFRMzM9h8iJYm3SizOfqSBg2siogJ4\nBDia0otzsy39P68k1Y9vtg//KL5vc0ozAJ8GnFNwuJRi3J/0h8CL2c/SPsALSuOHSilOSD9LjwBk\nP0+VkjpTenGeGxGPZtsP8Y9ql1zjlLQ9KSGMi4iJ2eGi/ByVRFKIiOsjomtEdAPOBp6KiO8Ak0gN\npGT/TtzSM7aFiHgLWC7pi9mhfsDLwOOUUJykmWf7SNpRkkhxvkLpxbnZlv6fJwFnS2onqRupymFG\nDvEhqT/pL9oBEbGh4FTJxBgRL0VEl4jolv0srQB6ZVUKJRNnZiJwIkD289QuIt6l9OJcJemr2faJ\nwKJsO7c4s5/p0cArEXFrwani/Bxti9byrWxZ/yr/6H20GzCd9B/xBNCpBOLrAcwkTf73CKkRqhTj\nHEpqgHqJ1Oi0fSnESSoJrgI+IU22+L3a4iJVhywBFpL1AskhxvOAxaRkOyd7jcwzxmpxbtz8tax2\n/jWy3kelFmf2/Tgu+/58ASgroTgLvzePJc3sMBd4DjisBOI8jtT2Orfg+7F/sX6OPHjNzMyqlET1\nkZmZlQYnBTMzq+KkYGZmVZwUzMysipOCmZlVcVIwM7MqTgpmZlbFScHMzKr8f/2eeL3tRliTAAAA\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10914e5d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tree_counts, accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6920 rows in the pivoted table\n",
      "Rows: 1000000, k=5\n",
      "Mean accuracy: 0.873250953987\n",
      "Standard deviation: 0.0224396149915\n",
      "Took 898.113418818s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.87325095398710173"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze(1000000, tree_count=200, threshold_out=1, period_minutes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8142 rows in the pivoted table\n",
      "Rows: 1200000, k=5\n",
      "Mean accuracy: 0.87753175687\n",
      "Standard deviation: 0.0101650338518\n",
      "Took 1438.6476028s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.87753175687006379"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze(1200000, tree_count=500, threshold_out=1, period_minutes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/IPython/core/interactiveshell.py:3012: DtypeWarning: Columns (3,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown string format",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-11ce94afdbc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500000000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiod_minutes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-84718858a621>\u001b[0m in \u001b[0;36manalyze\u001b[0;34m(row_limit, threshold_out, tree_count, period_minutes, k_folds)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/july_thru_sept.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCOLUMNS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Convert to timestamps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"starttime\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"starttime\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stoptime\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stoptime\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/pandas/util/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/pandas/tseries/tools.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, box, format, exact, coerce, unit, infer_datetime_format)\u001b[0m\n\u001b[1;32m    274\u001b[0m     return _to_datetime(arg, errors=errors, dayfirst=dayfirst, yearfirst=yearfirst,\n\u001b[1;32m    275\u001b[0m                         \u001b[0mutc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexact\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m                         unit=unit, infer_datetime_format=infer_datetime_format)\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/pandas/tseries/tools.py\u001b[0m in \u001b[0;36m_to_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, box, format, exact, unit, freq, infer_datetime_format)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/pandas/tseries/tools.py\u001b[0m in \u001b[0;36m_convert_listlike\u001b[0;34m(arg, box, format, name)\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown string format"
     ]
    }
   ],
   "source": [
    "analyze(500000000, tree_count=500, threshold_out=1, period_minutes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2902: DtypeWarning: Columns (3,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/july_thru_sept.csv\", usecols=COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14217684"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>start station id</th>\n",
       "      <th>end station id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [starttime, stoptime, start station id, end station id]\n",
       "Index: []"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"stoptime\"].isnull() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "> <ipython-input-45-c1cff856fa26>(6)<module>()->None\n",
      "-> import pdb; pdb.set_trace()\n",
      "(Pdb) e\n",
      "ValueError(u'Unknown string format',)\n",
      "(Pdb) values\n",
      "*** NameError: name 'values' is not defined\n",
      "(Pdb) locals()\n",
      "{'disp': <function disp at 0x104e00848>, 'lstsq': <function lstsq at 0x104e15b90>, 'all': <function all at 0x104d5acf8>, 'dist': <function dist at 0x1081d07d0>, 'issubsctype': <function issubsctype at 0x104a90b18>, 'sca': <function sca at 0x109d199b0>, 'savez': <function savez at 0x104e751b8>, 'entropy': <function entropy at 0x10a9b9f50>, 'restoredot': <function restoredot at 0x104d40500>, 'ptp': <function ptp at 0x104d5ae60>, 'Subplot': <class 'matplotlib.axes._subplots.AxesSubplot'>, 'frange': <function frange at 0x10a99c0c8>, 'PackageLoader': <class 'numpy._import_tools.PackageLoader'>, 'to': 3, 'rec2csv': <function rec2csv at 0x10a99f668>, 'ylabel': <function ylabel at 0x109d200c8>, 'tc': 200, 'norm': <function norm at 0x104e2c320>, 'MultipleLocator': <class 'matplotlib.ticker.MultipleLocator'>, 'pkgload': <function pkgload at 0x103a5bed8>, 'mpl': <module 'matplotlib' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/matplotlib/__init__.pyc'>, 'rc': <function rc at 0x109d1cc08>, 'ERR_RAISE': 2, 'void0': <type 'numpy.void'>, 'lapack_lite': <module 'numpy.linalg.lapack_lite' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/numpy/linalg/lapack_lite.so'>, 'window_hanning': <function window_hanning at 0x10a9b9320>, 'array_equal': <function array_equal at 0x104d5d938>, '_i22': u'lengths = [2, 5, 10, 15]\\naccs = []\\nfor length in lengths:\\n    accs.append(analyze(50000, tree_count=40, threshold_out=1, period_minutes=length))\\n    print \"\\\\n\"\\nplt.plot(lengths, accs)', 'longest_contiguous_ones': <function longest_contiguous_ones at 0x1081d0140>, '_i23': u'tree_counts = [40, 100, 200]\\naccs = []\\nfor tc in tree_counts:\\n    accs.append(analyze(50000, tree_count=tc, threshold_out=1, period_minutes=5))\\n    print \"\\\\n\"\\nplt.plot(lengths, tree_counts)', '_i20': u'thresholds = [1, 2, 3]\\nfor to in thresholds:\\n    accs.append(analyze(10000, tree_count=40, threshold_out=to))\\n    print \"\\\\n\"\\nplt.plot(thresholds, accs)', 'indices': <function indices at 0x104d5d488>, 'fftpack': <module 'numpy.fft.fftpack' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/numpy/fft/fftpack.pyc'>, 'argpartition': <function argpartition at 0x104d5a398>, 'Circle': <class 'matplotlib.patches.Circle'>, 'logseries': <built-in method logseries of mtrand.RandomState object at 0x104ee18d0>, 'YearLocator': <class 'matplotlib.dates.YearLocator'>, 'diag': <function diag at 0x104de97d0>, 'sum': <function sum at 0x104d5aaa0>, 'nanmin': <function nanmin at 0x104e13140>, 'memmap': <class 'numpy.core.memmap.memmap'>, 'axvline': <function axvline at 0x109d46050>, 'irfftn': <function irfftn at 0x103ab3050>, 'full': <function full at 0x104d40cf8>, 'copysign': <ufunc 'copysign'>, 'l2norm': <function l2norm at 0x1081d0f50>, 'unicode_': <type 'numpy.unicode_'>, 'legend': <function legend at 0x109d47848>, 'trunc': <ufunc 'trunc'>, 'irfft2': <function irfft2 at 0x103ab30c8>, 'ERR_PRINT': 4, 'IndexDateFormatter': <class 'matplotlib.dates.IndexDateFormatter'>, 'HourLocator': <class 'matplotlib.dates.HourLocator'>, 'l1norm': <function l1norm at 0x1081d0ed8>, 'BUFSIZE': 8192, 'sci': <function sci at 0x109d1cd70>, 'ginput': <function ginput at 0x109d19500>, 'shuffle': <built-in method shuffle of mtrand.RandomState object at 0x104ee18d0>, 'divide': <ufunc 'divide'>, 'fftshift': <function fftshift at 0x103ab3320>, 'fastCopyAndTranspose': <built-in function _fastCopyAndTranspose>, 'silent_list': <class 'matplotlib.cbook.silent_list'>, 'uintc': <type 'numpy.uint32'>, 'counts': [10, 20, 40, 100], '_i30': u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\n\\ndef analyze(row_limit, threshold_out=1, tree_count=10, period_minutes=5, k_folds=5):\\n    \"\"\"\\n    We can tune the following parameters:\\n    - number of rows we analyze\\n    - number of folds in our standard k-fold cross-validation\\n    - number of bicycles taken out in the period to be considered in the positive class\\n    - number of trees in our random forest\\n    - number of minutes in our period\\n    \"\"\"\\n    start = time.time()\\n    df = pd.read_csv(\"data/july_thru_sept.csv\", usecols=COLUMNS, nrows=row_limit)\\n    # Convert to timestamps \\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\n    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n    # Convert int64index to datetime index\\n    # Group using timegrouper and create new column for start period and stop period\\n    df = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\n    start_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\n    df[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\n    df = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\n    stop_time_group_by = df.groupby(pd.TimeGrouper(\\'{}Min\\'.format(period_minutes)),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\n    df[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n    # Create two sub dataframes, grouping on and aggregating start data and then stop data\\n    grouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\n    df_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\n    df_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\n    grouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\n    df_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\n    df_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n    # Combine these two dataframes and fill N/A values to 0\\n    df_combined = pd.concat([df_start, df_stop])\\n    df_combined = df_combined.fillna(0)\\n\\n    # Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n    # And reset the multi-level index so we have a normal DataFrame\\n    aggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n    # Let\\'s construct a pivot table\\n    pivoted = pd.pivot_table(\\n        aggregate_data,\\n        index=[\"period\"],\\n        columns=[\"station_id\"],\\n        aggfunc=np.sum,\\n        fill_value=0)\\n\\n    # Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\n    deeper_cols = pivoted.columns.get_level_values(1)\\n    top_level_cols = pivoted.columns.get_level_values(0)\\n\\n    # Flattening the columns\\n    resultant_cols = []    \\n    for i, station_id in enumerate(deeper_cols):\\n        if top_level_cols[i] == \"start_count\":\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n        else:\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\n    pivoted.columns = resultant_cols\\n    pivoted = pivoted.reset_index()\\n    print \"{} rows in the pivoted table\".format(len(pivoted))\\n    X = pivoted.copy()\\n    # Turn number of out in station TARGET_STATION_ID into 1s and 0s\\n    answer_series = (\\n        pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > threshold_out).apply(int)\\n    X = X[:-1]\\n    y = answer_series[1:]\\n\\n    classifier = RandomForestClassifier(n_estimators=tree_count)\\n    scores = cross_validation.cross_val_score(\\n        classifier,\\n        X,\\n        y,\\n        cv=k_folds\\n    )\\n\\n    end = time.time()\\n    mean_accuracy = np.mean(scores)\\n    print \"Rows: {}, k={}\".format(row_limit, k_folds)\\n    print \"Mean accuracy: {}\".format(mean_accuracy)\\n    print \"Standard deviation: {}\".format(np.std(scores))\\n    print \"Took {}s\".format(end - start)\\n    return mean_accuracy', 'byte': <type 'numpy.int8'>, 'select': <function select at 0x104e000c8>, 'deg2rad': <ufunc 'deg2rad'>, 'plot': <function plot at 0x109d46cf8>, 'eye': <function eye at 0x104de9758>, 'negative': <ufunc 'negative'>, 'busday_offset': <built-in function busday_offset>, 'mintypecode': <function mintypecode at 0x104dd31b8>, '_28': 0.86718256219107048, '_29': 0.87382836173351897, '_26': 0.87753175687006379, '_24': [<matplotlib.lines.Line2D object at 0x10a5bb2d0>], '_25': 0.87325095398710173, 'genfromtxt': <function genfromtxt at 0x104e75578>, 'clabel': <function clabel at 0x109d46398>, '_21': [<matplotlib.lines.Line2D object at 0x10917fe10>], 'rk4': <function rk4 at 0x1081d05f0>, 'longdouble': <type 'numpy.float128'>, 'uint0': <type 'numpy.uint64'>, 'get_fignums': <function get_fignums at 0x109d19050>, 'uint8': <type 'numpy.uint8'>, 'chararray': <class 'numpy.core.defchararray.chararray'>, 'hold': <function hold at 0x109d19758>, 'mirr': <function mirr at 0x104e771b8>, 'uint64': <type 'numpy.uint64'>, 'ma': <module 'numpy.ma' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/numpy/ma/__init__.pyc'>, 'Text': <class 'matplotlib.text.Text'>, 'true_divide': <ufunc 'true_divide'>, 'det': <function det at 0x104e15c08>, 'SU': SU, 'DateLocator': <class 'matplotlib.dates.DateLocator'>, 'SA': SA, 'Normalize': <class 'matplotlib.colors.Normalize'>, 'quiver': <function quiver at 0x109d46e60>, 'triu_indices': <function triu_indices at 0x104de9c80>, 'subplot2grid': <function subplot2grid at 0x109d19b90>, 'DAILY': 3, 'autumn': <function autumn at 0x109d20c80>, 'logical_or': <ufunc 'logical_or'>, 'minimum': <ufunc 'minimum'>, 'WRAP': 1, 'axis': <function axis at 0x109d19f50>, 'end': 1447097515.487214, 'csd': <function csd at 0x109d46500>, 'RRuleLocator': <class 'matplotlib.dates.RRuleLocator'>, 'length': 15, 'hot': <function hot at 0x109d47ed8>, 'minorticks_off': <function minorticks_off at 0x109d20488>, 'exception_to_str': <function exception_to_str at 0x105b49f50>, 'get_figlabels': <function get_figlabels at 0x109d190c8>, 'array_str': <function array_str at 0x104d5d398>, 'setdiff1d': <function setdiff1d at 0x104e30938>, 'void': <type 'numpy.void'>, 'griddata': <function griddata at 0x10a99f6e0>, 'unicode0': <type 'numpy.unicode_'>, 'str_': <type 'numpy.string_'>, 'fv': <function fv at 0x104e75ed8>, 'yticks': <function yticks at 0x109d20398>, 'linalg': <module 'numpy.linalg' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/numpy/linalg/__init__.pyc'>, 'asanyarray': <function asanyarray at 0x104d40b18>, 'logaddexp': <ufunc 'logaddexp'>, 'flatnonzero': <function flatnonzero at 0x104d407d0>, 'amin': <function amin at 0x104d5af50>, 'pylab_setup': <function pylab_setup at 0x109d0ee60>, 'tricontour': <function tricontour at 0x109d47398>, 'subplots': <function subplots at 0x109d19b18>, 'barbs': <function barbs at 0x109d476e0>, '__': Empty DataFrame\n",
      "Columns: [starttime, stoptime, start station id, end station id]\n",
      "Index: [], 'xlim': <function xlim at 0x109d20140>, 'copper': <function copper at 0x109d47d70>, 'MONTHLY': 1, 'dsplit': <function dsplit at 0x104e13ed8>, 'fft': <module 'numpy.fft' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/numpy/fft/__init__.pyc'>, 'cross': <function cross at 0x104d402a8>, 'top_level_cols': Index([u'start_count', u'start_count', u'start_count', u'start_count',\n",
      "       u'start_count', u'start_count', u'start_count', u'start_count',\n",
      "       u'start_count', u'start_count',\n",
      "       ...\n",
      "       u'stop_count', u'stop_count', u'stop_count', u'stop_count',\n",
      "       u'stop_count', u'stop_count', u'stop_count', u'stop_count',\n",
      "       u'stop_count', u'stop_count'],\n",
      "      dtype='object', length=814), 'ppmt': <function ppmt at 0x104e75b90>, 'cumsum': <function cumsum at 0x104d5ad70>, 'roots': <function roots at 0x104e2c488>, 'style': <module 'matplotlib.style' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/matplotlib/style/__init__.pyc'>, 'vectorize': <class 'numpy.lib.function_base.vectorize'>, 'fix': <function fix at 0x104dd3140>, 'stineman_interp': <function stineman_interp at 0x10a99f848>, 'busday_count': <built-in function busday_count>, 'cla': <function cla at 0x109d47758>, 'timedelta64': <type 'numpy.timedelta64'>, 'strpdate2num': <class matplotlib.dates.strpdate2num at 0x105a76530>, '_i': u'    df = pd.read_csv(\"data/july_thru_sept.csv\", usecols=COLUMNS)\\n    # Convert to timestamps \\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\n    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])', 'FPE_INVALID': 8, 'recfromcsv': <function recfromcsv at 0x104e75758>, 'fill_diagonal': <function fill_diagonal at 0x104e0e668>, 'empty_like': <built-in function empty_like>, 'logaddexp2': <ufunc 'logaddexp2'>, 'suptitle': <function suptitle at 0x109d19668>, 'get_backend': <function get_backend at 0x105a52758>, 'station_id': 3224, 'number': <type 'numpy.number'>, 'quiverkey': <function quiverkey at 0x109d46ed8>, 'is_numlike': <function is_numlike at 0x105b47d70>, 'ctypeslib': <module 'numpy.ctypeslib' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/numpy/ctypeslib.pyc'>, 'waitforbuttonpress': <function waitforbuttonpress at 0x109d19578>, 'PZERO': 0.0, 'relativedelta': <class 'dateutil.relativedelta.relativedelta'>, 'asfarray': <function asfarray at 0x104dcd938>, 'fliplr': <function fliplr at 0x104de95f0>, 'alen': <function alen at 0x104d5c050>, 'fmod': <ufunc 'fmod'>, 'classifier': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), 'bone': <function bone at 0x109d47c80>, 'mean': <function mean at 0x104d5c410>, 'set_state': <built-in method set_state of mtrand.RandomState object at 0x104ee18d0>, 'ogrid': <numpy.lib.index_tricks.nd_grid object at 0x104e05d50>, 'r_': <numpy.lib.index_tricks.RClass object at 0x104e05dd0>, 'hanning': <function hanning at 0x104e00c80>, 'connect': <function connect at 0x109d19230>, 'allclose': <function allclose at 0x104d5d848>, 'extract': <function extract at 0x104e00758>, 'exponential': <built-in method exponential of mtrand.RandomState object at 0x104ee18d0>, 'asarray': <function asarray at 0x104d40c08>, 'fftn': <function fftn at 0x104e77b90>, 'IndexLocator': <class 'matplotlib.ticker.IndexLocator'>, 'poly1d': <class 'numpy.lib.polynomial.poly1d'>, 'pivoted':      period  72_out  79_out  82_out  83_out  116_out  119_out  120_out  \\\n",
      "0         0       0       0       0       0        0        0        0   \n",
      "1         1       0       0       0       0        0        0        0   \n",
      "2         2       0       0       0       0        0        0        0   \n",
      "3         3       0       0       0       0        0        0        0   \n",
      "4         4       0       0       0       0        0        0        0   \n",
      "5         5       0       0       0       0        0        0        0   \n",
      "6         6       0       0       0       0        0        0        0   \n",
      "7         7       0       0       0       1        0        0        0   \n",
      "8         8       0       0       0       0        1        0        0   \n",
      "9         9       0       0       0       0        1        0        0   \n",
      "10       10       0       0       0       0        0        0        0   \n",
      "11       11       1       0       0       0        1        0        0   \n",
      "12       12       0       0       0       0        0        0        0   \n",
      "13       13       0       0       0       0        0        0        0   \n",
      "14       14       0       0       0       0        0        0        0   \n",
      "15       15       0       0       0       0        0        0        0   \n",
      "16       16       0       0       0       0        0        0        0   \n",
      "17       17       0       0       0       0        0        0        0   \n",
      "18       18       0       0       0       0        0        0        0   \n",
      "19       19       0       0       0       0        0        0        0   \n",
      "20       20       0       0       0       0        0        0        0   \n",
      "21       21       0       0       0       0        1        0        0   \n",
      "22       22       0       0       0       0        0        0        0   \n",
      "23       23       0       0       0       0        0        0        0   \n",
      "24       24       0       0       0       0        1        0        0   \n",
      "25       25       0       0       0       0        0        0        0   \n",
      "26       26       0       0       0       0        0        0        0   \n",
      "27       27       0       0       0       0        0        0        0   \n",
      "28       28       0       0       0       0        0        0        0   \n",
      "29       29       0       0       0       0        0        0        0   \n",
      "..      ...     ...     ...     ...     ...      ...      ...      ...   \n",
      "110     110       0       1       1       0        2        0        0   \n",
      "111     111       3       1       0       0        2        0        0   \n",
      "112     112       0       1       1       0        2        1        0   \n",
      "113     113       0       0       0       0        0        0        0   \n",
      "114     114       0       0       0       0        0        0        0   \n",
      "115     115       0       0       0       0        0        0        0   \n",
      "116     116       0       0       0       0        0        0        0   \n",
      "117     117       0       0       0       0        0        0        0   \n",
      "118     118       0       0       0       0        0        0        0   \n",
      "119     120       0       0       0       0        0        0        0   \n",
      "120     123       0       0       0       0        0        0        0   \n",
      "121     125       0       0       0       0        0        0        0   \n",
      "122     126       0       0       0       0        0        0        0   \n",
      "123     132       0       0       0       0        0        0        0   \n",
      "124     133       0       0       0       0        0        0        0   \n",
      "125     136       0       0       0       0        0        0        0   \n",
      "126     137       0       0       0       0        0        0        0   \n",
      "127     141       0       0       0       0        0        0        0   \n",
      "128     147       0       0       0       0        0        0        0   \n",
      "129     149       0       0       0       0        0        0        0   \n",
      "130     151       0       0       0       0        0        0        0   \n",
      "131     156       0       0       0       0        0        0        0   \n",
      "132     203       0       0       0       0        0        0        0   \n",
      "133     210       0       0       0       0        0        0        0   \n",
      "134     211       0       0       0       0        0        0        0   \n",
      "135     212       0       0       0       0        0        0        0   \n",
      "136     222       0       0       0       0        0        0        0   \n",
      "137     226       0       0       0       0        0        0        0   \n",
      "138     228       0       0       0       0        0        0        0   \n",
      "139     417       0       0       0       0        0        0        0   \n",
      "\n",
      "     127_out  128_out   ...     3129_in  3130_in  3133_in  3158_in  3163_in  \\\n",
      "0          0        0   ...           0        0        0        0        0   \n",
      "1          0        0   ...           0        0        0        0        0   \n",
      "2          0        0   ...           0        0        0        0        0   \n",
      "3          0        0   ...           0        0        0        0        0   \n",
      "4          1        1   ...           0        0        0        0        0   \n",
      "5          0        1   ...           0        0        0        0        0   \n",
      "6          0        0   ...           0        0        0        0        0   \n",
      "7          0        0   ...           0        0        0        0        0   \n",
      "8          0        0   ...           0        0        0        0        0   \n",
      "9          0        0   ...           0        0        1        0        0   \n",
      "10         0        0   ...           0        0        0        0        0   \n",
      "11         0        0   ...           0        0        0        0        0   \n",
      "12         0        0   ...           0        0        0        0        0   \n",
      "13         0        0   ...           0        1        0        0        0   \n",
      "14         0        0   ...           0        0        0        0        0   \n",
      "15         0        0   ...           0        0        0        1        0   \n",
      "16         1        0   ...           0        0        0        0        0   \n",
      "17         0        0   ...           0        0        0        0        0   \n",
      "18         0        0   ...           0        0        0        0        0   \n",
      "19         0        0   ...           0        0        0        0        0   \n",
      "20         0        0   ...           0        0        0        0        0   \n",
      "21         0        0   ...           0        0        0        0        0   \n",
      "22         0        0   ...           0        0        0        0        0   \n",
      "23         0        0   ...           0        0        0        0        0   \n",
      "24         0        0   ...           0        0        0        0        0   \n",
      "25         0        0   ...           0        0        0        0        0   \n",
      "26         0        0   ...           0        0        0        0        0   \n",
      "27         0        0   ...           0        1        0        0        0   \n",
      "28         0        0   ...           0        0        0        0        0   \n",
      "29         0        0   ...           0        0        0        0        0   \n",
      "..       ...      ...   ...         ...      ...      ...      ...      ...   \n",
      "110        2        4   ...           0        0        0        0        0   \n",
      "111        7        6   ...           0        0        0        0        0   \n",
      "112        2        1   ...           1        0        2        0        0   \n",
      "113        0        0   ...           0        0        0        0        0   \n",
      "114        0        0   ...           0        0        0        0        0   \n",
      "115        0        0   ...           0        0        0        0        0   \n",
      "116        0        0   ...           0        0        0        0        0   \n",
      "117        0        0   ...           0        0        1        0        0   \n",
      "118        0        0   ...           0        0        0        0        0   \n",
      "119        0        0   ...           0        0        0        0        0   \n",
      "120        0        0   ...           0        0        0        0        0   \n",
      "121        0        0   ...           0        0        0        0        0   \n",
      "122        0        0   ...           0        0        0        0        0   \n",
      "123        0        0   ...           0        0        0        0        0   \n",
      "124        0        0   ...           0        0        0        0        0   \n",
      "125        0        0   ...           0        0        0        0        0   \n",
      "126        0        0   ...           0        0        0        0        0   \n",
      "127        0        0   ...           0        0        0        0        0   \n",
      "128        0        0   ...           0        0        0        0        0   \n",
      "129        0        0   ...           0        0        0        0        0   \n",
      "130        0        0   ...           0        0        0        0        0   \n",
      "131        0        0   ...           0        0        0        0        0   \n",
      "132        0        0   ...           0        0        0        0        0   \n",
      "133        0        0   ...           0        0        0        0        0   \n",
      "134        0        0   ...           0        0        0        0        0   \n",
      "135        0        0   ...           0        0        0        0        0   \n",
      "136        0        0   ...           0        0        0        0        0   \n",
      "137        0        0   ...           0        0        0        0        0   \n",
      "138        0        0   ...           0        0        0        0        0   \n",
      "139        0        0   ...           0        0        0        0        0   \n",
      "\n",
      "     3180_in  3182_in  3222_in  3223_in  3224_in  \n",
      "0          0        0        0        0        0  \n",
      "1          0        0        0        0        0  \n",
      "2          0        0        0        1        0  \n",
      "3          0        0        0        0        0  \n",
      "4          0        0        0        0        0  \n",
      "5          0        0        0        0        0  \n",
      "6          0        0        0        0        0  \n",
      "7          0        0        0        0        0  \n",
      "8          0        0        0        0        0  \n",
      "9          0        0        0        0        3  \n",
      "10         0        0        0        0        0  \n",
      "11         0        0        1        0        0  \n",
      "12         0        0        0        0        0  \n",
      "13         0        0        0        0        0  \n",
      "14         0        0        0        0        0  \n",
      "15         0        0        0        0        0  \n",
      "16         0        0        0        0        0  \n",
      "17         0        0        0        0        0  \n",
      "18         0        0        0        0        0  \n",
      "19         0        0        0        0        0  \n",
      "20         0        0        0        0        0  \n",
      "21         0        0        0        0        0  \n",
      "22         0        0        0        0        0  \n",
      "23         0        0        0        0        0  \n",
      "24         0        0        0        0        0  \n",
      "25         0        0        0        0        0  \n",
      "26         0        0        0        0        0  \n",
      "27         0        0        0        0        0  \n",
      "28         0        0        0        0        0  \n",
      "29         0        0        0        0        0  \n",
      "..       ...      ...      ...      ...      ...  \n",
      "110        0        0        0        0        2  \n",
      "111        0        0        0        1        1  \n",
      "112        0        0        0        0        1  \n",
      "113        0        0        0        2        1  \n",
      "114        0        0        0        0        2  \n",
      "115        0        0        0        0        0  \n",
      "116        0        0        0        2        0  \n",
      "117        0        0        0        0        0  \n",
      "118        0        0        0        0        0  \n",
      "119        0        0        0        0        0  \n",
      "120        0        0        0        0        0  \n",
      "121        0        0        0        0        0  \n",
      "122        0        0        0        0        0  \n",
      "123        0        0        0        0        0  \n",
      "124        0        0        0        0        0  \n",
      "125        0        0        0        0        0  \n",
      "126        0        0        0        0        0  \n",
      "127        0        0        0        0        0  \n",
      "128        0        0        0        0        0  \n",
      "129        0        0        0        0        0  \n",
      "130        0        0        0        0        0  \n",
      "131        0        0        0        0        0  \n",
      "132        0        0        0        0        0  \n",
      "133        0        0        0        0        0  \n",
      "134        0        0        0        0        0  \n",
      "135        0        0        0        0        0  \n",
      "136        0        0        0        0        0  \n",
      "137        0        0        0        0        0  \n",
      "138        0        0        0        0        0  \n",
      "139        0        0        0        0        0  \n",
      "\n",
      "[140 rows x 815 columns], 'promote_types': <built-in function promote_types>, 'plotting': <function plotting at 0x109d205f0>, 'log2': <ufunc 'log2'>, 'acorr': <function acorr at 0x109d20d70>, 'vstack': <function vstack at 0x104d80140>, 'column_stack': <function column_stack at 0x104e13b90>, 'put': <function put at 0x104d5a1b8>, 'Line2D': <class 'matplotlib.lines.Line2D'>, '_i19': u'counts = [10, 20, 40, 100]\\naccs = []\\nfor tc in counts:\\n    print \"{} trees\".format(tc)\\n    accs.append(analyze(10000, tree_count=tc))\\n    print \"\\\\n\"\\nplt.plot(counts, accs)', 'row_stack': <function vstack at 0x104d80140>, 'ion': <function ion at 0x109d1caa0>, 'figaspect': <function figaspect at 0x109d0ca28>, 'semilogx': <function semilogx at 0x109d47050>, 'semilogy': <function semilogy at 0x109d470c8>, 'ndfromtxt': <function ndfromtxt at 0x104e755f0>, 'newaxis': None, 'arccos': <ufunc 'arccos'>, 'signedinteger': <type 'numpy.signedinteger'>, 'rand': <built-in method rand of mtrand.RandomState object at 0x104ee18d0>, 'ranf': <built-in method random_sample of mtrand.RandomState object at 0x104ee18d0>, 'fill_between': <function fill_between at 0x109d466e0>, 'Axes': <class 'matplotlib.axes._axes.Axes'>, 'MaxNLocator': <class 'matplotlib.ticker.MaxNLocator'>, 'rank': <function rank at 0x104d5c230>, 'ldexp': <ufunc 'ldexp'>, 'lognormal': <built-in method lognormal of mtrand.RandomState object at 0x104ee18d0>, 'lookfor': <function lookfor at 0x104df9848>, '_22': [<matplotlib.lines.Line2D object at 0x10b7515d0>], 'geterrcall': <function geterrcall at 0x104d5dc80>, 'jet': <function jet at 0x109d49050>, 'exp2': <ufunc 'exp2'>, 'axhline': <function axhline at 0x109d20ed8>, 'zeros': <built-in function zeros>, 'identity': <function identity at 0x104d5d7d0>, 'False_': False, 'logspace': <function logspace at 0x104d75758>, 'start_time_group_by': 0    2015-09-01 00:00:00   2015-09-01 00:00:00\n",
      "     2015-09-01 00:00:00   2015-09-01 00:00:00\n",
      "     2015-09-01 00:00:01   2015-09-01 00:00:01\n",
      "     2015-09-01 00:00:07   2015-09-01 00:00:07\n",
      "     2015-09-01 00:00:09   2015-09-01 00:00:09\n",
      "     2015-09-01 00:00:13   2015-09-01 00:00:13\n",
      "     2015-09-01 00:00:49   2015-09-01 00:00:49\n",
      "     2015-09-01 00:00:49   2015-09-01 00:00:49\n",
      "     2015-09-01 00:00:53   2015-09-01 00:00:53\n",
      "     2015-09-01 00:00:55   2015-09-01 00:00:55\n",
      "     2015-09-01 00:01:05   2015-09-01 00:01:05\n",
      "     2015-09-01 00:01:06   2015-09-01 00:01:06\n",
      "     2015-09-01 00:01:37   2015-09-01 00:01:37\n",
      "     2015-09-01 00:01:51   2015-09-01 00:01:51\n",
      "     2015-09-01 00:02:01   2015-09-01 00:02:01\n",
      "     2015-09-01 00:02:09   2015-09-01 00:02:09\n",
      "     2015-09-01 00:02:10   2015-09-01 00:02:10\n",
      "     2015-09-01 00:02:10   2015-09-01 00:02:10\n",
      "     2015-09-01 00:02:36   2015-09-01 00:02:36\n",
      "     2015-09-01 00:02:36   2015-09-01 00:02:36\n",
      "     2015-09-01 00:02:50   2015-09-01 00:02:50\n",
      "     2015-09-01 00:03:01   2015-09-01 00:03:01\n",
      "     2015-09-01 00:03:08   2015-09-01 00:03:08\n",
      "     2015-09-01 00:03:20   2015-09-01 00:03:20\n",
      "     2015-09-01 00:03:21   2015-09-01 00:03:21\n",
      "     2015-09-01 00:03:25   2015-09-01 00:03:25\n",
      "     2015-09-01 00:03:26   2015-09-01 00:03:26\n",
      "     2015-09-01 00:04:20   2015-09-01 00:04:20\n",
      "     2015-09-01 00:04:21   2015-09-01 00:04:21\n",
      "     2015-09-01 00:04:24   2015-09-01 00:04:24\n",
      "                                   ...        \n",
      "112  2015-09-01 09:21:44   2015-09-01 09:21:44\n",
      "     2015-09-01 09:21:44   2015-09-01 09:21:44\n",
      "     2015-09-01 09:21:46   2015-09-01 09:21:46\n",
      "     2015-09-01 09:21:47   2015-09-01 09:21:47\n",
      "     2015-09-01 09:21:48   2015-09-01 09:21:48\n",
      "     2015-09-01 09:21:49   2015-09-01 09:21:49\n",
      "     2015-09-01 09:21:51   2015-09-01 09:21:51\n",
      "     2015-09-01 09:21:53   2015-09-01 09:21:53\n",
      "     2015-09-01 09:21:54   2015-09-01 09:21:54\n",
      "     2015-09-01 09:21:59   2015-09-01 09:21:59\n",
      "     2015-09-01 09:22:00   2015-09-01 09:22:00\n",
      "     2015-09-01 09:22:02   2015-09-01 09:22:02\n",
      "     2015-09-01 09:22:03   2015-09-01 09:22:03\n",
      "     2015-09-01 09:22:04   2015-09-01 09:22:04\n",
      "     2015-09-01 09:22:06   2015-09-01 09:22:06\n",
      "     2015-09-01 09:22:07   2015-09-01 09:22:07\n",
      "     2015-09-01 09:22:07   2015-09-01 09:22:07\n",
      "     2015-09-01 09:22:07   2015-09-01 09:22:07\n",
      "     2015-09-01 09:22:09   2015-09-01 09:22:09\n",
      "     2015-09-01 09:22:13   2015-09-01 09:22:13\n",
      "     2015-09-01 09:22:14   2015-09-01 09:22:14\n",
      "     2015-09-01 09:22:15   2015-09-01 09:22:15\n",
      "     2015-09-01 09:22:15   2015-09-01 09:22:15\n",
      "     2015-09-01 09:22:16   2015-09-01 09:22:16\n",
      "     2015-09-01 09:22:16   2015-09-01 09:22:16\n",
      "     2015-09-01 09:22:16   2015-09-01 09:22:16\n",
      "     2015-09-01 09:22:17   2015-09-01 09:22:17\n",
      "     2015-09-01 09:22:22   2015-09-01 09:22:22\n",
      "     2015-09-01 09:22:22   2015-09-01 09:22:22\n",
      "     2015-09-01 09:22:24   2015-09-01 09:22:24\n",
      "Name: starttime, dtype: datetime64[ns], '_40': 0          False\n",
      "1          False\n",
      "2          False\n",
      "3          False\n",
      "4          False\n",
      "5          False\n",
      "6          False\n",
      "7          False\n",
      "8          False\n",
      "9          False\n",
      "10         False\n",
      "11         False\n",
      "12         False\n",
      "13         False\n",
      "14         False\n",
      "15         False\n",
      "16         False\n",
      "17         False\n",
      "18         False\n",
      "19         False\n",
      "20         False\n",
      "21         False\n",
      "22         False\n",
      "23         False\n",
      "24         False\n",
      "25         False\n",
      "26         False\n",
      "27         False\n",
      "28         False\n",
      "29         False\n",
      "           ...  \n",
      "3554391    False\n",
      "3554392    False\n",
      "3554393    False\n",
      "3554394    False\n",
      "3554395    False\n",
      "3554396    False\n",
      "3554397    False\n",
      "3554398    False\n",
      "3554399    False\n",
      "3554400    False\n",
      "3554401    False\n",
      "3554402    False\n",
      "3554403    False\n",
      "3554404    False\n",
      "3554405    False\n",
      "3554406    False\n",
      "3554407    False\n",
      "3554408    False\n",
      "3554409    False\n",
      "3554410    False\n",
      "3554411    False\n",
      "3554412    False\n",
      "3554413    False\n",
      "3554414    False\n",
      "3554415    False\n",
      "3554416    False\n",
      "3554417    False\n",
      "3554418    False\n",
      "3554419    False\n",
      "3554420    False\n",
      "Name: starttime, dtype: bool, '_41': 0          False\n",
      "1          False\n",
      "2          False\n",
      "3          False\n",
      "4          False\n",
      "5          False\n",
      "6          False\n",
      "7          False\n",
      "8          False\n",
      "9          False\n",
      "10         False\n",
      "11         False\n",
      "12         False\n",
      "13         False\n",
      "14         False\n",
      "15         False\n",
      "16         False\n",
      "17         False\n",
      "18         False\n",
      "19         False\n",
      "20         False\n",
      "21         False\n",
      "22         False\n",
      "23         False\n",
      "24         False\n",
      "25         False\n",
      "26         False\n",
      "27         False\n",
      "28         False\n",
      "29         False\n",
      "           ...  \n",
      "3554391    False\n",
      "3554392    False\n",
      "3554393    False\n",
      "3554394    False\n",
      "3554395    False\n",
      "3554396    False\n",
      "3554397    False\n",
      "3554398    False\n",
      "3554399    False\n",
      "3554400    False\n",
      "3554401    False\n",
      "3554402    False\n",
      "3554403    False\n",
      "3554404    False\n",
      "3554405    False\n",
      "3554406    False\n",
      "3554407    False\n",
      "3554408    False\n",
      "3554409    False\n",
      "3554410    False\n",
      "3554411    False\n",
      "3554412    False\n",
      "3554413    False\n",
      "3554414    False\n",
      "3554415    False\n",
      "3554416    False\n",
      "3554417    False\n",
      "3554418    False\n",
      "3554419    False\n",
      "3554420    False\n",
      "Name: starttime, dtype: bool, '_42': Empty DataFrame\n",
      "Columns: [starttime, stoptime, start station id, end station id]\n",
      "Index: [], '_43': Empty DataFrame\n",
      "Columns: [starttime, stoptime, start station id, end station id]\n",
      "Index: [], 'inexact': <type 'numpy.inexact'>, 'distances_along_curve': <function distances_along_curve at 0x10a99fe60>, 'copyto': <built-in function copyto>, 'locator_params': <function locator_params at 0x109d47aa0>, 'cosh': <ufunc 'cosh'>, 'std': <function std at 0x104d5c488>, 'pcolor': <function pcolor at 0x109d46b18>, 'fromfunction': <function fromfunction at 0x104d5d500>, 'imshow': <function imshow at 0x109d469b0>, 'rate': <function rate at 0x104e75938>, 'triplot': <function triplot at 0x109d47500>, 'nested_iters': <built-in function nested_iters>, 'interactive': <function interactive at 0x105a527d0>, 'subplot': <function subplot at 0x109d19aa0>, 'tripcolor': <function tripcolor at 0x109d47488>, '_i27': u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\n\\ndef analyze(row_limit, threshold_out=1, tree_count=10, period_minutes=5, k_folds=5):\\n    \"\"\"\\n    We can tune the following parameters:\\n    - number of rows we analyze\\n    - number of folds in our standard k-fold cross-validation\\n    - number of bicycles taken out in the period to be considered in the positive class\\n    - number of trees in our random forest\\n    - number of minutes in our period\\n    \"\"\"\\n    start = time.time()\\n    df = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=row_limit)\\n    # Convert to timestamps \\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\n    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n    # Convert int64index to datetime index\\n    # Group using timegrouper and create new column for start period and stop period\\n    df = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\n    start_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\n    df[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\n    df = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\n    stop_time_group_by = df.groupby(pd.TimeGrouper(\\'{}Min\\'.format(period_minutes)),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\n    df[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n    # Create two sub dataframes, grouping on and aggregating start data and then stop data\\n    grouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\n    df_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\n    df_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\n    grouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\n    df_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\n    df_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n    # Combine these two dataframes and fill N/A values to 0\\n    df_combined = pd.concat([df_start, df_stop])\\n    df_combined = df_combined.fillna(0)\\n\\n    # Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n    # And reset the multi-level index so we have a normal DataFrame\\n    aggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n    # Let\\'s construct a pivot table\\n    pivoted = pd.pivot_table(\\n        aggregate_data,\\n        index=[\"period\"],\\n        columns=[\"station_id\"],\\n        aggfunc=np.sum,\\n        fill_value=0)\\n\\n    # Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\n    deeper_cols = pivoted.columns.get_level_values(1)\\n    top_level_cols = pivoted.columns.get_level_values(0)\\n\\n    # Flattening the columns\\n    resultant_cols = []    \\n    for i, station_id in enumerate(deeper_cols):\\n        if top_level_cols[i] == \"start_count\":\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n        else:\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\n    pivoted.columns = resultant_cols\\n    pivoted = pivoted.reset_index()\\n    print \"{} rows in the pivoted table\".format(len(pivoted))\\n    X = pivoted.copy()\\n    # Turn number of out in station TARGET_STATION_ID into 1s and 0s\\n    answer_series = (\\n        pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > threshold_out).apply(int)\\n    X = X[:-1]\\n    y = answer_series[1:]\\n\\n    classifier = RandomForestClassifier(n_estimators=tree_count)\\n    scores = cross_validation.cross_val_score(\\n        classifier,\\n        X,\\n        y,\\n        cv=k_folds\\n    )\\n\\n    end = time.time()\\n    mean_accuracy = np.mean(scores)\\n    print \"Rows: {}, k={}\".format(row_limit, k_folds)\\n    print \"Mean accuracy: {}\".format(mean_accuracy)\\n    print \"Standard deviation: {}\".format(np.std(scores))\\n    print \"Took {}s\".format(end - start)\\n    return mean_accuracy', 'isinteractive': <function isinteractive at 0x109d1c9b0>, 'eigvals': <function eigvals at 0x104e23140>, 'seed': <built-in method seed of mtrand.RandomState object at 0x104ee18d0>, 'triu_indices_from': <function triu_indices_from at 0x104de9cf8>, 'conjugate': <ufunc 'conjugate'>, 'alterdot': <function alterdot at 0x104d40578>, 'polyval': <function polyval at 0x104e2c668>, 'polydiv': <function polydiv at 0x104e2c848>, 'randint': <built-in method randint of mtrand.RandomState object at 0x104ee18d0>, 'solve': <function solve at 0x104e23398>, 'FixedFormatter': <class 'matplotlib.ticker.FixedFormatter'>, 'broadcast_to': <function broadcast_to at 0x104e0cf50>, 'boxplot': <function boxplot at 0x109d462a8>, 'spectral': <function spectral at 0x109d49320>, 'Artist': <class 'matplotlib.artist.Artist'>, 'Button': <class 'matplotlib.widgets.Button'>, 'rcParams': RcParams({u'agg.path.chunksize': 0,\n",
      "          u'animation.avconv_args': [],\n",
      "          u'animation.avconv_path': u'avconv',\n",
      "          u'animation.bitrate': -1,\n",
      "          u'animation.codec': u'mpeg4',\n",
      "          u'animation.convert_args': [],\n",
      "          u'animation.convert_path': u'convert',\n",
      "          u'animation.ffmpeg_args': [],\n",
      "          u'animation.ffmpeg_path': u'ffmpeg',\n",
      "          u'animation.frame_format': u'png',\n",
      "          u'animation.mencoder_args': [],\n",
      "          u'animation.mencoder_path': u'mencoder',\n",
      "          u'animation.writer': u'ffmpeg',\n",
      "          u'axes.axisbelow': False,\n",
      "          u'axes.color_cycle': [u'b', u'g', u'r', u'c', u'm', u'y', u'k'],\n",
      "          u'axes.edgecolor': u'k',\n",
      "          u'axes.facecolor': u'w',\n",
      "          u'axes.formatter.limits': [-7, 7],\n",
      "          u'axes.formatter.use_locale': False,\n",
      "          u'axes.formatter.use_mathtext': False,\n",
      "          u'axes.formatter.useoffset': True,\n",
      "          u'axes.grid': False,\n",
      "          u'axes.grid.which': u'major',\n",
      "          u'axes.hold': True,\n",
      "          u'axes.labelcolor': u'k',\n",
      "          u'axes.labelsize': u'medium',\n",
      "          u'axes.labelweight': u'normal',\n",
      "          u'axes.linewidth': 1.0,\n",
      "          u'axes.titlesize': u'large',\n",
      "          u'axes.titleweight': u'normal',\n",
      "          u'axes.unicode_minus': True,\n",
      "          u'axes.xmargin': 0.0,\n",
      "          u'axes.ymargin': 0.0,\n",
      "          u'axes3d.grid': True,\n",
      "          u'backend': 'module://ipykernel.pylab.backend_inline',\n",
      "          u'backend.qt4': u'PyQt4',\n",
      "          u'backend.qt5': u'PyQt5',\n",
      "          u'backend_fallback': True,\n",
      "          u'contour.negative_linestyle': u'dashed',\n",
      "          u'datapath': u'/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/matplotlib/mpl-data',\n",
      "          u'docstring.hardcopy': False,\n",
      "          u'examples.directory': u'',\n",
      "          u'figure.autolayout': False,\n",
      "          u'figure.dpi': 80.0,\n",
      "          u'figure.edgecolor': (1, 1, 1, 0),\n",
      "          u'figure.facecolor': (1, 1, 1, 0),\n",
      "          u'figure.figsize': [6.0, 4.0],\n",
      "          u'figure.frameon': True,\n",
      "          u'figure.max_open_warning': 20,\n",
      "          u'figure.subplot.bottom': 0.125,\n",
      "          u'figure.subplot.hspace': 0.2,\n",
      "          u'figure.subplot.left': 0.125,\n",
      "          u'figure.subplot.right': 0.9,\n",
      "          u'figure.subplot.top': 0.9,\n",
      "          u'figure.subplot.wspace': 0.2,\n",
      "          u'font.cursive': [u'Apple Chancery',\n",
      "                            u'Textile',\n",
      "                            u'Zapf Chancery',\n",
      "                            u'Sand',\n",
      "                            u'cursive'],\n",
      "          u'font.family': [u'sans-serif'],\n",
      "          u'font.fantasy': [u'Comic Sans MS',\n",
      "                            u'Chicago',\n",
      "                            u'Charcoal',\n",
      "                            u'ImpactWestern',\n",
      "                            u'fantasy'],\n",
      "          u'font.monospace': [u'Bitstream Vera Sans Mono',\n",
      "                              u'DejaVu Sans Mono',\n",
      "                              u'Andale Mono',\n",
      "                              u'Nimbus Mono L',\n",
      "                              u'Courier New',\n",
      "                              u'Courier',\n",
      "                              u'Fixed',\n",
      "                              u'Terminal',\n",
      "                              u'monospace'],\n",
      "          u'font.sans-serif': [u'Bitstream Vera Sans',\n",
      "                               u'DejaVu Sans',\n",
      "                               u'Lucida Grande',\n",
      "                               u'Verdana',\n",
      "                               u'Geneva',\n",
      "                               u'Lucid',\n",
      "                               u'Arial',\n",
      "                               u'Helvetica',\n",
      "                               u'Avant Garde',\n",
      "                               u'sans-serif'],\n",
      "          u'font.serif': [u'Bitstream Vera Serif',\n",
      "                          u'DejaVu Serif',\n",
      "                          u'New Century Schoolbook',\n",
      "                          u'Century Schoolbook L',\n",
      "                          u'Utopia',\n",
      "                          u'ITC Bookman',\n",
      "                          u'Bookman',\n",
      "                          u'Nimbus Roman No9 L',\n",
      "                          u'Times New Roman',\n",
      "                          u'Times',\n",
      "                          u'Palatino',\n",
      "                          u'Charter',\n",
      "                          u'serif'],\n",
      "          u'font.size': 10.0,\n",
      "          u'font.stretch': u'normal',\n",
      "          u'font.style': u'normal',\n",
      "          u'font.variant': u'normal',\n",
      "          u'font.weight': u'normal',\n",
      "          u'grid.alpha': 1.0,\n",
      "          u'grid.color': u'k',\n",
      "          u'grid.linestyle': u':',\n",
      "          u'grid.linewidth': 0.5,\n",
      "          u'image.aspect': u'equal',\n",
      "          u'image.cmap': u'jet',\n",
      "          u'image.interpolation': u'bilinear',\n",
      "          u'image.lut': 256,\n",
      "          u'image.origin': u'upper',\n",
      "          u'image.resample': False,\n",
      "          u'interactive': True,\n",
      "          u'keymap.all_axes': [u'a'],\n",
      "          u'keymap.back': [u'left', u'c', u'backspace'],\n",
      "          u'keymap.forward': [u'right', u'v'],\n",
      "          u'keymap.fullscreen': [u'f', u'ctrl+f'],\n",
      "          u'keymap.grid': [u'g'],\n",
      "          u'keymap.home': [u'h', u'r', u'home'],\n",
      "          u'keymap.pan': [u'p'],\n",
      "          u'keymap.quit': [u'ctrl+w', u'cmd+w'],\n",
      "          u'keymap.save': [u's', u'ctrl+s'],\n",
      "          u'keymap.xscale': [u'k', u'L'],\n",
      "          u'keymap.yscale': [u'l'],\n",
      "          u'keymap.zoom': [u'o'],\n",
      "          u'legend.borderaxespad': 0.5,\n",
      "          u'legend.borderpad': 0.4,\n",
      "          u'legend.columnspacing': 2.0,\n",
      "          u'legend.fancybox': False,\n",
      "          u'legend.fontsize': u'large',\n",
      "          u'legend.framealpha': None,\n",
      "          u'legend.frameon': True,\n",
      "          u'legend.handleheight': 0.7,\n",
      "          u'legend.handlelength': 2.0,\n",
      "          u'legend.handletextpad': 0.8,\n",
      "          u'legend.isaxes': True,\n",
      "          u'legend.labelspacing': 0.5,\n",
      "          u'legend.loc': u'upper right',\n",
      "          u'legend.markerscale': 1.0,\n",
      "          u'legend.numpoints': 2,\n",
      "          u'legend.scatterpoints': 3,\n",
      "          u'legend.shadow': False,\n",
      "          u'lines.antialiased': True,\n",
      "          u'lines.color': u'b',\n",
      "          u'lines.dash_capstyle': u'butt',\n",
      "          u'lines.dash_joinstyle': u'round',\n",
      "          u'lines.linestyle': u'-',\n",
      "          u'lines.linewidth': 1.0,\n",
      "          u'lines.marker': u'None',\n",
      "          u'lines.markeredgewidth': 0.5,\n",
      "          u'lines.markersize': 6.0,\n",
      "          u'lines.solid_capstyle': u'projecting',\n",
      "          u'lines.solid_joinstyle': u'round',\n",
      "          u'mathtext.bf': u'serif:bold',\n",
      "          u'mathtext.cal': u'cursive',\n",
      "          u'mathtext.default': u'it',\n",
      "          u'mathtext.fallback_to_cm': True,\n",
      "          u'mathtext.fontset': u'cm',\n",
      "          u'mathtext.it': u'serif:italic',\n",
      "          u'mathtext.rm': u'serif',\n",
      "          u'mathtext.sf': u'sans\\\\-serif',\n",
      "          u'mathtext.tt': u'monospace',\n",
      "          u'nbagg.transparent': True,\n",
      "          u'patch.antialiased': True,\n",
      "          u'patch.edgecolor': u'k',\n",
      "          u'patch.facecolor': u'b',\n",
      "          u'patch.linewidth': 1.0,\n",
      "          u'path.effects': [],\n",
      "          u'path.simplify': True,\n",
      "          u'path.simplify_threshold': 0.1111111111111111,\n",
      "          u'path.sketch': None,\n",
      "          u'path.snap': True,\n",
      "          u'pdf.compression': 6,\n",
      "          u'pdf.fonttype': 3,\n",
      "          u'pdf.inheritcolor': False,\n",
      "          u'pdf.use14corefonts': False,\n",
      "          u'pgf.debug': False,\n",
      "          u'pgf.preamble': [],\n",
      "          u'pgf.rcfonts': True,\n",
      "          u'pgf.texsystem': u'xelatex',\n",
      "          u'plugins.directory': u'.matplotlib_plugins',\n",
      "          u'polaraxes.grid': True,\n",
      "          u'ps.distiller.res': 6000,\n",
      "          u'ps.fonttype': 3,\n",
      "          u'ps.papersize': u'letter',\n",
      "          u'ps.useafm': False,\n",
      "          u'ps.usedistiller': False,\n",
      "          u'savefig.bbox': None,\n",
      "          u'savefig.directory': u'~',\n",
      "          u'savefig.dpi': 72.0,\n",
      "          u'savefig.edgecolor': u'w',\n",
      "          u'savefig.facecolor': u'w',\n",
      "          u'savefig.format': u'png',\n",
      "          u'savefig.frameon': True,\n",
      "          u'savefig.jpeg_quality': 95,\n",
      "          u'savefig.orientation': u'portrait',\n",
      "          u'savefig.pad_inches': 0.1,\n",
      "          u'savefig.transparent': False,\n",
      "          u'svg.fonttype': u'path',\n",
      "          u'svg.image_inline': True,\n",
      "          u'svg.image_noscale': False,\n",
      "          u'text.antialiased': True,\n",
      "          u'text.color': u'k',\n",
      "          u'text.dvipnghack': None,\n",
      "          u'text.hinting': True,\n",
      "          u'text.hinting_factor': 8,\n",
      "          u'text.latex.preamble': [],\n",
      "          u'text.latex.preview': False,\n",
      "          u'text.latex.unicode': False,\n",
      "          u'text.usetex': False,\n",
      "          u'timezone': u'UTC',\n",
      "          u'tk.window_focus': False,\n",
      "          u'toolbar': u'toolbar2',\n",
      "          u'verbose.fileo': u'sys.stdout',\n",
      "          u'verbose.level': u'silent',\n",
      "          u'webagg.open_in_browser': True,\n",
      "          u'webagg.port': 8988,\n",
      "          u'webagg.port_retries': 50,\n",
      "          u'xtick.color': u'k',\n",
      "          u'xtick.direction': u'in',\n",
      "          u'xtick.labelsize': u'medium',\n",
      "          u'xtick.major.pad': 4.0,\n",
      "          u'xtick.major.size': 4.0,\n",
      "          u'xtick.major.width': 0.5,\n",
      "          u'xtick.minor.pad': 4.0,\n",
      "          u'xtick.minor.size': 2.0,\n",
      "          u'xtick.minor.width': 0.5,\n",
      "          u'ytick.color': u'k',\n",
      "          u'ytick.direction': u'in',\n",
      "          u'ytick.labelsize': u'medium',\n",
      "          u'ytick.major.pad': 4.0,\n",
      "          u'ytick.major.size': 4.0,\n",
      "          u'ytick.major.width': 0.5,\n",
      "          u'ytick.minor.pad': 4.0,\n",
      "          u'ytick.minor.size': 2.0,\n",
      "          u'ytick.minor.width': 0.5}), 'amap': <function amap at 0x1081d0de8>, 'detrend_none': <function detrend_none at 0x10a9b95f0>, 'amax': <function amax at 0x104d5aed8>, 'logical_not': <ufunc 'logical_not'>, 'partition': <function partition at 0x104d5a320>, 'nbytes': {<type 'numpy.uint8'>: 1, <type 'numpy.int8'>: 1, <type 'numpy.object_'>: 8, <type 'numpy.complex64'>: 8, <type 'numpy.float32'>: 4, <type 'numpy.uint16'>: 2, <type 'numpy.int16'>: 2, <type 'numpy.bool_'>: 1, <type 'numpy.complex128'>: 16, <type 'numpy.float64'>: 8, <type 'numpy.uint32'>: 4, <type 'numpy.int32'>: 4, <type 'numpy.string_'>: 0, <type 'numpy.complex256'>: 32, <type 'numpy.float128'>: 16, <type 'numpy.uint64'>: 8, <type 'numpy.int64'>: 8, <type 'numpy.unicode_'>: 0, <type 'numpy.datetime64'>: 8, <type 'numpy.uint64'>: 8, <type 'numpy.int64'>: 8, <type 'numpy.void'>: 0, <type 'numpy.timedelta64'>: 8, <type 'numpy.float16'>: 2}, 'exp': <ufunc 'exp'>, 'rollaxis': <function rollaxis at 0x104d40398>, 'dot': <built-in function dot>, 'longfloat': <type 'numpy.float128'>, 'rayleigh': <built-in method rayleigh of mtrand.RandomState object at 0x104ee18d0>, 'tree_counts': [40, 100, 200], 'random': <module 'numpy.random' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/numpy/random/__init__.pyc'>, 'demean': <function demean at 0x10a9b9500>, 'colors': <function colors at 0x109d206e0>, 'find': <function find at 0x1081d00c8>, 'randn': <built-in method randn of mtrand.RandomState object at 0x104ee18d0>, 'errstate': <class 'numpy.core.numeric.errstate'>, 'FPE_UNDERFLOW': 4, 'savefig': <function savefig at 0x109d19488>, 'swapaxes': <function swapaxes at 0x104d5a230>, 'UFUNC_BUFSIZE_DEFAULT': 8192, 'center_matrix': <function center_matrix at 0x1081d0578>, 'SHIFT_OVERFLOW': 3, 'infty': inf, 'plotfile': <function plotfile at 0x109d20b90>, 'df':                   starttime           stoptime start station id end station id\n",
      "0         9/1/2015 00:00:00  9/1/2015 00:04:48              263            307\n",
      "1         9/1/2015 00:00:00  9/1/2015 00:02:45              495            449\n",
      "2         9/1/2015 00:00:01  9/1/2015 00:06:08             3119           3118\n",
      "3         9/1/2015 00:00:07  9/1/2015 00:15:34              536            340\n",
      "4         9/1/2015 00:00:09  9/1/2015 00:11:07              347            483\n",
      "5         9/1/2015 00:00:13  9/1/2015 00:06:46             2004            254\n",
      "6         9/1/2015 00:00:49  9/1/2015 00:02:52              173            450\n",
      "7         9/1/2015 00:00:49  9/1/2015 00:18:41              397           3044\n",
      "8         9/1/2015 00:00:53  9/1/2015 00:03:44              536            476\n",
      "9         9/1/2015 00:00:55  9/1/2015 00:19:01              397           3044\n",
      "10        9/1/2015 00:01:05  9/1/2015 00:04:15              307            412\n",
      "11        9/1/2015 00:01:06  9/1/2015 00:13:02             3075            364\n",
      "12        9/1/2015 00:01:37  9/1/2015 00:08:56              361            356\n",
      "13        9/1/2015 00:01:51  9/1/2015 00:15:55              358            147\n",
      "14        9/1/2015 00:02:01  9/1/2015 00:16:51              410           3087\n",
      "15        9/1/2015 00:02:10  9/1/2015 00:27:24              509            494\n",
      "16        9/1/2015 00:02:09  9/1/2015 00:09:56             2003            474\n",
      "17        9/1/2015 00:02:10  9/1/2015 00:05:28              450            479\n",
      "18        9/1/2015 00:02:36  9/1/2015 00:28:15              386            386\n",
      "19        9/1/2015 00:02:36  9/1/2015 00:11:55              285            382\n",
      "20        9/1/2015 00:02:50  9/1/2015 00:12:41              479            458\n",
      "21        9/1/2015 00:03:01  9/1/2015 00:23:49             3133            334\n",
      "22        9/1/2015 00:03:08  9/1/2015 00:12:53              479            458\n",
      "23        9/1/2015 00:03:20  9/1/2015 00:28:28              386            386\n",
      "24        9/1/2015 00:03:21  9/1/2015 00:23:49             3133            334\n",
      "25        9/1/2015 00:03:25  9/1/2015 00:14:59             2021            500\n",
      "26        9/1/2015 00:03:26  9/1/2015 00:14:00              495            468\n",
      "27        9/1/2015 00:04:20  9/1/2015 00:19:06              488           3223\n",
      "28        9/1/2015 00:04:21  9/1/2015 00:07:15              316            279\n",
      "29        9/1/2015 00:04:24  9/1/2015 00:15:30              463             72\n",
      "...                     ...                ...              ...            ...\n",
      "3554391  7/31/2015 23:57:25  8/1/2015 00:01:29              521            489\n",
      "3554392  7/31/2015 23:57:29  8/1/2015 00:20:28              357            297\n",
      "3554393  7/31/2015 23:57:32  8/1/2015 00:01:22              499            449\n",
      "3554394  7/31/2015 23:57:33  8/1/2015 00:25:22              499            247\n",
      "3554395  7/31/2015 23:57:44  8/1/2015 00:05:58              368            312\n",
      "3554396  7/31/2015 23:57:54  8/1/2015 00:11:37              361            311\n",
      "3554397  7/31/2015 23:58:03  8/1/2015 00:08:20              347            458\n",
      "3554398  7/31/2015 23:58:08  8/1/2015 00:03:58              146            376\n",
      "3554399  7/31/2015 23:58:12  8/1/2015 00:11:50              459            515\n",
      "3554400  7/31/2015 23:58:15  8/1/2015 00:32:38              479            151\n",
      "3554401  7/31/2015 23:58:18  8/1/2015 00:14:04              490            252\n",
      "3554402  7/31/2015 23:58:24  8/1/2015 00:04:10              291            263\n",
      "3554403  7/31/2015 23:58:27  8/1/2015 00:05:06              507            438\n",
      "3554404  7/31/2015 23:58:42  8/1/2015 00:09:23              237            527\n",
      "3554405  7/31/2015 23:58:43  8/1/2015 00:29:55              490            513\n",
      "3554406  7/31/2015 23:58:51  8/1/2015 03:19:57             3180           3180\n",
      "3554407  7/31/2015 23:58:53  8/1/2015 00:03:19              252            435\n",
      "3554408  7/31/2015 23:58:58  8/1/2015 00:14:34              428            346\n",
      "3554409  7/31/2015 23:59:04  8/1/2015 00:05:40              312            307\n",
      "3554410  7/31/2015 23:59:10  8/1/2015 00:03:08              509            489\n",
      "3554411  7/31/2015 23:59:24  8/1/2015 00:08:36              505            463\n",
      "3554412  7/31/2015 23:59:23  8/1/2015 00:06:27              239            419\n",
      "3554413  7/31/2015 23:59:24  8/1/2015 00:26:28              534            312\n",
      "3554414  7/31/2015 23:59:24  8/1/2015 00:26:37              534            312\n",
      "3554415  7/31/2015 23:59:38  8/1/2015 00:04:43              489            521\n",
      "3554416  7/31/2015 23:59:40  8/1/2015 00:04:15              383            404\n",
      "3554417  7/31/2015 23:59:41  8/1/2015 00:08:32              455            507\n",
      "3554418  7/31/2015 23:59:42  8/1/2015 00:04:15              383            404\n",
      "3554419  7/31/2015 23:59:56  8/1/2015 00:21:09              477            432\n",
      "3554420  7/31/2015 23:59:59  8/1/2015 00:27:46             2021            401\n",
      "\n",
      "[3554421 rows x 4 columns], 'grouped_by': <pandas.core.groupby.DataFrameGroupBy object at 0x108305210>, 'ceil': <ufunc 'ceil'>, 'add_newdoc_ufunc': <built-in function _add_newdoc_ufunc>, 'X':      period  72_out  79_out  82_out  83_out  116_out  119_out  120_out  \\\n",
      "0         0       0       0       0       0        0        0        0   \n",
      "1         1       0       0       0       0        0        0        0   \n",
      "2         2       0       0       0       0        0        0        0   \n",
      "3         3       0       0       0       0        0        0        0   \n",
      "4         4       0       0       0       0        0        0        0   \n",
      "5         5       0       0       0       0        0        0        0   \n",
      "6         6       0       0       0       0        0        0        0   \n",
      "7         7       0       0       0       1        0        0        0   \n",
      "8         8       0       0       0       0        1        0        0   \n",
      "9         9       0       0       0       0        1        0        0   \n",
      "10       10       0       0       0       0        0        0        0   \n",
      "11       11       1       0       0       0        1        0        0   \n",
      "12       12       0       0       0       0        0        0        0   \n",
      "13       13       0       0       0       0        0        0        0   \n",
      "14       14       0       0       0       0        0        0        0   \n",
      "15       15       0       0       0       0        0        0        0   \n",
      "16       16       0       0       0       0        0        0        0   \n",
      "17       17       0       0       0       0        0        0        0   \n",
      "18       18       0       0       0       0        0        0        0   \n",
      "19       19       0       0       0       0        0        0        0   \n",
      "20       20       0       0       0       0        0        0        0   \n",
      "21       21       0       0       0       0        1        0        0   \n",
      "22       22       0       0       0       0        0        0        0   \n",
      "23       23       0       0       0       0        0        0        0   \n",
      "24       24       0       0       0       0        1        0        0   \n",
      "25       25       0       0       0       0        0        0        0   \n",
      "26       26       0       0       0       0        0        0        0   \n",
      "27       27       0       0       0       0        0        0        0   \n",
      "28       28       0       0       0       0        0        0        0   \n",
      "29       29       0       0       0       0        0        0        0   \n",
      "..      ...     ...     ...     ...     ...      ...      ...      ...   \n",
      "109     109       1       0       0       0        2        0        0   \n",
      "110     110       0       1       1       0        2        0        0   \n",
      "111     111       3       1       0       0        2        0        0   \n",
      "112     112       0       1       1       0        2        1        0   \n",
      "113     113       0       0       0       0        0        0        0   \n",
      "114     114       0       0       0       0        0        0        0   \n",
      "115     115       0       0       0       0        0        0        0   \n",
      "116     116       0       0       0       0        0        0        0   \n",
      "117     117       0       0       0       0        0        0        0   \n",
      "118     118       0       0       0       0        0        0        0   \n",
      "119     120       0       0       0       0        0        0        0   \n",
      "120     123       0       0       0       0        0        0        0   \n",
      "121     125       0       0       0       0        0        0        0   \n",
      "122     126       0       0       0       0        0        0        0   \n",
      "123     132       0       0       0       0        0        0        0   \n",
      "124     133       0       0       0       0        0        0        0   \n",
      "125     136       0       0       0       0        0        0        0   \n",
      "126     137       0       0       0       0        0        0        0   \n",
      "127     141       0       0       0       0        0        0        0   \n",
      "128     147       0       0       0       0        0        0        0   \n",
      "129     149       0       0       0       0        0        0        0   \n",
      "130     151       0       0       0       0        0        0        0   \n",
      "131     156       0       0       0       0        0        0        0   \n",
      "132     203       0       0       0       0        0        0        0   \n",
      "133     210       0       0       0       0        0        0        0   \n",
      "134     211       0       0       0       0        0        0        0   \n",
      "135     212       0       0       0       0        0        0        0   \n",
      "136     222       0       0       0       0        0        0        0   \n",
      "137     226       0       0       0       0        0        0        0   \n",
      "138     228       0       0       0       0        0        0        0   \n",
      "\n",
      "     127_out  128_out   ...     3129_in  3130_in  3133_in  3158_in  3163_in  \\\n",
      "0          0        0   ...           0        0        0        0        0   \n",
      "1          0        0   ...           0        0        0        0        0   \n",
      "2          0        0   ...           0        0        0        0        0   \n",
      "3          0        0   ...           0        0        0        0        0   \n",
      "4          1        1   ...           0        0        0        0        0   \n",
      "5          0        1   ...           0        0        0        0        0   \n",
      "6          0        0   ...           0        0        0        0        0   \n",
      "7          0        0   ...           0        0        0        0        0   \n",
      "8          0        0   ...           0        0        0        0        0   \n",
      "9          0        0   ...           0        0        1        0        0   \n",
      "10         0        0   ...           0        0        0        0        0   \n",
      "11         0        0   ...           0        0        0        0        0   \n",
      "12         0        0   ...           0        0        0        0        0   \n",
      "13         0        0   ...           0        1        0        0        0   \n",
      "14         0        0   ...           0        0        0        0        0   \n",
      "15         0        0   ...           0        0        0        1        0   \n",
      "16         1        0   ...           0        0        0        0        0   \n",
      "17         0        0   ...           0        0        0        0        0   \n",
      "18         0        0   ...           0        0        0        0        0   \n",
      "19         0        0   ...           0        0        0        0        0   \n",
      "20         0        0   ...           0        0        0        0        0   \n",
      "21         0        0   ...           0        0        0        0        0   \n",
      "22         0        0   ...           0        0        0        0        0   \n",
      "23         0        0   ...           0        0        0        0        0   \n",
      "24         0        0   ...           0        0        0        0        0   \n",
      "25         0        0   ...           0        0        0        0        0   \n",
      "26         0        0   ...           0        0        0        0        0   \n",
      "27         0        0   ...           0        1        0        0        0   \n",
      "28         0        0   ...           0        0        0        0        0   \n",
      "29         0        0   ...           0        0        0        0        0   \n",
      "..       ...      ...   ...         ...      ...      ...      ...      ...   \n",
      "109        1        2   ...           0        0        3        0        1   \n",
      "110        2        4   ...           0        0        0        0        0   \n",
      "111        7        6   ...           0        0        0        0        0   \n",
      "112        2        1   ...           1        0        2        0        0   \n",
      "113        0        0   ...           0        0        0        0        0   \n",
      "114        0        0   ...           0        0        0        0        0   \n",
      "115        0        0   ...           0        0        0        0        0   \n",
      "116        0        0   ...           0        0        0        0        0   \n",
      "117        0        0   ...           0        0        1        0        0   \n",
      "118        0        0   ...           0        0        0        0        0   \n",
      "119        0        0   ...           0        0        0        0        0   \n",
      "120        0        0   ...           0        0        0        0        0   \n",
      "121        0        0   ...           0        0        0        0        0   \n",
      "122        0        0   ...           0        0        0        0        0   \n",
      "123        0        0   ...           0        0        0        0        0   \n",
      "124        0        0   ...           0        0        0        0        0   \n",
      "125        0        0   ...           0        0        0        0        0   \n",
      "126        0        0   ...           0        0        0        0        0   \n",
      "127        0        0   ...           0        0        0        0        0   \n",
      "128        0        0   ...           0        0        0        0        0   \n",
      "129        0        0   ...           0        0        0        0        0   \n",
      "130        0        0   ...           0        0        0        0        0   \n",
      "131        0        0   ...           0        0        0        0        0   \n",
      "132        0        0   ...           0        0        0        0        0   \n",
      "133        0        0   ...           0        0        0        0        0   \n",
      "134        0        0   ...           0        0        0        0        0   \n",
      "135        0        0   ...           0        0        0        0        0   \n",
      "136        0        0   ...           0        0        0        0        0   \n",
      "137        0        0   ...           0        0        0        0        0   \n",
      "138        0        0   ...           0        0        0        0        0   \n",
      "\n",
      "     3180_in  3182_in  3222_in  3223_in  3224_in  \n",
      "0          0        0        0        0        0  \n",
      "1          0        0        0        0        0  \n",
      "2          0        0        0        1        0  \n",
      "3          0        0        0        0        0  \n",
      "4          0        0        0        0        0  \n",
      "5          0        0        0        0        0  \n",
      "6          0        0        0        0        0  \n",
      "7          0        0        0        0        0  \n",
      "8          0        0        0        0        0  \n",
      "9          0        0        0        0        3  \n",
      "10         0        0        0        0        0  \n",
      "11         0        0        1        0        0  \n",
      "12         0        0        0        0        0  \n",
      "13         0        0        0        0        0  \n",
      "14         0        0        0        0        0  \n",
      "15         0        0        0        0        0  \n",
      "16         0        0        0        0        0  \n",
      "17         0        0        0        0        0  \n",
      "18         0        0        0        0        0  \n",
      "19         0        0        0        0        0  \n",
      "20         0        0        0        0        0  \n",
      "21         0        0        0        0        0  \n",
      "22         0        0        0        0        0  \n",
      "23         0        0        0        0        0  \n",
      "24         0        0        0        0        0  \n",
      "25         0        0        0        0        0  \n",
      "26         0        0        0        0        0  \n",
      "27         0        0        0        0        0  \n",
      "28         0        0        0        0        0  \n",
      "29         0        0        0        0        0  \n",
      "..       ...      ...      ...      ...      ...  \n",
      "109        0        0        0        1        0  \n",
      "110        0        0        0        0        2  \n",
      "111        0        0        0        1        1  \n",
      "112        0        0        0        0        1  \n",
      "113        0        0        0        2        1  \n",
      "114        0        0        0        0        2  \n",
      "115        0        0        0        0        0  \n",
      "116        0        0        0        2        0  \n",
      "117        0        0        0        0        0  \n",
      "118        0        0        0        0        0  \n",
      "119        0        0        0        0        0  \n",
      "120        0        0        0        0        0  \n",
      "121        0        0        0        0        0  \n",
      "122        0        0        0        0        0  \n",
      "123        0        0        0        0        0  \n",
      "124        0        0        0        0        0  \n",
      "125        0        0        0        0        0  \n",
      "126        0        0        0        0        0  \n",
      "127        0        0        0        0        0  \n",
      "128        0        0        0        0        0  \n",
      "129        0        0        0        0        0  \n",
      "130        0        0        0        0        0  \n",
      "131        0        0        0        0        0  \n",
      "132        0        0        0        0        0  \n",
      "133        0        0        0        0        0  \n",
      "134        0        0        0        0        0  \n",
      "135        0        0        0        0        0  \n",
      "136        0        0        0        0        0  \n",
      "137        0        0        0        0        0  \n",
      "138        0        0        0        0        0  \n",
      "\n",
      "[139 rows x 815 columns], 'bar': <function bar at 0x109d46140>, 'bytes': <type 'str'>, 'geterr': <function geterr at 0x104d5daa0>, 'twiny': <function twiny at 0x109d19c80>, 'logistic': <built-in method logistic of mtrand.RandomState object at 0x104ee18d0>, 'double': <type 'numpy.float64'>, 'isreal': <function isreal at 0x104dcdd70>, 'fftsurr': <function fftsurr at 0x1081d0938>, 'minorticks_on': <function minorticks_on at 0x109d20410>, 'complex64': <type 'numpy.complex64'>, 'figimage': <function figimage at 0x109d196e0>, 'LogFormatterMathtext': <class 'matplotlib.ticker.LogFormatterMathtext'>, 'close': <function close at 0x109d191b8>, 'is_string_like': <function is_string_like at 0x105b47b18>, 'contour': <function contour at 0x109d46410>, 'rad2deg': <ufunc 'rad2deg'>, 'get_xyz_where': <function get_xyz_where at 0x1081d06e0>, 'irr': <function irr at 0x104e758c0>, 'sctypeDict': {0: <type 'numpy.bool_'>, 1: <type 'numpy.int8'>, 2: <type 'numpy.uint8'>, 3: <type 'numpy.int16'>, 4: <type 'numpy.uint16'>, 5: <type 'numpy.int32'>, 6: <type 'numpy.uint32'>, 7: <type 'numpy.int64'>, 8: <type 'numpy.uint64'>, 9: <type 'numpy.int64'>, 10: <type 'numpy.uint64'>, 11: <type 'numpy.float32'>, 12: <type 'numpy.float64'>, 13: <type 'numpy.float128'>, 14: <type 'numpy.complex64'>, 15: <type 'numpy.complex128'>, 16: <type 'numpy.complex256'>, 17: <type 'numpy.object_'>, 18: <type 'numpy.string_'>, 19: <type 'numpy.unicode_'>, 20: <type 'numpy.void'>, 21: <type 'numpy.datetime64'>, 'unicode': <type 'numpy.unicode_'>, 23: <type 'numpy.float16'>, 'cfloat': <type 'numpy.complex128'>, 'longfloat': <type 'numpy.float128'>, 'Int32': <type 'numpy.int32'>, 'Complex64': <type 'numpy.complex128'>, 'unicode_': <type 'numpy.unicode_'>, 'complex': <type 'numpy.complex128'>, 'timedelta64': <type 'numpy.timedelta64'>, 'uint16': <type 'numpy.uint16'>, 'c16': <type 'numpy.complex128'>, 'float32': <type 'numpy.float32'>, 'complex256': <type 'numpy.complex256'>, 'D': <type 'numpy.complex128'>, 'H': <type 'numpy.uint16'>, 'void': <type 'numpy.void'>, 'unicode0': <type 'numpy.unicode_'>, 'L': <type 'numpy.uint64'>, 'P': <type 'numpy.uint64'>, 'half': <type 'numpy.float16'>, 'void0': <type 'numpy.void'>, 'd': <type 'numpy.float64'>, 'h': <type 'numpy.int16'>, 'l': <type 'numpy.int64'>, 'p': <type 'numpy.int64'>, 'c32': <type 'numpy.complex256'>, 22: <type 'numpy.timedelta64'>, 'Timedelta64': <type 'numpy.timedelta64'>, 'object0': <type 'numpy.object_'>, 'b1': <type 'numpy.bool_'>, 'float128': <type 'numpy.float128'>, 'M8': <type 'numpy.datetime64'>, 'String0': <type 'numpy.string_'>, 'float16': <type 'numpy.float16'>, 'ulonglong': <type 'numpy.uint64'>, 'i1': <type 'numpy.int8'>, 'uint32': <type 'numpy.uint32'>, '?': <type 'numpy.bool_'>, 'Void0': <type 'numpy.void'>, 'complex64': <type 'numpy.complex64'>, 'G': <type 'numpy.complex256'>, 'O': <type 'numpy.object_'>, 'UInt8': <type 'numpy.uint8'>, 'S': <type 'numpy.string_'>, 'byte': <type 'numpy.int8'>, 'UInt64': <type 'numpy.uint64'>, 'g': <type 'numpy.float128'>, 'float64': <type 'numpy.float64'>, 'ushort': <type 'numpy.uint16'>, 'float_': <type 'numpy.float64'>, 'uint': <type 'numpy.uint64'>, 'object_': <type 'numpy.object_'>, 'Float16': <type 'numpy.float16'>, 'complex_': <type 'numpy.complex128'>, 'Unicode0': <type 'numpy.unicode_'>, 'uintp': <type 'numpy.uint64'>, 'intc': <type 'numpy.int32'>, 'csingle': <type 'numpy.complex64'>, 'datetime64': <type 'numpy.datetime64'>, 'float': <type 'numpy.float64'>, 'bool8': <type 'numpy.bool_'>, 'Bool': <type 'numpy.bool_'>, 'intp': <type 'numpy.int64'>, 'uintc': <type 'numpy.uint32'>, 'bytes_': <type 'numpy.string_'>, 'u8': <type 'numpy.uint64'>, 'u4': <type 'numpy.uint32'>, 'int_': <type 'numpy.int64'>, 'cdouble': <type 'numpy.complex128'>, 'u1': <type 'numpy.uint8'>, 'complex128': <type 'numpy.complex128'>, 'u2': <type 'numpy.uint16'>, 'f8': <type 'numpy.float64'>, 'Datetime64': <type 'numpy.datetime64'>, 'ubyte': <type 'numpy.uint8'>, 'm8': <type 'numpy.timedelta64'>, 'B': <type 'numpy.uint8'>, 'uint0': <type 'numpy.uint64'>, 'F': <type 'numpy.complex64'>, 'bool_': <type 'numpy.bool_'>, 'uint8': <type 'numpy.uint8'>, 'c8': <type 'numpy.complex64'>, 'Int64': <type 'numpy.int64'>, 'Int8': <type 'numpy.int8'>, 'Complex32': <type 'numpy.complex64'>, 'V': <type 'numpy.void'>, 'int8': <type 'numpy.int8'>, 'uint64': <type 'numpy.uint64'>, 'b': <type 'numpy.int8'>, 'f': <type 'numpy.float32'>, 'double': <type 'numpy.float64'>, 'UInt32': <type 'numpy.uint32'>, 'clongdouble': <type 'numpy.complex256'>, 'str': <type 'numpy.string_'>, 'f16': <type 'numpy.float128'>, 'f2': <type 'numpy.float16'>, 'f4': <type 'numpy.float32'>, 'int32': <type 'numpy.int32'>, 'int': <type 'numpy.int64'>, 'longdouble': <type 'numpy.float128'>, 'Complex128': <type 'numpy.complex256'>, 'single': <type 'numpy.float32'>, 'string': <type 'numpy.string_'>, 'q': <type 'numpy.int64'>, 'Int16': <type 'numpy.int16'>, 'Float64': <type 'numpy.float64'>, 'longcomplex': <type 'numpy.complex256'>, 'UInt16': <type 'numpy.uint16'>, 'bool': <type 'numpy.bool_'>, 'Float32': <type 'numpy.float32'>, 'string0': <type 'numpy.string_'>, 'longlong': <type 'numpy.int64'>, 'i8': <type 'numpy.int64'>, 'int16': <type 'numpy.int16'>, 'str_': <type 'numpy.string_'>, 'I': <type 'numpy.uint32'>, 'object': <type 'numpy.object_'>, 'M': <type 'numpy.datetime64'>, 'i4': <type 'numpy.int32'>, 'singlecomplex': <type 'numpy.complex64'>, 'Q': <type 'numpy.uint64'>, 'string_': <type 'numpy.string_'>, 'U': <type 'numpy.unicode_'>, 'a': <type 'numpy.string_'>, 'short': <type 'numpy.int16'>, 'e': <type 'numpy.float16'>, 'i': <type 'numpy.int32'>, 'clongfloat': <type 'numpy.complex256'>, 'm': <type 'numpy.timedelta64'>, 'Object0': <type 'numpy.object_'>, 'int64': <type 'numpy.int64'>, 'Float128': <type 'numpy.float128'>, 'i2': <type 'numpy.int16'>, 'int0': <type 'numpy.int64'>}, 'xticks': <function xticks at 0x109d20320>, 'bivariate_normal': <function bivariate_normal at 0x1081d0668>, 'min_scalar_type': <built-in function min_scalar_type>, 'concatenate': <built-in function concatenate>, 'imsave': <function imsave at 0x109d20aa0>, 'bincount': <built-in function bincount>, 'num2epoch': <function num2epoch at 0x106045848>, 'detrend_linear': <function detrend_linear at 0x10a9b9668>, 'corrcoef': <function corrcoef at 0x104e00b18>, 'vector_lengths': <function vector_lengths at 0x10a99fde8>, 'AutoLocator': <class 'matplotlib.ticker.AutoLocator'>, 'trim_zeros': <function trim_zeros at 0x104e005f0>, 'WEEKLY': 2, 'cos': <ufunc 'cos'>, 'cov': <function cov at 0x104e008c0>, 'cumprod': <function cumprod at 0x104d5c140>, 'resultant_cols': ['72_out', '79_out', '82_out', '83_out', '116_out', '119_out', '120_out', '127_out', '128_out', '137_out', '143_out', '144_out', '146_out', '147_out', '150_out', '151_out', '152_out', '153_out', '157_out', '160_out', '161_out', '164_out', '167_out', '168_out', '173_out', '174_out', '195_out', '212_out', '216_out', '217_out', '218_out', '223_out', '224_out', '225_out', '228_out', '229_out', '232_out', '233_out', '236_out', '237_out', '238_out', '239_out', '241_out', '242_out', '243_out', '244_out', '245_out', '247_out', '248_out', '249_out', '250_out', '251_out', '252_out', '253_out', '254_out', '257_out', '258_out', '259_out', '260_out', '261_out', '262_out', '263_out', '264_out', '265_out', '266_out', '267_out', '268_out', '270_out', '274_out', '275_out', '276_out', '278_out', '279_out', '280_out', '281_out', '282_out', '284_out', '285_out', '289_out', '290_out', '291_out', '293_out', '294_out', '295_out', '296_out', '297_out', '298_out', '300_out', '301_out', '302_out', '303_out', '304_out', '305_out', '306_out', '307_out', '308_out', '309_out', '310_out', '311_out', '312_out', '313_out', '314_out', '315_out', '316_out', '317_out', '318_out', '319_out', '320_out', '321_out', '322_out', '323_out', '324_out', '325_out', '326_out', '327_out', '328_out', '329_out', '330_out', '331_out', '332_out', '334_out', '335_out', '336_out', '337_out', '339_out', '340_out', '341_out', '342_out', '343_out', '344_out', '345_out', '346_out', '347_out', '348_out', '349_out', '350_out', '351_out', '352_out', '353_out', '354_out', '355_out', '356_out', '357_out', '358_out', '359_out', '360_out', '361_out', '362_out', '363_out', '364_out', '365_out', '366_out', '367_out', '368_out', '369_out', '373_out', '375_out', '376_out', '377_out', '379_out', '380_out', '382_out', '383_out', '384_out', '385_out', '386_out', '387_out', '388_out', '389_out', '390_out', '391_out', '392_out', '393_out', '394_out', '396_out', '397_out', '398_out', '399_out', '400_out', '401_out', '402_out', '403_out', '405_out', '406_out', '408_out', '409_out', '410_out', '411_out', '412_out', '414_out', '415_out', '416_out', '417_out', '418_out', '419_out', '420_out', '421_out', '422_out', '423_out', '426_out', '427_out', '428_out', '430_out', '431_out', '432_out', '433_out', '434_out', '435_out', '436_out', '437_out', '438_out', '439_out', '440_out', '441_out', '442_out', '443_out', '444_out', '445_out', '446_out', '447_out', '448_out', '449_out', '450_out', '453_out', '454_out', '455_out', '456_out', '457_out', '458_out', '459_out', '460_out', '461_out', '462_out', '463_out', '465_out', '466_out', '467_out', '468_out', '469_out', '470_out', '471_out', '472_out', '473_out', '474_out', '475_out', '476_out', '477_out', '478_out', '479_out', '480_out', '481_out', '482_out', '483_out', '484_out', '485_out', '486_out', '487_out', '488_out', '489_out', '490_out', '491_out', '492_out', '493_out', '494_out', '495_out', '496_out', '497_out', '498_out', '499_out', '500_out', '501_out', '502_out', '503_out', '504_out', '505_out', '507_out', '508_out', '509_out', '510_out', '511_out', '512_out', '513_out', '514_out', '515_out', '516_out', '517_out', '518_out', '519_out', '520_out', '521_out', '522_out', '523_out', '524_out', '525_out', '526_out', '527_out', '528_out', '529_out', '530_out', '531_out', '532_out', '533_out', '534_out', '536_out', '537_out', '539_out', '540_out', '545_out', '546_out', '2000_out', '2001_out', '2002_out', '2003_out', '2004_out', '2005_out', '2006_out', '2008_out', '2009_out', '2010_out', '2012_out', '2021_out', '2022_out', '2023_out', '3002_out', '3041_out', '3042_out', '3043_out', '3044_out', '3046_out', '3047_out', '3048_out', '3049_out', '3050_out', '3052_out', '3054_out', '3055_out', '3056_out', '3057_out', '3058_out', '3059_out', '3060_out', '3061_out', '3062_out', '3064_out', '3065_out', '3066_out', '3067_out', '3068_out', '3069_out', '3070_out', '3071_out', '3072_out', '3073_out', '3074_out', '3075_out', '3076_out', '3079_out', '3081_out', '3083_out', '3084_out', '3086_out', '3087_out', '3088_out', '3090_out', '3091_out', '3092_out', '3093_out', '3094_out', '3095_out', '3097_out', '3098_out', '3101_out', '3102_out', '3103_out', '3104_out', '3105_out', '3106_out', '3107_out', '3108_out', '3109_out', '3110_out', '3111_out', '3112_out', '3113_out', '3114_out', '3115_out', '3117_out', '3118_out', '3119_out', '3120_out', '3121_out', '3123_out', '3124_out', '3125_out', '3126_out', '3127_out', '3128_out', '3129_out', '3130_out', '3133_out', '3158_out', '3163_out', '3180_out', '3182_out', '3222_out', '3223_out', '3224_out', '72_in', '79_in', '82_in', '83_in', '116_in', '119_in', '120_in', '127_in', '128_in', '137_in', '143_in', '144_in', '146_in', '147_in', '150_in', '151_in', '152_in', '153_in', '157_in', '160_in', '161_in', '164_in', '167_in', '168_in', '173_in', '174_in', '195_in', '212_in', '216_in', '217_in', '218_in', '223_in', '224_in', '225_in', '228_in', '229_in', '232_in', '233_in', '236_in', '237_in', '238_in', '239_in', '241_in', '242_in', '243_in', '244_in', '245_in', '247_in', '248_in', '249_in', '250_in', '251_in', '252_in', '253_in', '254_in', '257_in', '258_in', '259_in', '260_in', '261_in', '262_in', '263_in', '264_in', '265_in', '266_in', '267_in', '268_in', '270_in', '274_in', '275_in', '276_in', '278_in', '279_in', '280_in', '281_in', '282_in', '284_in', '285_in', '289_in', '290_in', '291_in', '293_in', '294_in', '295_in', '296_in', '297_in', '298_in', '300_in', '301_in', '302_in', '303_in', '304_in', '305_in', '306_in', '307_in', '308_in', '309_in', '310_in', '311_in', '312_in', '313_in', '314_in', '315_in', '316_in', '317_in', '318_in', '319_in', '320_in', '321_in', '322_in', '323_in', '324_in', '325_in', '326_in', '327_in', '328_in', '329_in', '330_in', '331_in', '332_in', '334_in', '335_in', '336_in', '337_in', '339_in', '340_in', '341_in', '342_in', '343_in', '344_in', '345_in', '346_in', '347_in', '348_in', '349_in', '350_in', '351_in', '352_in', '353_in', '354_in', '355_in', '356_in', '357_in', '358_in', '359_in', '360_in', '361_in', '362_in', '363_in', '364_in', '365_in', '366_in', '367_in', '368_in', '369_in', '373_in', '375_in', '376_in', '377_in', '379_in', '380_in', '382_in', '383_in', '384_in', '385_in', '386_in', '387_in', '388_in', '389_in', '390_in', '391_in', '392_in', '393_in', '394_in', '396_in', '397_in', '398_in', '399_in', '400_in', '401_in', '402_in', '403_in', '405_in', '406_in', '408_in', '409_in', '410_in', '411_in', '412_in', '414_in', '415_in', '416_in', '417_in', '418_in', '419_in', '420_in', '421_in', '422_in', '423_in', '426_in', '427_in', '428_in', '430_in', '431_in', '432_in', '433_in', '434_in', '435_in', '436_in', '437_in', '438_in', '439_in', '440_in', '441_in', '442_in', '443_in', '444_in', '445_in', '446_in', '447_in', '448_in', '449_in', '450_in', '453_in', '454_in', '455_in', '456_in', '457_in', '458_in', '459_in', '460_in', '461_in', '462_in', '463_in', '465_in', '466_in', '467_in', '468_in', '469_in', '470_in', '471_in', '472_in', '473_in', '474_in', '475_in', '476_in', '477_in', '478_in', '479_in', '480_in', '481_in', '482_in', '483_in', '484_in', '485_in', '486_in', '487_in', '488_in', '489_in', '490_in', '491_in', '492_in', '493_in', '494_in', '495_in', '496_in', '497_in', '498_in', '499_in', '500_in', '501_in', '502_in', '503_in', '504_in', '505_in', '507_in', '508_in', '509_in', '510_in', '511_in', '512_in', '513_in', '514_in', '515_in', '516_in', '517_in', '518_in', '519_in', '520_in', '521_in', '522_in', '523_in', '524_in', '525_in', '526_in', '527_in', '528_in', '529_in', '530_in', '531_in', '532_in', '533_in', '534_in', '536_in', '537_in', '539_in', '540_in', '545_in', '546_in', '2000_in', '2001_in', '2002_in', '2003_in', '2004_in', '2005_in', '2006_in', '2008_in', '2009_in', '2010_in', '2012_in', '2021_in', '2022_in', '2023_in', '3002_in', '3041_in', '3042_in', '3043_in', '3044_in', '3046_in', '3047_in', '3048_in', '3049_in', '3050_in', '3052_in', '3054_in', '3055_in', '3056_in', '3057_in', '3058_in', '3059_in', '3060_in', '3061_in', '3062_in', '3064_in', '3065_in', '3066_in', '3067_in', '3068_in', '3069_in', '3070_in', '3071_in', '3072_in', '3073_in', '3074_in', '3075_in', '3076_in', '3079_in', '3081_in', '3083_in', '3084_in', '3086_in', '3087_in', '3088_in', '3090_in', '3091_in', '3092_in', '3093_in', '3094_in', '3095_in', '3097_in', '3098_in', '3101_in', '3102_in', '3103_in', '3104_in', '3105_in', '3106_in', '3107_in', '3108_in', '3109_in', '3110_in', '3111_in', '3112_in', '3113_in', '3114_in', '3115_in', '3117_in', '3118_in', '3119_in', '3120_in', '3121_in', '3123_in', '3124_in', '3125_in', '3126_in', '3127_in', '3128_in', '3129_in', '3130_in', '3133_in', '3158_in', '3163_in', '3180_in', '3182_in', '3222_in', '3223_in', '3224_in'], 'float_': <type 'numpy.float64'>, 'vander': <function vander at 0x104de9a28>, '_i45': u'df = pd.read_csv(\"data/july_thru_sept.csv\", usecols=COLUMNS)\\n# Convert to timestamps \\ntry:\\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\nexcept Exception as e:\\n    import pdb; pdb.set_trace()', 'pdb': <module 'pdb' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/pdb.pyc'>, 'prepca': <function prepca at 0x1081d0230>, 'load': <function load at 0x104e6f5f0>, 'issubclass_': <function issubclass_ at 0x104a90aa0>, 'loglog': <function loglog at 0x109d46a28>, 'diff': <function diff at 0x104e00398>, 'normpdf': <function normpdf at 0x1081d0050>, 'iterable': <function iterable at 0x104de9e60>, 'array_split': <function array_split at 0x104e13cf8>, 'get_include': <function get_include at 0x104df9f50>, 'pv': <function pv at 0x104e75b18>, 'rfftn': <function rfftn at 0x103aa59b0>, 'fftpack_lite': <module 'numpy.fft.fftpack_lite' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/numpy/fft/fftpack_lite.so'>, 'SHIFT_INVALID': 9, 'ubyte': <type 'numpy.uint8'>, 'pd': <module 'pandas' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/pandas/__init__.py'>, 'flexible': <type 'numpy.flexible'>, 'pi': 3.141592653589793, 'numpy': <module 'numpy' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/numpy/__init__.pyc'>, '__doc__': 'Automatically created module for IPython interactive environment', 'empty': <built-in function empty>, 'VisibleDeprecationWarning': <class 'numpy.VisibleDeprecationWarning'>, 'find_common_type': <function find_common_type at 0x1039c95f0>, 'longest_ones': <function longest_ones at 0x1081d01b8>, 'ylim': <function ylim at 0x109d201b8>, 'imag': <function imag at 0x104dcdf50>, 'sctype2char': <function sctype2char at 0x104a90cf8>, 'SHIFT_DIVIDEBYZERO': 0, '_i40': u'df[\"starttime\"].isnull()', 'apply_along_axis': <function apply_along_axis at 0x104e13a28>, 'tight_layout': <function tight_layout at 0x109d19de8>, 'array_repr': <function array_repr at 0x104d5ccf8>, 'reciprocal': <ufunc 'reciprocal'>, 'tanh': <ufunc 'tanh'>, 'angle_spectrum': <function angle_spectrum at 0x109d20de8>, 'typename': <function typename at 0x104dcda28>, 'gumbel': <built-in method gumbel of mtrand.RandomState object at 0x104ee18d0>, 'rfft2': <function rfft2 at 0x103aa5758>, 'packbits': <built-in function packbits>, 'issctype': <function issctype at 0x104a909b0>, 'vonmises': <built-in method vonmises of mtrand.RandomState object at 0x104ee18d0>, 'unicode_literals': _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 131072), 'aggregate_data':       period  station_id  start_count  stop_count\n",
      "0          0         173            1           0\n",
      "1          0         263            1           0\n",
      "2          0         274            1           0\n",
      "3          0         285            1           0\n",
      "4          0         307            1           1\n",
      "5          0         316            1           0\n",
      "6          0         317            1           0\n",
      "7          0         326            1           0\n",
      "8          0         340            0           1\n",
      "9          0         347            1           0\n",
      "10         0         358            1           0\n",
      "11         0         361            1           0\n",
      "12         0         386            2           0\n",
      "13         0         397            2           0\n",
      "14         0         410            1           0\n",
      "15         0         449            0           1\n",
      "16         0         450            1           0\n",
      "17         0         463            1           0\n",
      "18         0         479            2           0\n",
      "19         0         483            0           1\n",
      "20         0         488            1           0\n",
      "21         0         495            2           0\n",
      "22         0         509            1           0\n",
      "23         0         536            2           0\n",
      "24         0         545            1           0\n",
      "25         0        2003            1           0\n",
      "26         0        2004            1           0\n",
      "27         0        2021            1           0\n",
      "28         0        3075            1           0\n",
      "29         0        3118            0           1\n",
      "...      ...         ...          ...         ...\n",
      "9612     120         293            0           1\n",
      "9613     120         301            0           1\n",
      "9614     120         347            0           1\n",
      "9615     120         388            0           1\n",
      "9616     120         466            0           1\n",
      "9617     123         301            0           1\n",
      "9618     125         473            0           1\n",
      "9619     125         474            0           1\n",
      "9620     126         417            0           1\n",
      "9621     126         533            0           1\n",
      "9622     132         151            0           1\n",
      "9623     133         499            0           1\n",
      "9624     136         447            0           1\n",
      "9625     136         458            0           1\n",
      "9626     137         519            0           1\n",
      "9627     141         153            0           1\n",
      "9628     147         151            0           1\n",
      "9629     147         348            0           1\n",
      "9630     149         444            0           1\n",
      "9631     151          72            0           1\n",
      "9632     156         521            0           1\n",
      "9633     203         401            0           1\n",
      "9634     210         293            0           1\n",
      "9635     211         517            0           1\n",
      "9636     212         447            0           1\n",
      "9637     222        2023            0           1\n",
      "9638     226         430            0           1\n",
      "9639     226        3002            0           1\n",
      "9640     228         432            0           1\n",
      "9641     417         239            0           1\n",
      "\n",
      "[9642 rows x 4 columns], 'cond': <function cond at 0x104e15de8>, 'conj': <ufunc 'conjugate'>, 'flatiter': <type 'numpy.flatiter'>, 'WeekdayLocator': <class 'matplotlib.dates.WeekdayLocator'>, 'lengths': [2, 5, 10, 15], 'NaN': nan, 'show_config': <function show at 0x103a5bd70>, 'split': <function split at 0x104e13d70>, 'nextafter': <ufunc 'nextafter'>, 'SubplotTool': <class 'matplotlib.widgets.SubplotTool'>, 'i0': <function i0 at 0x104e00ed8>, 'permutation': <built-in method permutation of mtrand.RandomState object at 0x104ee18d0>, 'unravel_index': <built-in function unravel_index>, 'sys': <module 'sys' (built-in)>, 'bartlett': <function bartlett at 0x104e00c08>, 'stack': <function stack at 0x104d80230>, 'safe_eval': <function safe_eval at 0x104df97d0>, 'ifft': <function ifft at 0x104e77938>, 'Figure': <class 'matplotlib.figure.Figure'>, 'PINF': inf, 'add_newdocs': <module 'numpy.add_newdocs' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/numpy/add_newdocs.pyc'>, 'y': 1      0\n",
      "2      0\n",
      "3      1\n",
      "4      0\n",
      "5      0\n",
      "6      0\n",
      "7      0\n",
      "8      0\n",
      "9      0\n",
      "10     0\n",
      "11     0\n",
      "12     0\n",
      "13     0\n",
      "14     0\n",
      "15     0\n",
      "16     0\n",
      "17     0\n",
      "18     0\n",
      "19     0\n",
      "20     0\n",
      "21     0\n",
      "22     0\n",
      "23     0\n",
      "24     0\n",
      "25     0\n",
      "26     0\n",
      "27     0\n",
      "28     0\n",
      "29     0\n",
      "30     0\n",
      "      ..\n",
      "110    1\n",
      "111    1\n",
      "112    1\n",
      "113    0\n",
      "114    0\n",
      "115    0\n",
      "116    0\n",
      "117    0\n",
      "118    0\n",
      "119    0\n",
      "120    0\n",
      "121    0\n",
      "122    0\n",
      "123    0\n",
      "124    0\n",
      "125    0\n",
      "126    0\n",
      "127    0\n",
      "128    0\n",
      "129    0\n",
      "130    0\n",
      "131    0\n",
      "132    0\n",
      "133    0\n",
      "134    0\n",
      "135    0\n",
      "136    0\n",
      "137    0\n",
      "138    0\n",
      "139    0\n",
      "Name: 529_out, dtype: int64, 'putmask': <built-in function putmask>, 'apply_over_axes': <function apply_over_axes at 0x104e13aa0>, 'array_equiv': <function array_equiv at 0x104d5d9b0>, 'pylab': <module 'matplotlib.pylab' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/matplotlib/pylab.pyc'>, 'shape': <function shape at 0x104d5a938>, 'setbufsize': <function setbufsize at 0x104d5db18>, 'cfloat': <type 'numpy.complex128'>, 'uintp': <type 'numpy.uint64'>, 'detrend_mean': <function detrend_mean at 0x10a9b9578>, 'get_current_fig_manager': <function get_current_fig_manager at 0x109d19140>, 'character': <type 'numpy.character'>, 'source': <function source at 0x104df98c0>, 'UFUNC_PYVALS_NAME': 'UFUNC_PYVALS', 'uint16': <type 'numpy.uint16'>, 'cbrt': <ufunc 'cbrt'>, 'save': <function save at 0x104e75140>, 'float32': <type 'numpy.float32'>, 'insert': <function insert at 0x104e04578>, 'lexsort': <built-in function lexsort>, 'get_scale_names': <function get_scale_names at 0x109585c08>, 'complex_': <type 'numpy.complex128'>, 'ComplexWarning': <class 'numpy.core.numeric.ComplexWarning'>, 'datestr2num': <function datestr2num at 0x106041b18>, 'ipmt': <function ipmt at 0x104e75cf8>, 'atleast_3d': <function atleast_3d at 0x104d800c8>, 'nper': <function nper at 0x104e75de8>, 'integer': <type 'numpy.integer'>, 'unique': <function unique at 0x104e306e0>, 'cbook': <module 'matplotlib.cbook' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/matplotlib/cbook.pyc'>, 'bitwise_not': <ufunc 'invert'>, 'plot_date': <function plot_date at 0x109d46d70>, 'arange': <built-in function arange>, 'TARGET_STATION_ID': '529', '_dh': [u'/Users/suneel0101/Development/citibike'], 'spring': <function spring at 0x109d491b8>, 'interp': <function interp at 0x104e00410>, 'YEARLY': 0, 'rcdefaults': <function rcdefaults at 0x109d1ccf8>, 'rfft': <function rfft at 0x104e77848>, 'hypot': <ufunc 'hypot'>, 'logical_and': <ufunc 'logical_and'>, 'flatten': <function flatten at 0x105b49050>, 'matshow': <function matshow at 0x109d209b0>, 'MINUTELY': 5, 'ifftshift': <function ifftshift at 0x103ab32a8>, 'warnings': <module 'warnings' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/warnings.pyc'>, 'prod': <function prod at 0x104d5c0c8>, 'plt': <module 'matplotlib.pyplot' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/matplotlib/pyplot.pyc'>, 'bytes_': <type 'numpy.string_'>, 'stem': <function stem at 0x109d47230>, 'step': <function step at 0x109d472a8>, 'percentile': <function percentile at 0x104e042a8>, 'hsv': <function hsv at 0x109d47f50>, 'subtract': <ufunc 'subtract'>, 'frombuffer': <built-in function frombuffer>, 'fill_betweenx': <function fill_betweenx at 0x109d46758>, 'add_docstring': <built-in function add_docstring>, 'argsort': <function argsort at 0x104d5a488>, 'fmin': <ufunc 'fmin'>, 'gamma': <built-in method gamma of mtrand.RandomState object at 0x104ee18d0>, 'arcsinh': <ufunc 'arcsinh'>, 'intc': <type 'numpy.int32'>, 'exp_safe': <function exp_safe at 0x1081d0d70>, 'normalize': <function Normalize at 0x105a41500>, 'intp': <type 'numpy.int64'>, 'HOURLY': 4, 'arrow': <function arrow at 0x109d20e60>, 'True_': True, 'cdouble': <type 'numpy.complex128'>, 'round_': <function round_ at 0x104d5c398>, 'int_': <type 'numpy.int64'>, 'analyze': <function analyze at 0x109a19e60>, 'noncentral_chisquare': <built-in method noncentral_chisquare of mtrand.RandomState object at 0x104ee18d0>, 'issubdtype': <function issubdtype at 0x104a90b90>, 'maximum_sctype': <function maximum_sctype at 0x104a908c0>, 'int8': <type 'numpy.int8'>, 'info': <function info at 0x104df9938>, 'seterr': <function seterr at 0x104d5da28>, 'weibull': <built-in method weibull of mtrand.RandomState object at 0x104ee18d0>, 'maximum': <ufunc 'maximum'>, 'obj2sctype': <function obj2sctype at 0x104a90a28>, 'clongdouble': <type 'numpy.complex256'>, 'euler_gamma': 0.5772156649015329, 'arccosh': <ufunc 'arccosh'>, '_oh': {32:                               starttime            stoptime  start station id  \\\n",
      "2015-09-01 00:04:48 2015-09-01 00:00:00 2015-09-01 00:04:48               263   \n",
      "2015-09-01 00:02:45 2015-09-01 00:00:00 2015-09-01 00:02:45               495   \n",
      "2015-09-01 00:06:08 2015-09-01 00:00:01 2015-09-01 00:06:08              3119   \n",
      "2015-09-01 00:15:34 2015-09-01 00:00:07 2015-09-01 00:15:34               536   \n",
      "2015-09-01 00:11:07 2015-09-01 00:00:09 2015-09-01 00:11:07               347   \n",
      "2015-09-01 00:06:46 2015-09-01 00:00:13 2015-09-01 00:06:46              2004   \n",
      "2015-09-01 00:02:52 2015-09-01 00:00:49 2015-09-01 00:02:52               173   \n",
      "2015-09-01 00:18:41 2015-09-01 00:00:49 2015-09-01 00:18:41               397   \n",
      "2015-09-01 00:03:44 2015-09-01 00:00:53 2015-09-01 00:03:44               536   \n",
      "2015-09-01 00:19:01 2015-09-01 00:00:55 2015-09-01 00:19:01               397   \n",
      "2015-09-01 00:04:15 2015-09-01 00:01:05 2015-09-01 00:04:15               307   \n",
      "2015-09-01 00:13:02 2015-09-01 00:01:06 2015-09-01 00:13:02              3075   \n",
      "2015-09-01 00:08:56 2015-09-01 00:01:37 2015-09-01 00:08:56               361   \n",
      "2015-09-01 00:15:55 2015-09-01 00:01:51 2015-09-01 00:15:55               358   \n",
      "2015-09-01 00:16:51 2015-09-01 00:02:01 2015-09-01 00:16:51               410   \n",
      "2015-09-01 00:27:24 2015-09-01 00:02:10 2015-09-01 00:27:24               509   \n",
      "2015-09-01 00:09:56 2015-09-01 00:02:09 2015-09-01 00:09:56              2003   \n",
      "2015-09-01 00:05:28 2015-09-01 00:02:10 2015-09-01 00:05:28               450   \n",
      "2015-09-01 00:28:15 2015-09-01 00:02:36 2015-09-01 00:28:15               386   \n",
      "2015-09-01 00:11:55 2015-09-01 00:02:36 2015-09-01 00:11:55               285   \n",
      "2015-09-01 00:12:41 2015-09-01 00:02:50 2015-09-01 00:12:41               479   \n",
      "2015-09-01 00:23:49 2015-09-01 00:03:01 2015-09-01 00:23:49              3133   \n",
      "2015-09-01 00:12:53 2015-09-01 00:03:08 2015-09-01 00:12:53               479   \n",
      "2015-09-01 00:28:28 2015-09-01 00:03:20 2015-09-01 00:28:28               386   \n",
      "2015-09-01 00:23:49 2015-09-01 00:03:21 2015-09-01 00:23:49              3133   \n",
      "2015-09-01 00:14:59 2015-09-01 00:03:25 2015-09-01 00:14:59              2021   \n",
      "2015-09-01 00:14:00 2015-09-01 00:03:26 2015-09-01 00:14:00               495   \n",
      "2015-09-01 00:19:06 2015-09-01 00:04:20 2015-09-01 00:19:06               488   \n",
      "2015-09-01 00:07:15 2015-09-01 00:04:21 2015-09-01 00:07:15               316   \n",
      "2015-09-01 00:15:30 2015-09-01 00:04:24 2015-09-01 00:15:30               463   \n",
      "...                                 ...                 ...               ...   \n",
      "2015-09-01 09:31:46 2015-09-01 09:21:44 2015-09-01 09:31:46               174   \n",
      "2015-09-01 09:37:20 2015-09-01 09:21:44 2015-09-01 09:37:20              3002   \n",
      "2015-09-01 09:26:05 2015-09-01 09:21:47 2015-09-01 09:26:05               531   \n",
      "2015-09-01 09:31:51 2015-09-01 09:21:46 2015-09-01 09:31:51               536   \n",
      "2015-09-01 09:29:17 2015-09-01 09:21:48 2015-09-01 09:29:17               116   \n",
      "2015-09-01 09:31:45 2015-09-01 09:21:49 2015-09-01 09:31:45               348   \n",
      "2015-09-01 09:29:06 2015-09-01 09:21:51 2015-09-01 09:29:06               533   \n",
      "2015-09-01 09:37:10 2015-09-01 09:21:53 2015-09-01 09:37:10              3084   \n",
      "2015-09-01 09:31:19 2015-09-01 09:21:54 2015-09-01 09:31:19               494   \n",
      "2015-09-01 09:40:31 2015-09-01 09:21:59 2015-09-01 09:40:31               306   \n",
      "2015-09-01 09:26:33 2015-09-01 09:22:00 2015-09-01 09:26:33              2004   \n",
      "2015-09-01 09:25:47 2015-09-01 09:22:02 2015-09-01 09:25:47               281   \n",
      "2015-09-01 09:39:33 2015-09-01 09:22:03 2015-09-01 09:39:33                79   \n",
      "2015-09-01 09:40:34 2015-09-01 09:22:04 2015-09-01 09:40:34               536   \n",
      "2015-09-01 09:33:27 2015-09-01 09:22:06 2015-09-01 09:33:27               293   \n",
      "2015-09-01 09:30:26 2015-09-01 09:22:07 2015-09-01 09:30:26               173   \n",
      "2015-09-01 09:27:53 2015-09-01 09:22:07 2015-09-01 09:27:53               383   \n",
      "2015-09-01 09:52:56 2015-09-01 09:22:07 2015-09-01 09:52:56               508   \n",
      "2015-09-01 09:38:47 2015-09-01 09:22:14 2015-09-01 09:38:47              3224   \n",
      "2015-09-01 09:35:35 2015-09-01 09:22:09 2015-09-01 09:35:35               212   \n",
      "2015-09-01 09:30:49 2015-09-01 09:22:13 2015-09-01 09:30:49               284   \n",
      "2015-09-01 09:45:07 2015-09-01 09:22:15 2015-09-01 09:45:07               511   \n",
      "2015-09-01 09:26:42 2015-09-01 09:22:15 2015-09-01 09:26:42               383   \n",
      "2015-09-01 09:29:00 2015-09-01 09:22:16 2015-09-01 09:29:00               362   \n",
      "2015-09-01 09:25:45 2015-09-01 09:22:16 2015-09-01 09:25:45              2021   \n",
      "2015-09-01 09:27:54 2015-09-01 09:22:17 2015-09-01 09:27:54               468   \n",
      "2015-09-01 09:43:43 2015-09-01 09:22:16 2015-09-01 09:43:43               212   \n",
      "2015-09-01 09:43:14 2015-09-01 09:22:22 2015-09-01 09:43:14               511   \n",
      "2015-09-01 09:33:07 2015-09-01 09:22:22 2015-09-01 09:33:07               503   \n",
      "2015-09-01 09:32:49 2015-09-01 09:22:24 2015-09-01 09:32:49               366   \n",
      "\n",
      "                     end station id  start_period  stop_period  \n",
      "2015-09-01 00:04:48             307             0            0  \n",
      "2015-09-01 00:02:45             449             0            0  \n",
      "2015-09-01 00:06:08            3118             0            0  \n",
      "2015-09-01 00:15:34             340             0            0  \n",
      "2015-09-01 00:11:07             483             0            0  \n",
      "2015-09-01 00:06:46             254             0            1  \n",
      "2015-09-01 00:02:52             450             0            1  \n",
      "2015-09-01 00:18:41            3044             0            1  \n",
      "2015-09-01 00:03:44             476             0            1  \n",
      "2015-09-01 00:19:01            3044             0            1  \n",
      "2015-09-01 00:04:15             412             0            1  \n",
      "2015-09-01 00:13:02             364             0            1  \n",
      "2015-09-01 00:08:56             356             0            1  \n",
      "2015-09-01 00:15:55             147             0            1  \n",
      "2015-09-01 00:16:51            3087             0            1  \n",
      "2015-09-01 00:27:24             494             0            2  \n",
      "2015-09-01 00:09:56             474             0            2  \n",
      "2015-09-01 00:05:28             479             0            2  \n",
      "2015-09-01 00:28:15             386             0            2  \n",
      "2015-09-01 00:11:55             382             0            2  \n",
      "2015-09-01 00:12:41             458             0            2  \n",
      "2015-09-01 00:23:49             334             0            2  \n",
      "2015-09-01 00:12:53             458             0            2  \n",
      "2015-09-01 00:28:28             386             0            2  \n",
      "2015-09-01 00:23:49             334             0            2  \n",
      "2015-09-01 00:14:59             500             0            2  \n",
      "2015-09-01 00:14:00             468             0            2  \n",
      "2015-09-01 00:19:06            3223             0            2  \n",
      "2015-09-01 00:07:15             279             0            2  \n",
      "2015-09-01 00:15:30              72             0            3  \n",
      "...                             ...           ...          ...  \n",
      "2015-09-01 09:31:46             466           112          120  \n",
      "2015-09-01 09:37:20             347           112          120  \n",
      "2015-09-01 09:26:05             301           112          120  \n",
      "2015-09-01 09:31:51             293           112          120  \n",
      "2015-09-01 09:29:17             388           112          120  \n",
      "2015-09-01 09:31:45             301           112          123  \n",
      "2015-09-01 09:29:06             474           112          125  \n",
      "2015-09-01 09:37:10             473           112          125  \n",
      "2015-09-01 09:31:19             533           112          126  \n",
      "2015-09-01 09:40:31             417           112          126  \n",
      "2015-09-01 09:26:33             151           112          132  \n",
      "2015-09-01 09:25:47             499           112          133  \n",
      "2015-09-01 09:39:33             458           112          136  \n",
      "2015-09-01 09:40:34             447           112          136  \n",
      "2015-09-01 09:33:27             519           112          137  \n",
      "2015-09-01 09:30:26             153           112          141  \n",
      "2015-09-01 09:27:53             348           112          147  \n",
      "2015-09-01 09:52:56             151           112          147  \n",
      "2015-09-01 09:38:47             444           112          149  \n",
      "2015-09-01 09:35:35              72           112          151  \n",
      "2015-09-01 09:30:49             521           112          156  \n",
      "2015-09-01 09:45:07             401           112          203  \n",
      "2015-09-01 09:26:42             293           112          210  \n",
      "2015-09-01 09:29:00             517           112          211  \n",
      "2015-09-01 09:25:45             447           112          212  \n",
      "2015-09-01 09:27:54            2023           112          222  \n",
      "2015-09-01 09:43:43            3002           112          226  \n",
      "2015-09-01 09:43:14             430           112          226  \n",
      "2015-09-01 09:33:07             432           112          228  \n",
      "2015-09-01 09:32:49             239           112          417  \n",
      "\n",
      "[10000 rows x 6 columns], 33: 10000, 38: 14217684, 40: 0          False\n",
      "1          False\n",
      "2          False\n",
      "3          False\n",
      "4          False\n",
      "5          False\n",
      "6          False\n",
      "7          False\n",
      "8          False\n",
      "9          False\n",
      "10         False\n",
      "11         False\n",
      "12         False\n",
      "13         False\n",
      "14         False\n",
      "15         False\n",
      "16         False\n",
      "17         False\n",
      "18         False\n",
      "19         False\n",
      "20         False\n",
      "21         False\n",
      "22         False\n",
      "23         False\n",
      "24         False\n",
      "25         False\n",
      "26         False\n",
      "27         False\n",
      "28         False\n",
      "29         False\n",
      "           ...  \n",
      "3554391    False\n",
      "3554392    False\n",
      "3554393    False\n",
      "3554394    False\n",
      "3554395    False\n",
      "3554396    False\n",
      "3554397    False\n",
      "3554398    False\n",
      "3554399    False\n",
      "3554400    False\n",
      "3554401    False\n",
      "3554402    False\n",
      "3554403    False\n",
      "3554404    False\n",
      "3554405    False\n",
      "3554406    False\n",
      "3554407    False\n",
      "3554408    False\n",
      "3554409    False\n",
      "3554410    False\n",
      "3554411    False\n",
      "3554412    False\n",
      "3554413    False\n",
      "3554414    False\n",
      "3554415    False\n",
      "3554416    False\n",
      "3554417    False\n",
      "3554418    False\n",
      "3554419    False\n",
      "3554420    False\n",
      "Name: starttime, dtype: bool, 41: 0          False\n",
      "1          False\n",
      "2          False\n",
      "3          False\n",
      "4          False\n",
      "5          False\n",
      "6          False\n",
      "7          False\n",
      "8          False\n",
      "9          False\n",
      "10         False\n",
      "11         False\n",
      "12         False\n",
      "13         False\n",
      "14         False\n",
      "15         False\n",
      "16         False\n",
      "17         False\n",
      "18         False\n",
      "19         False\n",
      "20         False\n",
      "21         False\n",
      "22         False\n",
      "23         False\n",
      "24         False\n",
      "25         False\n",
      "26         False\n",
      "27         False\n",
      "28         False\n",
      "29         False\n",
      "           ...  \n",
      "3554391    False\n",
      "3554392    False\n",
      "3554393    False\n",
      "3554394    False\n",
      "3554395    False\n",
      "3554396    False\n",
      "3554397    False\n",
      "3554398    False\n",
      "3554399    False\n",
      "3554400    False\n",
      "3554401    False\n",
      "3554402    False\n",
      "3554403    False\n",
      "3554404    False\n",
      "3554405    False\n",
      "3554406    False\n",
      "3554407    False\n",
      "3554408    False\n",
      "3554409    False\n",
      "3554410    False\n",
      "3554411    False\n",
      "3554412    False\n",
      "3554413    False\n",
      "3554414    False\n",
      "3554415    False\n",
      "3554416    False\n",
      "3554417    False\n",
      "3554418    False\n",
      "3554419    False\n",
      "3554420    False\n",
      "Name: starttime, dtype: bool, 42: Empty DataFrame\n",
      "Columns: [starttime, stoptime, start station id, end station id]\n",
      "Index: [], 43: Empty DataFrame\n",
      "Columns: [starttime, stoptime, start station id, end station id]\n",
      "Index: [], 16: [<matplotlib.lines.Line2D object at 0x1095de290>], 18: [<matplotlib.lines.Line2D object at 0x109e43610>], 19: [<matplotlib.lines.Line2D object at 0x10acd0bd0>], 21: [<matplotlib.lines.Line2D object at 0x10917fe10>], 22: [<matplotlib.lines.Line2D object at 0x10b7515d0>], 24: [<matplotlib.lines.Line2D object at 0x10a5bb2d0>], 25: 0.87325095398710173, 26: 0.87753175687006379, 28: 0.86718256219107048, 29: 0.87382836173351897}, 'df_stop':       period  station_id  stop_count\n",
      "0          0         307           1\n",
      "1          0         340           1\n",
      "2          0         449           1\n",
      "3          0         483           1\n",
      "4          0        3118           1\n",
      "5          1         147           1\n",
      "6          1         254           1\n",
      "7          1         356           1\n",
      "8          1         364           1\n",
      "9          1         412           1\n",
      "10         1         450           1\n",
      "11         1         476           1\n",
      "12         1        3044           2\n",
      "13         1        3087           1\n",
      "14         2         279           1\n",
      "15         2         334           2\n",
      "16         2         382           1\n",
      "17         2         386           2\n",
      "18         2         458           2\n",
      "19         2         468           1\n",
      "20         2         474           1\n",
      "21         2         479           1\n",
      "22         2         494           1\n",
      "23         2         500           1\n",
      "24         2        3223           1\n",
      "25         3          72           1\n",
      "26         3         116           1\n",
      "27         3         161           1\n",
      "28         3         291           1\n",
      "29         3         325           2\n",
      "...      ...         ...         ...\n",
      "6039     120         293           1\n",
      "6040     120         301           1\n",
      "6041     120         347           1\n",
      "6042     120         388           1\n",
      "6043     120         466           1\n",
      "6044     123         301           1\n",
      "6045     125         473           1\n",
      "6046     125         474           1\n",
      "6047     126         417           1\n",
      "6048     126         533           1\n",
      "6049     132         151           1\n",
      "6050     133         499           1\n",
      "6051     136         447           1\n",
      "6052     136         458           1\n",
      "6053     137         519           1\n",
      "6054     141         153           1\n",
      "6055     147         151           1\n",
      "6056     147         348           1\n",
      "6057     149         444           1\n",
      "6058     151          72           1\n",
      "6059     156         521           1\n",
      "6060     203         401           1\n",
      "6061     210         293           1\n",
      "6062     211         517           1\n",
      "6063     212         447           1\n",
      "6064     222        2023           1\n",
      "6065     226         430           1\n",
      "6066     226        3002           1\n",
      "6067     228         432           1\n",
      "6068     417         239           1\n",
      "\n",
      "[6069 rows x 3 columns], 'delete': <function delete at 0x104e04500>, 'tril': <function tril at 0x104de9938>, 'digitize': <built-in function digitize>, 'yscale': <function yscale at 0x109d202a8>, 'specgram': <function specgram at 0x109d47140>, 'answer_series': 0      0\n",
      "1      0\n",
      "2      0\n",
      "3      1\n",
      "4      0\n",
      "5      0\n",
      "6      0\n",
      "7      0\n",
      "8      0\n",
      "9      0\n",
      "10     0\n",
      "11     0\n",
      "12     0\n",
      "13     0\n",
      "14     0\n",
      "15     0\n",
      "16     0\n",
      "17     0\n",
      "18     0\n",
      "19     0\n",
      "20     0\n",
      "21     0\n",
      "22     0\n",
      "23     0\n",
      "24     0\n",
      "25     0\n",
      "26     0\n",
      "27     0\n",
      "28     0\n",
      "29     0\n",
      "      ..\n",
      "110    1\n",
      "111    1\n",
      "112    1\n",
      "113    0\n",
      "114    0\n",
      "115    0\n",
      "116    0\n",
      "117    0\n",
      "118    0\n",
      "119    0\n",
      "120    0\n",
      "121    0\n",
      "122    0\n",
      "123    0\n",
      "124    0\n",
      "125    0\n",
      "126    0\n",
      "127    0\n",
      "128    0\n",
      "129    0\n",
      "130    0\n",
      "131    0\n",
      "132    0\n",
      "133    0\n",
      "134    0\n",
      "135    0\n",
      "136    0\n",
      "137    0\n",
      "138    0\n",
      "139    0\n",
      "Name: 529_out, dtype: int64, 'char': <module 'numpy.core.defchararray' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/numpy/core/defchararray.pyc'>, 'single': <type 'numpy.float32'>, 'triu': <function triu at 0x104de99b0>, 'floating': <type 'numpy.floating'>, 'expand_dims': <function expand_dims at 0x104e13b18>, 'floor': <ufunc 'floor'>, 'TU': TU, 'ERR_IGNORE': 0, 'bmat': <function bmat at 0x104e0cb18>, 'isclose': <function isclose at 0x104d5d8c0>, 'ERR_DEFAULT': 521, 'TH': TH, 'np': <module 'numpy' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/numpy/__init__.pyc'>, 'register_cmap': <function register_cmap at 0x10821b320>, 'roll': <function roll at 0x104d40410>, 'figsize': <function figsize at 0x1032f6938>, 'compare_chararrays': <built-in function compare_chararrays>, 'nonzero': <function nonzero at 0x104d5a8c0>, 'draw': <function draw at 0x109d19398>, 'nanvar': <function nanvar at 0x104e137d0>, 'hamming': <function hamming at 0x104e00cf8>, 'ravel_multi_index': <built-in function ravel_multi_index>, 'scores': array([ 0.73333333,  0.73333333,  1.        ,  1.        ,  0.92857143,\n",
      "        1.        ,  0.69230769,  0.69230769,  0.92307692,  0.84615385]), 'Inf': inf, 'delaxes': <function delaxes at 0x109d19938>, 'e': ValueError(u'Unknown string format',), 'datetime_data': <built-in function datetime_data>, 'svd': <function svd at 0x104e15e60>, 'flag': <function flag at 0x109d47de8>, 'full_like': <function full_like at 0x104d40c80>, 'FuncFormatter': <class 'matplotlib.ticker.FuncFormatter'>, 'base_repr': <function base_repr at 0x104d5d668>, 'argwhere': <function argwhere at 0x104d408c0>, 'time': <module 'time' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/lib-dynload/time.so'>, 'set_string_function': <function set_string_function at 0x104d5d410>, 'union1d': <function union1d at 0x104e308c0>, 'atleast_2d': <function atleast_2d at 0x104d80050>, 'contourf': <function contourf at 0x109d46488>, 'fft2': <function fft2 at 0x103aa5aa0>, 'xkcd': <function xkcd at 0x109d1cde8>, 'resize': <function resize at 0x104d5a668>, 'blackman': <function blackman at 0x104e00b90>, 'FLOATING_POINT_SUPPORT': 1, 'division': _Feature((2, 2, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 8192), 'get_scale_docs': <function get_scale_docs at 0x109599cf8>, 'mlab': <module 'matplotlib.mlab' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/matplotlib/mlab.pyc'>, 'busdaycalendar': <type 'numpy.busdaycalendar'>, 'thetagrids': <function thetagrids at 0x109d20578>, 'cool': <function cool at 0x109d47cf8>, 'tri': <function tri at 0x104de98c0>, 'FormatStrFormatter': <class 'matplotlib.ticker.FormatStrFormatter'>, 'get_plot_commands': <function get_plot_commands at 0x109d20668>, '_i13': u'for tc in [10, 20, 40]:\\n    print \"{} trees\".format(tc)\\n    analyze(10000, tree_count=tc)', '_i12': u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nstart = time.time()\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\n\\ndef analyze(row_limit, threshold_out=1, tree_count=10, period_minutes=5, k_folds=5):\\n    \"\"\"\\n    We can tune the following parameters:\\n    - number of rows we analyze\\n    - number of folds in our standard k-fold cross-validation\\n    - number of bicycles taken out in the period to be considered in the positive class\\n    - number of trees in our random forest\\n    - number of minutes in our period\\n    \"\"\"\\n    df = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=row_limit)\\n    # Convert to timestamps \\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\n    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n    # Convert int64index to datetime index\\n    # Group using timegrouper and create new column for start period and stop period\\n    df = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\n    start_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\n    df[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\n    df = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\n    stop_time_group_by = df.groupby(pd.TimeGrouper(\\'{}Min\\'.format(period_minutes)),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\n    df[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n    # Create two sub dataframes, grouping on and aggregating start data and then stop data\\n    grouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\n    df_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\n    df_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\n    grouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\n    df_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\n    df_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n    # Combine these two dataframes and fill N/A values to 0\\n    df_combined = pd.concat([df_start, df_stop])\\n    df_combined = df_combined.fillna(0)\\n\\n    # Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n    # And reset the multi-level index so we have a normal DataFrame\\n    aggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n    # Let\\'s construct a pivot table\\n    pivoted = pd.pivot_table(\\n        aggregate_data,\\n        index=[\"period\"],\\n        columns=[\"station_id\"],\\n        aggfunc=np.sum,\\n        fill_value=0)\\n\\n    # Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\n    deeper_cols = pivoted.columns.get_level_values(1)\\n    top_level_cols = pivoted.columns.get_level_values(0)\\n\\n    # Flattening the columns\\n    resultant_cols = []    \\n    for i, station_id in enumerate(deeper_cols):\\n        if top_level_cols[i] == \"start_count\":\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n        else:\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\n    pivoted.columns = resultant_cols\\n    pivoted = pivoted.reset_index()\\n    print \"{} rows in the pivoted table\".format(len(pivoted))\\n    X = pivoted.copy()\\n    # Turn number of out in station TARGET_STATION_ID into 1s and 0s\\n    answer_series = (\\n        pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > threshold_out).apply(int)\\n    X = X[:-1]\\n    y = answer_series[1:]\\n\\n    classifier = RandomForestClassifier(n_estimators=tree_count)\\n    scores = cross_validation.cross_val_score(\\n        classifier,\\n        X,\\n        y,\\n        cv=k_folds\\n    )\\n\\n    end = time.time()\\n    print \"Rows: {}, k={}\".format(row_limit, k_folds)\\n    print \"Mean accuracy: {}\".format(np.mean(scores))\\n    print \"Standard deviation: {}\".format(np.std(scores))\\n    print \"Took {}s\".format(end - start)', '_i11': u'for tc in [10, 20, 40]:\\n    analyze(10000, tree_count=tc)', '_i10': u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nstart = time.time()\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\n\\ndef analyze(row_limit, threshold_out=1, tree_count=10, period_minutes=5, k_folds=5):\\n    \"\"\"\\n    We can tune the following parameters:\\n    - number of rows we analyze\\n    - number of folds in our standard k-fold cross-validation\\n    - number of bicycles taken out in the period to be considered in the positive class\\n    - number of trees in our random forest\\n    - number of minutes in our period\\n    \"\"\"\\n    df = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=row_limit)\\n    # Convert to timestamps \\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\n    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n    # Convert int64index to datetime index\\n    # Group using timegrouper and create new column for start period and stop period\\n    df = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\n    start_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\n    df[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\n    df = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\n    stop_time_group_by = df.groupby(pd.TimeGrouper(\\'{}Min\\'.format(period_minutes)),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\n    df[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n    # Create two sub dataframes, grouping on and aggregating start data and then stop data\\n    grouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\n    df_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\n    df_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\n    grouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\n    df_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\n    df_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n    # Combine these two dataframes and fill N/A values to 0\\n    df_combined = pd.concat([df_start, df_stop])\\n    df_combined = df_combined.fillna(0)\\n\\n    # Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n    # And reset the multi-level index so we have a normal DataFrame\\n    aggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n    # Let\\'s construct a pivot table\\n    pivoted = pd.pivot_table(\\n        aggregate_data,\\n        index=[\"period\"],\\n        columns=[\"station_id\"],\\n        aggfunc=np.sum,\\n        fill_value=0)\\n\\n    # Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\n    deeper_cols = pivoted.columns.get_level_values(1)\\n    top_level_cols = pivoted.columns.get_level_values(0)\\n\\n    # Flattening the columns\\n    resultant_cols = []    \\n    for i, station_id in enumerate(deeper_cols):\\n        if top_level_cols[i] == \"start_count\":\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n        else:\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\n    pivoted.columns = resultant_cols\\n    pivoted = pivoted.reset_index()\\n    print \"{} rows in the pivoted table\".format(len(pivoted))\\n    X = pivoted.copy()\\n    # Turn number of out in station TARGET_STATION_ID into 1s and 0s\\n    answer_series = (\\n        pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > threshhold_out).apply(int)\\n    X = X[:-1]\\n    y = answer_series[1:]\\n\\n    classifier = RandomForestClassifier(n_estimators=tree_count)\\n    scores = cross_validation.cross_val_score(\\n        classifier,\\n        X,\\n        y,\\n        cv=k_folds\\n    )\\n\\n    end = time.time()\\n    print \"Rows: {}, k={}\".format(row_limit, k_folds)\\n    print \"Mean accuracy: {}\".format(np.mean(scores))\\n    print \"Standard deviation: {}\".format(np.std(scores))\\n    print \"Took {}s\".format(end - start)', '_i17': u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nstart = time.time()\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\n\\ndef analyze(row_limit, threshold_out=1, tree_count=10, period_minutes=5, k_folds=5):\\n    \"\"\"\\n    We can tune the following parameters:\\n    - number of rows we analyze\\n    - number of folds in our standard k-fold cross-validation\\n    - number of bicycles taken out in the period to be considered in the positive class\\n    - number of trees in our random forest\\n    - number of minutes in our period\\n    \"\"\"\\n    df = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=row_limit)\\n    # Convert to timestamps \\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\n    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n    # Convert int64index to datetime index\\n    # Group using timegrouper and create new column for start period and stop period\\n    df = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\n    start_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\n    df[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\n    df = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\n    stop_time_group_by = df.groupby(pd.TimeGrouper(\\'{}Min\\'.format(period_minutes)),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\n    df[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n    # Create two sub dataframes, grouping on and aggregating start data and then stop data\\n    grouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\n    df_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\n    df_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\n    grouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\n    df_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\n    df_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n    # Combine these two dataframes and fill N/A values to 0\\n    df_combined = pd.concat([df_start, df_stop])\\n    df_combined = df_combined.fillna(0)\\n\\n    # Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n    # And reset the multi-level index so we have a normal DataFrame\\n    aggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n    # Let\\'s construct a pivot table\\n    pivoted = pd.pivot_table(\\n        aggregate_data,\\n        index=[\"period\"],\\n        columns=[\"station_id\"],\\n        aggfunc=np.sum,\\n        fill_value=0)\\n\\n    # Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\n    deeper_cols = pivoted.columns.get_level_values(1)\\n    top_level_cols = pivoted.columns.get_level_values(0)\\n\\n    # Flattening the columns\\n    resultant_cols = []    \\n    for i, station_id in enumerate(deeper_cols):\\n        if top_level_cols[i] == \"start_count\":\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n        else:\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\n    pivoted.columns = resultant_cols\\n    pivoted = pivoted.reset_index()\\n    print \"{} rows in the pivoted table\".format(len(pivoted))\\n    X = pivoted.copy()\\n    # Turn number of out in station TARGET_STATION_ID into 1s and 0s\\n    answer_series = (\\n        pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > threshold_out).apply(int)\\n    X = X[:-1]\\n    y = answer_series[1:]\\n\\n    classifier = RandomForestClassifier(n_estimators=tree_count)\\n    scores = cross_validation.cross_val_score(\\n        classifier,\\n        X,\\n        y,\\n        cv=k_folds\\n    )\\n\\n    end = time.time()\\n    mean_accuracy = np.mean(scores)\\n    print \"Rows: {}, k={}\".format(row_limit, k_folds)\\n    print \"Mean accuracy: {}\".format(mean_accuracy)\\n    print \"Standard deviation: {}\".format(np.std(scores))\\n    print \"Took {}s\".format(end - start)\\n    return mean_accuracy', '_i16': u'plt.plot([1, 2], [3, 4])', '_i15': u'from matplotlib import pyplot as plt', '_i14': u'%pylab inline', 'loads': <built-in function loads>, '_i18': u'counts = [10, 20, 40]\\naccs = []\\nfor tc in counts:\\n    print \"{} trees\".format(tc)\\n    accs.append(analyze(10000, tree_count=tc))\\nplt.plot(counts, accs)', 'set_numeric_ops': <built-in function set_numeric_ops>, 'pmt': <function pmt at 0x104e75e60>, 'rfftfreq': <function rfftfreq at 0x103ab31b8>, 'nanstd': <function nanstd at 0x104e13848>, 'diag_indices_from': <function diag_indices_from at 0x104e0ec80>, 'object0': <type 'numpy.object_'>, 'ishold': <function ishold at 0x109d197d0>, 'FPE_OVERFLOW': 2, 'index_exp': <numpy.lib.index_tricks.IndexExpression object at 0x104e05f50>, 'append': <function append at 0x104e045f0>, 'deeper_cols': Int64Index([  72,   79,   82,   83,  116,  119,  120,  127,  128,  137,\n",
      "            ...\n",
      "            3129, 3130, 3133, 3158, 3163, 3180, 3182, 3222, 3223, 3224],\n",
      "           dtype='int64', name=u'station_id', length=814), 'nanargmax': <function nanargmax at 0x104e132a8>, 'hstack': <function hstack at 0x104d801b8>, 'pyplot': <module 'matplotlib.pyplot' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/matplotlib/pyplot.pyc'>, 'axes': <function axes at 0x109d198c0>, 'ERR_WARN': 1, 'uniform': <built-in method uniform of mtrand.RandomState object at 0x104ee18d0>, 'polyfit': <function polyfit at 0x104e2c5f0>, 'phase_spectrum': <function phase_spectrum at 0x109d46c08>, 'violinplot': <function violinplot at 0x109d47578>, 'nan_to_num': <function nan_to_num at 0x104dcdb90>, 'twinx': <function twinx at 0x109d19c08>, 'df_start':       period  station_id  start_count\n",
      "0          0         173            1\n",
      "1          0         263            1\n",
      "2          0         274            1\n",
      "3          0         285            1\n",
      "4          0         307            1\n",
      "5          0         316            1\n",
      "6          0         317            1\n",
      "7          0         326            1\n",
      "8          0         347            1\n",
      "9          0         358            1\n",
      "10         0         361            1\n",
      "11         0         386            2\n",
      "12         0         397            2\n",
      "13         0         410            1\n",
      "14         0         450            1\n",
      "15         0         463            1\n",
      "16         0         479            2\n",
      "17         0         488            1\n",
      "18         0         495            2\n",
      "19         0         509            1\n",
      "20         0         536            2\n",
      "21         0         545            1\n",
      "22         0        2003            1\n",
      "23         0        2004            1\n",
      "24         0        2021            1\n",
      "25         0        3075            1\n",
      "26         0        3119            1\n",
      "27         0        3133            2\n",
      "28         1         274            1\n",
      "29         1         293            1\n",
      "...      ...         ...          ...\n",
      "6013     112         490            1\n",
      "6014     112         494            1\n",
      "6015     112         499            1\n",
      "6016     112         500            1\n",
      "6017     112         501            1\n",
      "6018     112         503            1\n",
      "6019     112         504            1\n",
      "6020     112         505            1\n",
      "6021     112         508            1\n",
      "6022     112         511            4\n",
      "6023     112         513            1\n",
      "6024     112         517            3\n",
      "6025     112         529            3\n",
      "6026     112         531            1\n",
      "6027     112         533            2\n",
      "6028     112         536            2\n",
      "6029     112         537            1\n",
      "6030     112        2004            1\n",
      "6031     112        2021            1\n",
      "6032     112        3002            3\n",
      "6033     112        3046            1\n",
      "6034     112        3060            1\n",
      "6035     112        3084            1\n",
      "6036     112        3086            1\n",
      "6037     112        3108            2\n",
      "6038     112        3109            1\n",
      "6039     112        3129            1\n",
      "6040     112        3163            1\n",
      "6041     112        3223            1\n",
      "6042     112        3224            1\n",
      "\n",
      "[6043 rows x 3 columns], 'fmax': <ufunc 'fmax'>, 'spacing': <ufunc 'spacing'>, 'matplotlib': <module 'matplotlib' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/matplotlib/__init__.pyc'>, 'getfigs': <function getfigs at 0x1032f68c0>, 'FigureCanvasBase': <class 'matplotlib.backend_bases.FigureCanvasBase'>, 'sinh': <ufunc 'sinh'>, 'cholesky': <function cholesky at 0x104e23230>, 'rgrids': <function rgrids at 0x109d20500>, 'sinc': <function sinc at 0x104e04050>, 'box': <function box at 0x109d19e60>, 'finfo': <class 'numpy.core.getlimits.finfo'>, 'MachAr': <class 'numpy.core.machar.MachAr'>, 'MO': MO, 'asscalar': <function asscalar at 0x104dcdaa0>, 'binomial': <built-in method binomial of mtrand.RandomState object at 0x104ee18d0>, 'broken_barh': <function broken_barh at 0x109d46230>, 'poisson': <built-in method poisson of mtrand.RandomState object at 0x104ee18d0>, 'less_equal': <ufunc 'less_equal'>, 'object_': <type 'numpy.object_'>, 'FR': FR, 'RAISE': 2, 'csingle': <type 'numpy.complex64'>, 'dtype': <type 'numpy.dtype'>, 'unsignedinteger': <type 'numpy.unsignedinteger'>, 'sign': <ufunc 'sign'>, 'num2date': <function num2date at 0x106041de8>, 'bitwise_and': <ufunc 'bitwise_and'>, 'ifftn': <function ifftn at 0x103aa5b18>, 'ticklabel_format': <function ticklabel_format at 0x109d47a28>, 'nditer': <type 'numpy.nditer'>, 'kron': <function kron at 0x104e150c8>, 'newbuffer': <built-in function newbuffer>, 'axhspan': <function axhspan at 0x109d20f50>, 'standard_gamma': <built-in method standard_gamma of mtrand.RandomState object at 0x104ee18d0>, 'print_function': _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 65536), 'MAXDIMS': 32, '_i34': u'df = pd.read_csv(\"data/july_thru_sept.csv\", usecols=COLUMNS)', 'standard_normal': <built-in method standard_normal of mtrand.RandomState object at 0x104ee18d0>, 'fftfreq': <function fftfreq at 0x103ab3230>, 'ifft2': <function ifft2 at 0x103aa5a28>, 'loadtxt': <function loadtxt at 0x104e75398>, 'vlines': <function vlines at 0x109d475f0>, 'zeros_like': <function zeros_like at 0x104d40f50>, 'int_asbuffer': <built-in function int_asbuffer>, 'linspace': <function linspace at 0x104d75230>, 'COLUMNS': ['starttime', 'stoptime', 'start station id', 'end station id'], 'f': <built-in method f of mtrand.RandomState object at 0x104ee18d0>, 'hist2d': <function hist2d at 0x109d468c0>, 'isneginf': <function isneginf at 0x104dd30c8>, '__return__': None, 'rc_context': <function rc_context at 0x109d1cc80>, 'scatter': <function scatter at 0x109d46f50>, 'Out': {32:                               starttime            stoptime  start station id  \\\n",
      "2015-09-01 00:04:48 2015-09-01 00:00:00 2015-09-01 00:04:48               263   \n",
      "2015-09-01 00:02:45 2015-09-01 00:00:00 2015-09-01 00:02:45               495   \n",
      "2015-09-01 00:06:08 2015-09-01 00:00:01 2015-09-01 00:06:08              3119   \n",
      "2015-09-01 00:15:34 2015-09-01 00:00:07 2015-09-01 00:15:34               536   \n",
      "2015-09-01 00:11:07 2015-09-01 00:00:09 2015-09-01 00:11:07               347   \n",
      "2015-09-01 00:06:46 2015-09-01 00:00:13 2015-09-01 00:06:46              2004   \n",
      "2015-09-01 00:02:52 2015-09-01 00:00:49 2015-09-01 00:02:52               173   \n",
      "2015-09-01 00:18:41 2015-09-01 00:00:49 2015-09-01 00:18:41               397   \n",
      "2015-09-01 00:03:44 2015-09-01 00:00:53 2015-09-01 00:03:44               536   \n",
      "2015-09-01 00:19:01 2015-09-01 00:00:55 2015-09-01 00:19:01               397   \n",
      "2015-09-01 00:04:15 2015-09-01 00:01:05 2015-09-01 00:04:15               307   \n",
      "2015-09-01 00:13:02 2015-09-01 00:01:06 2015-09-01 00:13:02              3075   \n",
      "2015-09-01 00:08:56 2015-09-01 00:01:37 2015-09-01 00:08:56               361   \n",
      "2015-09-01 00:15:55 2015-09-01 00:01:51 2015-09-01 00:15:55               358   \n",
      "2015-09-01 00:16:51 2015-09-01 00:02:01 2015-09-01 00:16:51               410   \n",
      "2015-09-01 00:27:24 2015-09-01 00:02:10 2015-09-01 00:27:24               509   \n",
      "2015-09-01 00:09:56 2015-09-01 00:02:09 2015-09-01 00:09:56              2003   \n",
      "2015-09-01 00:05:28 2015-09-01 00:02:10 2015-09-01 00:05:28               450   \n",
      "2015-09-01 00:28:15 2015-09-01 00:02:36 2015-09-01 00:28:15               386   \n",
      "2015-09-01 00:11:55 2015-09-01 00:02:36 2015-09-01 00:11:55               285   \n",
      "2015-09-01 00:12:41 2015-09-01 00:02:50 2015-09-01 00:12:41               479   \n",
      "2015-09-01 00:23:49 2015-09-01 00:03:01 2015-09-01 00:23:49              3133   \n",
      "2015-09-01 00:12:53 2015-09-01 00:03:08 2015-09-01 00:12:53               479   \n",
      "2015-09-01 00:28:28 2015-09-01 00:03:20 2015-09-01 00:28:28               386   \n",
      "2015-09-01 00:23:49 2015-09-01 00:03:21 2015-09-01 00:23:49              3133   \n",
      "2015-09-01 00:14:59 2015-09-01 00:03:25 2015-09-01 00:14:59              2021   \n",
      "2015-09-01 00:14:00 2015-09-01 00:03:26 2015-09-01 00:14:00               495   \n",
      "2015-09-01 00:19:06 2015-09-01 00:04:20 2015-09-01 00:19:06               488   \n",
      "2015-09-01 00:07:15 2015-09-01 00:04:21 2015-09-01 00:07:15               316   \n",
      "2015-09-01 00:15:30 2015-09-01 00:04:24 2015-09-01 00:15:30               463   \n",
      "...                                 ...                 ...               ...   \n",
      "2015-09-01 09:31:46 2015-09-01 09:21:44 2015-09-01 09:31:46               174   \n",
      "2015-09-01 09:37:20 2015-09-01 09:21:44 2015-09-01 09:37:20              3002   \n",
      "2015-09-01 09:26:05 2015-09-01 09:21:47 2015-09-01 09:26:05               531   \n",
      "2015-09-01 09:31:51 2015-09-01 09:21:46 2015-09-01 09:31:51               536   \n",
      "2015-09-01 09:29:17 2015-09-01 09:21:48 2015-09-01 09:29:17               116   \n",
      "2015-09-01 09:31:45 2015-09-01 09:21:49 2015-09-01 09:31:45               348   \n",
      "2015-09-01 09:29:06 2015-09-01 09:21:51 2015-09-01 09:29:06               533   \n",
      "2015-09-01 09:37:10 2015-09-01 09:21:53 2015-09-01 09:37:10              3084   \n",
      "2015-09-01 09:31:19 2015-09-01 09:21:54 2015-09-01 09:31:19               494   \n",
      "2015-09-01 09:40:31 2015-09-01 09:21:59 2015-09-01 09:40:31               306   \n",
      "2015-09-01 09:26:33 2015-09-01 09:22:00 2015-09-01 09:26:33              2004   \n",
      "2015-09-01 09:25:47 2015-09-01 09:22:02 2015-09-01 09:25:47               281   \n",
      "2015-09-01 09:39:33 2015-09-01 09:22:03 2015-09-01 09:39:33                79   \n",
      "2015-09-01 09:40:34 2015-09-01 09:22:04 2015-09-01 09:40:34               536   \n",
      "2015-09-01 09:33:27 2015-09-01 09:22:06 2015-09-01 09:33:27               293   \n",
      "2015-09-01 09:30:26 2015-09-01 09:22:07 2015-09-01 09:30:26               173   \n",
      "2015-09-01 09:27:53 2015-09-01 09:22:07 2015-09-01 09:27:53               383   \n",
      "2015-09-01 09:52:56 2015-09-01 09:22:07 2015-09-01 09:52:56               508   \n",
      "2015-09-01 09:38:47 2015-09-01 09:22:14 2015-09-01 09:38:47              3224   \n",
      "2015-09-01 09:35:35 2015-09-01 09:22:09 2015-09-01 09:35:35               212   \n",
      "2015-09-01 09:30:49 2015-09-01 09:22:13 2015-09-01 09:30:49               284   \n",
      "2015-09-01 09:45:07 2015-09-01 09:22:15 2015-09-01 09:45:07               511   \n",
      "2015-09-01 09:26:42 2015-09-01 09:22:15 2015-09-01 09:26:42               383   \n",
      "2015-09-01 09:29:00 2015-09-01 09:22:16 2015-09-01 09:29:00               362   \n",
      "2015-09-01 09:25:45 2015-09-01 09:22:16 2015-09-01 09:25:45              2021   \n",
      "2015-09-01 09:27:54 2015-09-01 09:22:17 2015-09-01 09:27:54               468   \n",
      "2015-09-01 09:43:43 2015-09-01 09:22:16 2015-09-01 09:43:43               212   \n",
      "2015-09-01 09:43:14 2015-09-01 09:22:22 2015-09-01 09:43:14               511   \n",
      "2015-09-01 09:33:07 2015-09-01 09:22:22 2015-09-01 09:33:07               503   \n",
      "2015-09-01 09:32:49 2015-09-01 09:22:24 2015-09-01 09:32:49               366   \n",
      "\n",
      "                     end station id  start_period  stop_period  \n",
      "2015-09-01 00:04:48             307             0            0  \n",
      "2015-09-01 00:02:45             449             0            0  \n",
      "2015-09-01 00:06:08            3118             0            0  \n",
      "2015-09-01 00:15:34             340             0            0  \n",
      "2015-09-01 00:11:07             483             0            0  \n",
      "2015-09-01 00:06:46             254             0            1  \n",
      "2015-09-01 00:02:52             450             0            1  \n",
      "2015-09-01 00:18:41            3044             0            1  \n",
      "2015-09-01 00:03:44             476             0            1  \n",
      "2015-09-01 00:19:01            3044             0            1  \n",
      "2015-09-01 00:04:15             412             0            1  \n",
      "2015-09-01 00:13:02             364             0            1  \n",
      "2015-09-01 00:08:56             356             0            1  \n",
      "2015-09-01 00:15:55             147             0            1  \n",
      "2015-09-01 00:16:51            3087             0            1  \n",
      "2015-09-01 00:27:24             494             0            2  \n",
      "2015-09-01 00:09:56             474             0            2  \n",
      "2015-09-01 00:05:28             479             0            2  \n",
      "2015-09-01 00:28:15             386             0            2  \n",
      "2015-09-01 00:11:55             382             0            2  \n",
      "2015-09-01 00:12:41             458             0            2  \n",
      "2015-09-01 00:23:49             334             0            2  \n",
      "2015-09-01 00:12:53             458             0            2  \n",
      "2015-09-01 00:28:28             386             0            2  \n",
      "2015-09-01 00:23:49             334             0            2  \n",
      "2015-09-01 00:14:59             500             0            2  \n",
      "2015-09-01 00:14:00             468             0            2  \n",
      "2015-09-01 00:19:06            3223             0            2  \n",
      "2015-09-01 00:07:15             279             0            2  \n",
      "2015-09-01 00:15:30              72             0            3  \n",
      "...                             ...           ...          ...  \n",
      "2015-09-01 09:31:46             466           112          120  \n",
      "2015-09-01 09:37:20             347           112          120  \n",
      "2015-09-01 09:26:05             301           112          120  \n",
      "2015-09-01 09:31:51             293           112          120  \n",
      "2015-09-01 09:29:17             388           112          120  \n",
      "2015-09-01 09:31:45             301           112          123  \n",
      "2015-09-01 09:29:06             474           112          125  \n",
      "2015-09-01 09:37:10             473           112          125  \n",
      "2015-09-01 09:31:19             533           112          126  \n",
      "2015-09-01 09:40:31             417           112          126  \n",
      "2015-09-01 09:26:33             151           112          132  \n",
      "2015-09-01 09:25:47             499           112          133  \n",
      "2015-09-01 09:39:33             458           112          136  \n",
      "2015-09-01 09:40:34             447           112          136  \n",
      "2015-09-01 09:33:27             519           112          137  \n",
      "2015-09-01 09:30:26             153           112          141  \n",
      "2015-09-01 09:27:53             348           112          147  \n",
      "2015-09-01 09:52:56             151           112          147  \n",
      "2015-09-01 09:38:47             444           112          149  \n",
      "2015-09-01 09:35:35              72           112          151  \n",
      "2015-09-01 09:30:49             521           112          156  \n",
      "2015-09-01 09:45:07             401           112          203  \n",
      "2015-09-01 09:26:42             293           112          210  \n",
      "2015-09-01 09:29:00             517           112          211  \n",
      "2015-09-01 09:25:45             447           112          212  \n",
      "2015-09-01 09:27:54            2023           112          222  \n",
      "2015-09-01 09:43:43            3002           112          226  \n",
      "2015-09-01 09:43:14             430           112          226  \n",
      "2015-09-01 09:33:07             432           112          228  \n",
      "2015-09-01 09:32:49             239           112          417  \n",
      "\n",
      "[10000 rows x 6 columns], 33: 10000, 38: 14217684, 40: 0          False\n",
      "1          False\n",
      "2          False\n",
      "3          False\n",
      "4          False\n",
      "5          False\n",
      "6          False\n",
      "7          False\n",
      "8          False\n",
      "9          False\n",
      "10         False\n",
      "11         False\n",
      "12         False\n",
      "13         False\n",
      "14         False\n",
      "15         False\n",
      "16         False\n",
      "17         False\n",
      "18         False\n",
      "19         False\n",
      "20         False\n",
      "21         False\n",
      "22         False\n",
      "23         False\n",
      "24         False\n",
      "25         False\n",
      "26         False\n",
      "27         False\n",
      "28         False\n",
      "29         False\n",
      "           ...  \n",
      "3554391    False\n",
      "3554392    False\n",
      "3554393    False\n",
      "3554394    False\n",
      "3554395    False\n",
      "3554396    False\n",
      "3554397    False\n",
      "3554398    False\n",
      "3554399    False\n",
      "3554400    False\n",
      "3554401    False\n",
      "3554402    False\n",
      "3554403    False\n",
      "3554404    False\n",
      "3554405    False\n",
      "3554406    False\n",
      "3554407    False\n",
      "3554408    False\n",
      "3554409    False\n",
      "3554410    False\n",
      "3554411    False\n",
      "3554412    False\n",
      "3554413    False\n",
      "3554414    False\n",
      "3554415    False\n",
      "3554416    False\n",
      "3554417    False\n",
      "3554418    False\n",
      "3554419    False\n",
      "3554420    False\n",
      "Name: starttime, dtype: bool, 41: 0          False\n",
      "1          False\n",
      "2          False\n",
      "3          False\n",
      "4          False\n",
      "5          False\n",
      "6          False\n",
      "7          False\n",
      "8          False\n",
      "9          False\n",
      "10         False\n",
      "11         False\n",
      "12         False\n",
      "13         False\n",
      "14         False\n",
      "15         False\n",
      "16         False\n",
      "17         False\n",
      "18         False\n",
      "19         False\n",
      "20         False\n",
      "21         False\n",
      "22         False\n",
      "23         False\n",
      "24         False\n",
      "25         False\n",
      "26         False\n",
      "27         False\n",
      "28         False\n",
      "29         False\n",
      "           ...  \n",
      "3554391    False\n",
      "3554392    False\n",
      "3554393    False\n",
      "3554394    False\n",
      "3554395    False\n",
      "3554396    False\n",
      "3554397    False\n",
      "3554398    False\n",
      "3554399    False\n",
      "3554400    False\n",
      "3554401    False\n",
      "3554402    False\n",
      "3554403    False\n",
      "3554404    False\n",
      "3554405    False\n",
      "3554406    False\n",
      "3554407    False\n",
      "3554408    False\n",
      "3554409    False\n",
      "3554410    False\n",
      "3554411    False\n",
      "3554412    False\n",
      "3554413    False\n",
      "3554414    False\n",
      "3554415    False\n",
      "3554416    False\n",
      "3554417    False\n",
      "3554418    False\n",
      "3554419    False\n",
      "3554420    False\n",
      "Name: starttime, dtype: bool, 42: Empty DataFrame\n",
      "Columns: [starttime, stoptime, start station id, end station id]\n",
      "Index: [], 43: Empty DataFrame\n",
      "Columns: [starttime, stoptime, start station id, end station id]\n",
      "Index: [], 16: [<matplotlib.lines.Line2D object at 0x1095de290>], 18: [<matplotlib.lines.Line2D object at 0x109e43610>], 19: [<matplotlib.lines.Line2D object at 0x10acd0bd0>], 21: [<matplotlib.lines.Line2D object at 0x10917fe10>], 22: [<matplotlib.lines.Line2D object at 0x10b7515d0>], 24: [<matplotlib.lines.Line2D object at 0x10a5bb2d0>], 25: 0.87325095398710173, 26: 0.87753175687006379, 28: 0.86718256219107048, 29: 0.87382836173351897}, 'spy': <function spy at 0x109d20cf8>, 'MinuteLocator': <class 'matplotlib.dates.MinuteLocator'>, 'figure': <function figure at 0x109d1ced8>, 'get_sparse_matrix': <function get_sparse_matrix at 0x1081d0758>, 'add_newdoc': <function add_newdoc at 0x104e04410>, 'seterrcall': <function seterrcall at 0x104d5dc08>, 'sample': <built-in method random_sample of mtrand.RandomState object at 0x104ee18d0>, 'tan': <ufunc 'tan'>, 'rms_flat': <function rms_flat at 0x1081d0e60>, 'eigvalsh': <function eigvalsh at 0x104e230c8>, 'gca': <function gca at 0x109d19a28>, 'winter': <function winter at 0x109d492a8>, 'gcf': <function gcf at 0x109d1cf50>, 'gci': <function gci at 0x109d1cb90>, 'get_array_wrap': <function get_array_wrap at 0x104e15050>, 'polymul': <function polymul at 0x104e2c7d0>, 'standard_exponential': <built-in method standard_exponential of mtrand.RandomState object at 0x104ee18d0>, 'get_ipython': <bound method ZMQInteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x103ae6cd0>>, 'tile': <function tile at 0x104e15140>, 'absolute': <ufunc 'absolute'>, 'pinv': <function pinv at 0x104e15cf8>, 'longlong': <type 'numpy.int64'>, 'pink': <function pink at 0x109d490c8>, 'product': <function product at 0x104d5ab18>, 'int16': <type 'numpy.int16'>, 's_': <numpy.lib.index_tricks.IndexExpression object at 0x104e05fd0>, 'mat': <function asmatrix at 0x104e04938>, 'docstring': <module 'matplotlib.docstring' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/matplotlib/docstring.pyc'>, 'uint': <type 'numpy.uint64'>, 'negative_binomial': <built-in method negative_binomial of mtrand.RandomState object at 0x104ee18d0>, 'npv': <function npv at 0x104e757d0>, '_32':                               starttime            stoptime  start station id  \\\n",
      "2015-09-01 00:04:48 2015-09-01 00:00:00 2015-09-01 00:04:48               263   \n",
      "2015-09-01 00:02:45 2015-09-01 00:00:00 2015-09-01 00:02:45               495   \n",
      "2015-09-01 00:06:08 2015-09-01 00:00:01 2015-09-01 00:06:08              3119   \n",
      "2015-09-01 00:15:34 2015-09-01 00:00:07 2015-09-01 00:15:34               536   \n",
      "2015-09-01 00:11:07 2015-09-01 00:00:09 2015-09-01 00:11:07               347   \n",
      "2015-09-01 00:06:46 2015-09-01 00:00:13 2015-09-01 00:06:46              2004   \n",
      "2015-09-01 00:02:52 2015-09-01 00:00:49 2015-09-01 00:02:52               173   \n",
      "2015-09-01 00:18:41 2015-09-01 00:00:49 2015-09-01 00:18:41               397   \n",
      "2015-09-01 00:03:44 2015-09-01 00:00:53 2015-09-01 00:03:44               536   \n",
      "2015-09-01 00:19:01 2015-09-01 00:00:55 2015-09-01 00:19:01               397   \n",
      "2015-09-01 00:04:15 2015-09-01 00:01:05 2015-09-01 00:04:15               307   \n",
      "2015-09-01 00:13:02 2015-09-01 00:01:06 2015-09-01 00:13:02              3075   \n",
      "2015-09-01 00:08:56 2015-09-01 00:01:37 2015-09-01 00:08:56               361   \n",
      "2015-09-01 00:15:55 2015-09-01 00:01:51 2015-09-01 00:15:55               358   \n",
      "2015-09-01 00:16:51 2015-09-01 00:02:01 2015-09-01 00:16:51               410   \n",
      "2015-09-01 00:27:24 2015-09-01 00:02:10 2015-09-01 00:27:24               509   \n",
      "2015-09-01 00:09:56 2015-09-01 00:02:09 2015-09-01 00:09:56              2003   \n",
      "2015-09-01 00:05:28 2015-09-01 00:02:10 2015-09-01 00:05:28               450   \n",
      "2015-09-01 00:28:15 2015-09-01 00:02:36 2015-09-01 00:28:15               386   \n",
      "2015-09-01 00:11:55 2015-09-01 00:02:36 2015-09-01 00:11:55               285   \n",
      "2015-09-01 00:12:41 2015-09-01 00:02:50 2015-09-01 00:12:41               479   \n",
      "2015-09-01 00:23:49 2015-09-01 00:03:01 2015-09-01 00:23:49              3133   \n",
      "2015-09-01 00:12:53 2015-09-01 00:03:08 2015-09-01 00:12:53               479   \n",
      "2015-09-01 00:28:28 2015-09-01 00:03:20 2015-09-01 00:28:28               386   \n",
      "2015-09-01 00:23:49 2015-09-01 00:03:21 2015-09-01 00:23:49              3133   \n",
      "2015-09-01 00:14:59 2015-09-01 00:03:25 2015-09-01 00:14:59              2021   \n",
      "2015-09-01 00:14:00 2015-09-01 00:03:26 2015-09-01 00:14:00               495   \n",
      "2015-09-01 00:19:06 2015-09-01 00:04:20 2015-09-01 00:19:06               488   \n",
      "2015-09-01 00:07:15 2015-09-01 00:04:21 2015-09-01 00:07:15               316   \n",
      "2015-09-01 00:15:30 2015-09-01 00:04:24 2015-09-01 00:15:30               463   \n",
      "...                                 ...                 ...               ...   \n",
      "2015-09-01 09:31:46 2015-09-01 09:21:44 2015-09-01 09:31:46               174   \n",
      "2015-09-01 09:37:20 2015-09-01 09:21:44 2015-09-01 09:37:20              3002   \n",
      "2015-09-01 09:26:05 2015-09-01 09:21:47 2015-09-01 09:26:05               531   \n",
      "2015-09-01 09:31:51 2015-09-01 09:21:46 2015-09-01 09:31:51               536   \n",
      "2015-09-01 09:29:17 2015-09-01 09:21:48 2015-09-01 09:29:17               116   \n",
      "2015-09-01 09:31:45 2015-09-01 09:21:49 2015-09-01 09:31:45               348   \n",
      "2015-09-01 09:29:06 2015-09-01 09:21:51 2015-09-01 09:29:06               533   \n",
      "2015-09-01 09:37:10 2015-09-01 09:21:53 2015-09-01 09:37:10              3084   \n",
      "2015-09-01 09:31:19 2015-09-01 09:21:54 2015-09-01 09:31:19               494   \n",
      "2015-09-01 09:40:31 2015-09-01 09:21:59 2015-09-01 09:40:31               306   \n",
      "2015-09-01 09:26:33 2015-09-01 09:22:00 2015-09-01 09:26:33              2004   \n",
      "2015-09-01 09:25:47 2015-09-01 09:22:02 2015-09-01 09:25:47               281   \n",
      "2015-09-01 09:39:33 2015-09-01 09:22:03 2015-09-01 09:39:33                79   \n",
      "2015-09-01 09:40:34 2015-09-01 09:22:04 2015-09-01 09:40:34               536   \n",
      "2015-09-01 09:33:27 2015-09-01 09:22:06 2015-09-01 09:33:27               293   \n",
      "2015-09-01 09:30:26 2015-09-01 09:22:07 2015-09-01 09:30:26               173   \n",
      "2015-09-01 09:27:53 2015-09-01 09:22:07 2015-09-01 09:27:53               383   \n",
      "2015-09-01 09:52:56 2015-09-01 09:22:07 2015-09-01 09:52:56               508   \n",
      "2015-09-01 09:38:47 2015-09-01 09:22:14 2015-09-01 09:38:47              3224   \n",
      "2015-09-01 09:35:35 2015-09-01 09:22:09 2015-09-01 09:35:35               212   \n",
      "2015-09-01 09:30:49 2015-09-01 09:22:13 2015-09-01 09:30:49               284   \n",
      "2015-09-01 09:45:07 2015-09-01 09:22:15 2015-09-01 09:45:07               511   \n",
      "2015-09-01 09:26:42 2015-09-01 09:22:15 2015-09-01 09:26:42               383   \n",
      "2015-09-01 09:29:00 2015-09-01 09:22:16 2015-09-01 09:29:00               362   \n",
      "2015-09-01 09:25:45 2015-09-01 09:22:16 2015-09-01 09:25:45              2021   \n",
      "2015-09-01 09:27:54 2015-09-01 09:22:17 2015-09-01 09:27:54               468   \n",
      "2015-09-01 09:43:43 2015-09-01 09:22:16 2015-09-01 09:43:43               212   \n",
      "2015-09-01 09:43:14 2015-09-01 09:22:22 2015-09-01 09:43:14               511   \n",
      "2015-09-01 09:33:07 2015-09-01 09:22:22 2015-09-01 09:33:07               503   \n",
      "2015-09-01 09:32:49 2015-09-01 09:22:24 2015-09-01 09:32:49               366   \n",
      "\n",
      "                     end station id  start_period  stop_period  \n",
      "2015-09-01 00:04:48             307             0            0  \n",
      "2015-09-01 00:02:45             449             0            0  \n",
      "2015-09-01 00:06:08            3118             0            0  \n",
      "2015-09-01 00:15:34             340             0            0  \n",
      "2015-09-01 00:11:07             483             0            0  \n",
      "2015-09-01 00:06:46             254             0            1  \n",
      "2015-09-01 00:02:52             450             0            1  \n",
      "2015-09-01 00:18:41            3044             0            1  \n",
      "2015-09-01 00:03:44             476             0            1  \n",
      "2015-09-01 00:19:01            3044             0            1  \n",
      "2015-09-01 00:04:15             412             0            1  \n",
      "2015-09-01 00:13:02             364             0            1  \n",
      "2015-09-01 00:08:56             356             0            1  \n",
      "2015-09-01 00:15:55             147             0            1  \n",
      "2015-09-01 00:16:51            3087             0            1  \n",
      "2015-09-01 00:27:24             494             0            2  \n",
      "2015-09-01 00:09:56             474             0            2  \n",
      "2015-09-01 00:05:28             479             0            2  \n",
      "2015-09-01 00:28:15             386             0            2  \n",
      "2015-09-01 00:11:55             382             0            2  \n",
      "2015-09-01 00:12:41             458             0            2  \n",
      "2015-09-01 00:23:49             334             0            2  \n",
      "2015-09-01 00:12:53             458             0            2  \n",
      "2015-09-01 00:28:28             386             0            2  \n",
      "2015-09-01 00:23:49             334             0            2  \n",
      "2015-09-01 00:14:59             500             0            2  \n",
      "2015-09-01 00:14:00             468             0            2  \n",
      "2015-09-01 00:19:06            3223             0            2  \n",
      "2015-09-01 00:07:15             279             0            2  \n",
      "2015-09-01 00:15:30              72             0            3  \n",
      "...                             ...           ...          ...  \n",
      "2015-09-01 09:31:46             466           112          120  \n",
      "2015-09-01 09:37:20             347           112          120  \n",
      "2015-09-01 09:26:05             301           112          120  \n",
      "2015-09-01 09:31:51             293           112          120  \n",
      "2015-09-01 09:29:17             388           112          120  \n",
      "2015-09-01 09:31:45             301           112          123  \n",
      "2015-09-01 09:29:06             474           112          125  \n",
      "2015-09-01 09:37:10             473           112          125  \n",
      "2015-09-01 09:31:19             533           112          126  \n",
      "2015-09-01 09:40:31             417           112          126  \n",
      "2015-09-01 09:26:33             151           112          132  \n",
      "2015-09-01 09:25:47             499           112          133  \n",
      "2015-09-01 09:39:33             458           112          136  \n",
      "2015-09-01 09:40:34             447           112          136  \n",
      "2015-09-01 09:33:27             519           112          137  \n",
      "2015-09-01 09:30:26             153           112          141  \n",
      "2015-09-01 09:27:53             348           112          147  \n",
      "2015-09-01 09:52:56             151           112          147  \n",
      "2015-09-01 09:38:47             444           112          149  \n",
      "2015-09-01 09:35:35              72           112          151  \n",
      "2015-09-01 09:30:49             521           112          156  \n",
      "2015-09-01 09:45:07             401           112          203  \n",
      "2015-09-01 09:26:42             293           112          210  \n",
      "2015-09-01 09:29:00             517           112          211  \n",
      "2015-09-01 09:25:45             447           112          212  \n",
      "2015-09-01 09:27:54            2023           112          222  \n",
      "2015-09-01 09:43:43            3002           112          226  \n",
      "2015-09-01 09:43:14             430           112          226  \n",
      "2015-09-01 09:33:07             432           112          228  \n",
      "2015-09-01 09:32:49             239           112          417  \n",
      "\n",
      "[10000 rows x 6 columns], 'correlate': <function correlate at 0x104d406e0>, 'fromstring': <built-in function fromstring>, 'left_shift': <ufunc 'left_shift'>, 'TickHelper': <class 'matplotlib.ticker.TickHelper'>, 'searchsorted': <function searchsorted at 0x104d5a5f0>, 'int64': <type 'numpy.int64'>, 'may_share_memory': <built-in function may_share_memory>, 'GridSpec': <class 'matplotlib.gridspec.GridSpec'>, 'six': <module 'six' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/six.py'>, 'thresholds': [1, 2, 3], 'intersect1d': <function intersect1d at 0x104e30758>, 'window_none': <function window_none at 0x10a9b9398>, 'can_cast': <built-in function can_cast>, 'Widget': <class 'matplotlib.widgets.Widget'>, 'outer': <function outer at 0x104d405f0>, 'subplot_tool': <function subplot_tool at 0x109d19d70>, 'choose': <function choose at 0x104d5a0c8>, 'SECONDLY': 6, 'greater': <ufunc 'greater'>, 'matrix_power': <function matrix_power at 0x104e049b0>, 'histogram2d': <function histogram2d at 0x104de9aa0>, 'polyint': <function polyint at 0x104e2c500>, 'qr': <function qr at 0x104e231b8>, 'datetime64': <type 'numpy.datetime64'>, 'complexfloating': <type 'numpy.complexfloating'>, 'ndindex': <class 'numpy.lib.index_tricks.ndindex'>, 'MonthLocator': <class 'matplotlib.dates.MonthLocator'>, 'nanmedian': <function nanmedian at 0x104e135f0>, 'radians': <ufunc 'radians'>, 'sin': <ufunc 'sin'>, '_16': [<matplotlib.lines.Line2D object at 0x1095de290>], 'recarray': <class 'numpy.recarray'>, 'modf': <ufunc 'modf'>, '_19': [<matplotlib.lines.Line2D object at 0x10acd0bd0>], 'ix_': <function ix_ at 0x104e0e140>, 'LogFormatter': <class 'matplotlib.ticker.LogFormatter'>, 'poly_below': <function poly_below at 0x10a99fb18>, 'square': <ufunc 'square'>, 'isvector': <function isvector at 0x10a99c398>, 'ioff': <function ioff at 0x109d1ca28>, 'nanargmin': <function nanargmin at 0x104e13230>, 'hypergeometric': <built-in method hypergeometric of mtrand.RandomState object at 0x104ee18d0>, 'margins': <function margins at 0x109d47b90>, 'pareto': <built-in method pareto of mtrand.RandomState object at 0x104ee18d0>, 'float16': <type 'numpy.float16'>, 'ulonglong': <type 'numpy.uint64'>, 'matrix': <class 'numpy.matrixlib.defmatrix.matrix'>, 'streamplot': <function streamplot at 0x109d47320>, '_i28': u'analyze(20000, tree_count=500, threshold_out=1, period_minutes=5)', '_i29': u'analyze(1000000, tree_count=200, threshold_out=1, period_minutes=5)', '_i26': u'analyze(1200000, tree_count=500, threshold_out=1, period_minutes=5)', 'rec': <module 'numpy.core.records' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/numpy/core/records.pyc'>, '_i24': u'plt.plot(tree_counts, accs)', '_i25': u'analyze(1000000, tree_count=200, threshold_out=1, period_minutes=5)', 'datetime_as_string': <built-in function datetime_as_string>, 'uint32': <type 'numpy.uint32'>, 'math': <module 'math' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/lib-dynload/math.so'>, '_i21': u'thresholds = [1, 2, 3]\\naccs = []\\nfor to in thresholds:\\n    accs.append(analyze(10000, tree_count=40, threshold_out=to))\\n    print \"\\\\n\"\\nplt.plot(thresholds, accs)', 'get_cmap': <function get_cmap at 0x10821b398>, 'date2num': <function date2num at 0x106041c80>, '__builtins__': {'bytearray': <type 'bytearray'>, 'IndexError': <type 'exceptions.IndexError'>, 'all': <built-in function all>, 'help': Type help() for interactive help, or help(object) for help about object., 'vars': <built-in function vars>, 'SyntaxError': <type 'exceptions.SyntaxError'>, '__IPYTHON__active': 'Deprecated, check for __IPYTHON__', 'unicode': <type 'unicode'>, 'UnicodeDecodeError': <type 'exceptions.UnicodeDecodeError'>, 'memoryview': <type 'memoryview'>, 'isinstance': <built-in function isinstance>, 'copyright': Copyright (c) 2001-2015 Python Software Foundation.\n",
      "All Rights Reserved.\n",
      "\n",
      "Copyright (c) 2000 BeOpen.com.\n",
      "All Rights Reserved.\n",
      "\n",
      "Copyright (c) 1995-2001 Corporation for National Research Initiatives.\n",
      "All Rights Reserved.\n",
      "\n",
      "Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\n",
      "All Rights Reserved., 'NameError': <type 'exceptions.NameError'>, 'BytesWarning': <type 'exceptions.BytesWarning'>, 'dict': <type 'dict'>, 'input': <function <lambda> at 0x1039bfb18>, 'oct': <built-in function oct>, 'bin': <built-in function bin>, 'SystemExit': <type 'exceptions.SystemExit'>, 'StandardError': <type 'exceptions.StandardError'>, 'format': <built-in function format>, 'repr': <built-in function repr>, 'sorted': <built-in function sorted>, 'False': False, 'RuntimeWarning': <type 'exceptions.RuntimeWarning'>, 'list': <type 'list'>, 'iter': <built-in function iter>, 'reload': <built-in function reload>, 'Warning': <type 'exceptions.Warning'>, '__package__': None, 'round': <built-in function round>, 'dir': <built-in function dir>, 'cmp': <built-in function cmp>, 'set': <type 'set'>, 'bytes': <type 'str'>, 'reduce': <built-in function reduce>, 'intern': <built-in function intern>, 'issubclass': <built-in function issubclass>, 'Ellipsis': Ellipsis, 'EOFError': <type 'exceptions.EOFError'>, 'locals': <built-in function locals>, 'BufferError': <type 'exceptions.BufferError'>, 'slice': <type 'slice'>, 'FloatingPointError': <type 'exceptions.FloatingPointError'>, 'sum': <built-in function sum>, 'getattr': <built-in function getattr>, 'abs': <built-in function abs>, 'print': <built-in function print>, 'True': True, 'FutureWarning': <type 'exceptions.FutureWarning'>, 'ImportWarning': <type 'exceptions.ImportWarning'>, 'None': None, 'hash': <built-in function hash>, 'ReferenceError': <type 'exceptions.ReferenceError'>, 'len': <built-in function len>, 'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands\n",
      "    for supporting Python development.  See www.python.org for more information., 'frozenset': <type 'frozenset'>, '__name__': '__builtin__', 'ord': <built-in function ord>, 'super': <type 'super'>, 'TypeError': <type 'exceptions.TypeError'>, 'license': Type license() to see the full license text, 'KeyboardInterrupt': <type 'exceptions.KeyboardInterrupt'>, 'UserWarning': <type 'exceptions.UserWarning'>, 'filter': <built-in function filter>, 'range': <built-in function range>, 'staticmethod': <type 'staticmethod'>, 'SystemError': <type 'exceptions.SystemError'>, 'BaseException': <type 'exceptions.BaseException'>, 'pow': <built-in function pow>, 'RuntimeError': <type 'exceptions.RuntimeError'>, 'float': <type 'float'>, 'MemoryError': <type 'exceptions.MemoryError'>, 'StopIteration': <type 'exceptions.StopIteration'>, 'globals': <built-in function globals>, 'divmod': <built-in function divmod>, 'enumerate': <type 'enumerate'>, 'apply': <built-in function apply>, 'LookupError': <type 'exceptions.LookupError'>, 'open': <built-in function open>, 'basestring': <type 'basestring'>, 'UnicodeError': <type 'exceptions.UnicodeError'>, 'zip': <built-in function zip>, 'hex': <built-in function hex>, 'long': <type 'long'>, 'next': <built-in function next>, 'ImportError': <type 'exceptions.ImportError'>, 'chr': <built-in function chr>, 'xrange': <type 'xrange'>, 'type': <type 'type'>, '__doc__': \"Built-in functions, exceptions, and other objects.\\n\\nNoteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\", 'Exception': <type 'exceptions.Exception'>, '__IPYTHON__': True, 'tuple': <type 'tuple'>, 'UnicodeTranslateError': <type 'exceptions.UnicodeTranslateError'>, 'reversed': <type 'reversed'>, 'UnicodeEncodeError': <type 'exceptions.UnicodeEncodeError'>, 'IOError': <type 'exceptions.IOError'>, 'hasattr': <built-in function hasattr>, 'delattr': <built-in function delattr>, 'setattr': <built-in function setattr>, 'raw_input': <bound method IPythonKernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x103ae6c90>>, 'SyntaxWarning': <type 'exceptions.SyntaxWarning'>, 'compile': <built-in function compile>, 'ArithmeticError': <type 'exceptions.ArithmeticError'>, 'str': <type 'str'>, 'property': <type 'property'>, 'dreload': <function _dreload at 0x10347c5f0>, 'GeneratorExit': <type 'exceptions.GeneratorExit'>, 'int': <type 'int'>, '__import__': <built-in function __import__>, 'KeyError': <type 'exceptions.KeyError'>, 'coerce': <built-in function coerce>, 'PendingDeprecationWarning': <type 'exceptions.PendingDeprecationWarning'>, 'file': <type 'file'>, 'EnvironmentError': <type 'exceptions.EnvironmentError'>, 'unichr': <built-in function unichr>, 'id': <built-in function id>, 'OSError': <type 'exceptions.OSError'>, 'DeprecationWarning': <type 'exceptions.DeprecationWarning'>, 'min': <built-in function min>, 'UnicodeWarning': <type 'exceptions.UnicodeWarning'>, 'execfile': <built-in function execfile>, 'any': <built-in function any>, 'complex': <type 'complex'>, 'bool': <type 'bool'>, 'get_ipython': <bound method ZMQInteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x103ae6cd0>>, 'ValueError': <type 'exceptions.ValueError'>, 'NotImplemented': NotImplemented, 'map': <built-in function map>, 'buffer': <type 'buffer'>, 'max': <built-in function max>, 'object': <type 'object'>, 'TabError': <type 'exceptions.TabError'>, 'callable': <built-in function callable>, 'ZeroDivisionError': <type 'exceptions.ZeroDivisionError'>, 'eval': <built-in function eval>, '__debug__': True, 'IndentationError': <type 'exceptions.IndentationError'>, 'AssertionError': <type 'exceptions.AssertionError'>, 'classmethod': <type 'classmethod'>, 'UnboundLocalError': <type 'exceptions.UnboundLocalError'>, 'NotImplementedError': <type 'exceptions.NotImplementedError'>, 'AttributeError': <type 'exceptions.AttributeError'>, 'OverflowError': <type 'exceptions.OverflowError'>}, 'rec_join': <function rec_join at 0x10a99c758>, 'cumproduct': <function cumproduct at 0x104d5ade8>, 'diagonal': <function diagonal at 0x104d5a758>, 'atleast_1d': <function atleast_1d at 0x104d75b18>, 'meshgrid': <function meshgrid at 0x104e04488>, 'eventplot': <function eventplot at 0x109d465f0>, '___': 0          False\n",
      "1          False\n",
      "2          False\n",
      "3          False\n",
      "4          False\n",
      "5          False\n",
      "6          False\n",
      "7          False\n",
      "8          False\n",
      "9          False\n",
      "10         False\n",
      "11         False\n",
      "12         False\n",
      "13         False\n",
      "14         False\n",
      "15         False\n",
      "16         False\n",
      "17         False\n",
      "18         False\n",
      "19         False\n",
      "20         False\n",
      "21         False\n",
      "22         False\n",
      "23         False\n",
      "24         False\n",
      "25         False\n",
      "26         False\n",
      "27         False\n",
      "28         False\n",
      "29         False\n",
      "           ...  \n",
      "3554391    False\n",
      "3554392    False\n",
      "3554393    False\n",
      "3554394    False\n",
      "3554395    False\n",
      "3554396    False\n",
      "3554397    False\n",
      "3554398    False\n",
      "3554399    False\n",
      "3554400    False\n",
      "3554401    False\n",
      "3554402    False\n",
      "3554403    False\n",
      "3554404    False\n",
      "3554405    False\n",
      "3554406    False\n",
      "3554407    False\n",
      "3554408    False\n",
      "3554409    False\n",
      "3554410    False\n",
      "3554411    False\n",
      "3554412    False\n",
      "3554413    False\n",
      "3554414    False\n",
      "3554415    False\n",
      "3554416    False\n",
      "3554417    False\n",
      "3554418    False\n",
      "3554419    False\n",
      "3554420    False\n",
      "Name: starttime, dtype: bool, 'remainder': <ufunc 'remainder'>, 'expm1': <ufunc 'expm1'>, 'isfinite': <ufunc 'isfinite'>, 'matmul': <built-in function matmul>, 'place': <function place at 0x104e007d0>, 'DataSource': <class 'numpy.lib._datasource.DataSource'>, 'epoch2num': <function epoch2num at 0x1060457d0>, 'ndim': <function ndim at 0x104d5c1b8>, 'irfft': <function irfft at 0x104e77aa0>, 'subplots_adjust': <function subplots_adjust at 0x109d19cf8>, 'rint': <ufunc 'rint'>, 'arctan2': <ufunc 'arctan2'>, 'little_endian': True, 'hfft': <function hfft at 0x104e779b0>, 'array': <built-in function array>, 'common_type': <function common_type at 0x104dcd9b0>, 'accs': [0.86440185830429728, 0.86939605110336815, 0.87427409988385596], 'size': <function size at 0x104d5c2a8>, 'logical_xor': <ufunc 'logical_xor'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'sometrue': <function sometrue at 0x104d5ab90>, 'df_combined':       period  start_count  station_id  stop_count\n",
      "0          0            1         173           0\n",
      "1          0            1         263           0\n",
      "2          0            1         274           0\n",
      "3          0            1         285           0\n",
      "4          0            1         307           0\n",
      "5          0            1         316           0\n",
      "6          0            1         317           0\n",
      "7          0            1         326           0\n",
      "8          0            1         347           0\n",
      "9          0            1         358           0\n",
      "10         0            1         361           0\n",
      "11         0            2         386           0\n",
      "12         0            2         397           0\n",
      "13         0            1         410           0\n",
      "14         0            1         450           0\n",
      "15         0            1         463           0\n",
      "16         0            2         479           0\n",
      "17         0            1         488           0\n",
      "18         0            2         495           0\n",
      "19         0            1         509           0\n",
      "20         0            2         536           0\n",
      "21         0            1         545           0\n",
      "22         0            1        2003           0\n",
      "23         0            1        2004           0\n",
      "24         0            1        2021           0\n",
      "25         0            1        3075           0\n",
      "26         0            1        3119           0\n",
      "27         0            2        3133           0\n",
      "28         1            1         274           0\n",
      "29         1            1         293           0\n",
      "...      ...          ...         ...         ...\n",
      "6039     120            0         293           1\n",
      "6040     120            0         301           1\n",
      "6041     120            0         347           1\n",
      "6042     120            0         388           1\n",
      "6043     120            0         466           1\n",
      "6044     123            0         301           1\n",
      "6045     125            0         473           1\n",
      "6046     125            0         474           1\n",
      "6047     126            0         417           1\n",
      "6048     126            0         533           1\n",
      "6049     132            0         151           1\n",
      "6050     133            0         499           1\n",
      "6051     136            0         447           1\n",
      "6052     136            0         458           1\n",
      "6053     137            0         519           1\n",
      "6054     141            0         153           1\n",
      "6055     147            0         151           1\n",
      "6056     147            0         348           1\n",
      "6057     149            0         444           1\n",
      "6058     151            0          72           1\n",
      "6059     156            0         521           1\n",
      "6060     203            0         401           1\n",
      "6061     210            0         293           1\n",
      "6062     211            0         517           1\n",
      "6063     212            0         447           1\n",
      "6064     222            0        2023           1\n",
      "6065     226            0         430           1\n",
      "6066     226            0        3002           1\n",
      "6067     228            0         432           1\n",
      "6068     417            0         239           1\n",
      "\n",
      "[12112 rows x 4 columns], 'bool8': <type 'numpy.bool_'>, 'colormaps': <function colormaps at 0x109d20758>, 'msort': <function msort at 0x104e040c8>, 'alltrue': <function alltrue at 0x104d5ac08>, 'ispower2': <function ispower2 at 0x10a99c320>, 'LogFormatterExponent': <class 'matplotlib.ticker.LogFormatterExponent'>, 'ihfft': <function ihfft at 0x104e77a28>, 'nansum': <function nansum at 0x104e13320>, 'bool_': <type 'numpy.bool_'>, 'histogramdd': <function histogramdd at 0x104de9d70>, 'nanpercentile': <function nanpercentile at 0x104e13668>, 'broadcast': <type 'numpy.broadcast'>, 'short': <type 'numpy.int16'>, 'arctanh': <ufunc 'arctanh'>, 'typecodes': {'All': '?bhilqpBHILQPefdgFDGSUVOMm', 'Complex': 'FDG', 'AllFloat': 'efdgFDG', 'Integer': 'bhilqp', 'UnsignedInteger': 'BHILQP', 'Float': 'efdg', 'Character': 'c', 'Datetime': 'Mm', 'AllInteger': 'bBhHiIlLqQpP'}, 'rot90': <function rot90 at 0x104de96e0>, 'savetxt': <function savetxt at 0x104e75488>, 'copy': <function copy at 0x104e002a8>, 'sctypes': {'int': [<type 'numpy.int8'>, <type 'numpy.int16'>, <type 'numpy.int32'>, <type 'numpy.int64'>], 'float': [<type 'numpy.float16'>, <type 'numpy.float32'>, <type 'numpy.float64'>, <type 'numpy.float128'>], 'uint': [<type 'numpy.uint8'>, <type 'numpy.uint16'>, <type 'numpy.uint32'>, <type 'numpy.uint64'>], 'complex': [<type 'numpy.complex64'>, <type 'numpy.complex128'>, <type 'numpy.complex256'>], 'others': [<type 'bool'>, <type 'object'>, <type 'str'>, <type 'unicode'>, <type 'numpy.void'>]}, 'segments_intersect': <function segments_intersect at 0x1081d08c0>, 'not_equal': <ufunc 'not_equal'>, 'tril_indices_from': <function tril_indices_from at 0x104de9c08>, 'require': <function require at 0x104d409b0>, '_iii': u'df[df[\"starttime\"].isnull() == True]', 'xlabel': <function xlabel at 0x109d20050>, 'typeNA': {<type 'numpy.uint8'>: 'UInt8', <type 'numpy.object_'>: 'Object0', <type 'numpy.complex64'>: 'Complex32', 'Int32': <type 'numpy.int32'>, 'Complex64': <type 'numpy.complex128'>, <type 'numpy.complex128'>: 'Complex64', 'm8': 'Timedelta64', <type 'numpy.string_'>: 'String0', 'UInt32': <type 'numpy.uint32'>, <type 'numpy.complex256'>: 'Complex128', 'D': 'Complex64', 'H': 'UInt16', 'L': 'UInt64', <type 'numpy.unicode_'>: 'Unicode0', 'd': 'Float64', 'h': 'Int16', 'l': 'Int64', 'c32': 'Complex128', <type 'numpy.int8'>: 'Int8', 'Timedelta64': <type 'numpy.timedelta64'>, <type 'numpy.void'>: 'Void0', 'b1': 'Bool', 'M8': 'Datetime64', 'String0': <type 'numpy.string_'>, 'I': 'UInt32', <type 'numpy.int32'>: 'Int32', '?': 'Bool', 'Void0': <type 'numpy.void'>, 'Float64': <type 'numpy.float64'>, 'G': 'Complex128', 'O': 'Object0', <type 'numpy.int64'>: 'Int64', 'S': 'String0', <type 'numpy.bool_'>: 'Bool', 'UInt64': <type 'numpy.uint64'>, 'g': 'Float128', <type 'numpy.int64'>: 'Int64', 'UInt8': <type 'numpy.uint8'>, 'Float16': <type 'numpy.float16'>, 'Bool': <type 'numpy.bool_'>, <type 'numpy.uint16'>: 'UInt16', 'u8': <type 'numpy.uint64'>, 'u4': <type 'numpy.uint32'>, 'Unicode0': <type 'numpy.unicode_'>, 'u1': <type 'numpy.uint8'>, 'u2': <type 'numpy.uint16'>, <type 'numpy.uint32'>: 'UInt32', 'Datetime64': <type 'numpy.datetime64'>, 'Int8': <type 'numpy.int8'>, 'B': 'UInt8', 'F': 'Complex32', <type 'numpy.uint64'>: 'UInt64', 'c8': 'Complex32', 'Int64': <type 'numpy.int64'>, 'Complex32': <type 'numpy.complex64'>, 'V': 'Void0', 'Float32': <type 'numpy.float32'>, <type 'numpy.uint64'>: 'UInt64', 'b': 'Int8', 'f': 'Float32', 'c16': 'Complex64', <type 'numpy.float16'>: 'Float16', 'f16': 'Float128', 'f2': 'Float16', 'f4': 'Float32', 'f8': 'Float64', 'Complex128': <type 'numpy.complex256'>, <type 'numpy.float32'>: 'Float32', 'Object0': <type 'numpy.object_'>, 'Int16': <type 'numpy.int16'>, <type 'numpy.float64'>: 'Float64', 'UInt16': <type 'numpy.uint16'>, <type 'numpy.int16'>: 'Int16', 'i8': <type 'numpy.int64'>, <type 'numpy.float128'>: 'Float128', 'i1': <type 'numpy.int8'>, 'i2': <type 'numpy.int16'>, 'M': 'Datetime64', 'i4': <type 'numpy.int32'>, 'Q': 'UInt64', 'U': 'Unicode0', <type 'numpy.datetime64'>: 'Datetime64', 'e': 'Float16', 'i': 'Int32', 'm': 'Timedelta64', 'q': 'Int64', <type 'numpy.timedelta64'>: 'Timedelta64', 'Float128': <type 'numpy.float128'>}, 'getbuffer': <built-in function getbuffer>, 'xcorr': <function xcorr at 0x109d47668>, 'slogdet': <function slogdet at 0x104e15c80>, 'clip': <function clip at 0x104d5aa28>, 'savez_compressed': <function savez_compressed at 0x104e75230>, 'frompyfunc': <built-in function frompyfunc>, 'barh': <function barh at 0x109d461b8>, 'clim': <function clim at 0x109d208c0>, 'any': <function any at 0x104d5ac80>, 'cross_validation': <module 'sklearn.cross_validation' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/sklearn/cross_validation.pyc'>, 'asfortranarray': <function asfortranarray at 0x104d40a28>, 'binary_repr': <function binary_repr at 0x104d5d5f0>, 'angle': <function angle at 0x104e00488>, '_i9': u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nstart = time.time()\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\n\\ndef analyze(row_limit, k_folds=5, threshold_out=1, tree_count=10, period_minutes=5):\\n    \"\"\"\\n    We can tune the following parameters:\\n    - number of rows we analyze\\n    - number of folds in our standard k-fold cross-validation\\n    - number of bicycles taken out in the period to be considered in the positive class\\n    - number of trees in our random forest\\n    - number of minutes in our period\\n    \"\"\"\\n    df = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=row_limit)\\n    # Convert to timestamps \\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\n    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n    # Convert int64index to datetime index\\n    # Group using timegrouper and create new column for start period and stop period\\n    df = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\n    start_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\n    df[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\n    df = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\n    stop_time_group_by = df.groupby(pd.TimeGrouper(\\'{}Min\\'.format(period_minutes)),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\n    df[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n    # Create two sub dataframes, grouping on and aggregating start data and then stop data\\n    grouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\n    df_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\n    df_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\n    grouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\n    df_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\n    df_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n    # Combine these two dataframes and fill N/A values to 0\\n    df_combined = pd.concat([df_start, df_stop])\\n    df_combined = df_combined.fillna(0)\\n\\n    # Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n    # And reset the multi-level index so we have a normal DataFrame\\n    aggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n    # Let\\'s construct a pivot table\\n    pivoted = pd.pivot_table(\\n        aggregate_data,\\n        index=[\"period\"],\\n        columns=[\"station_id\"],\\n        aggfunc=np.sum,\\n        fill_value=0)\\n\\n    # Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\n    deeper_cols = pivoted.columns.get_level_values(1)\\n    top_level_cols = pivoted.columns.get_level_values(0)\\n\\n    # Flattening the columns\\n    resultant_cols = []    \\n    for i, station_id in enumerate(deeper_cols):\\n        if top_level_cols[i] == \"start_count\":\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n        else:\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\n    pivoted.columns = resultant_cols\\n    pivoted = pivoted.reset_index()\\n    print \"{} rows in the pivoted table\".format(len(pivoted))\\n    X = pivoted.copy()\\n    # Turn number of out in station TARGET_STATION_ID into 1s and 0s\\n    answer_series = (\\n        pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > threshhold_out).apply(int)\\n    X = X[:-1]\\n    y = answer_series[1:]\\n\\n    classifier = RandomForestClassifier(n_estimators=tree_count)\\n    scores = cross_validation.cross_val_score(\\n        classifier,\\n        X,\\n        y,\\n        cv=k_folds\\n    )\\n\\n    end = time.time()\\n    print \"Rows: {}, k={}\".format(row_limit, k_folds)\\n    print \"Mean accuracy: {}\".format(np.mean(scores))\\n    print \"Standard deviation: {}\".format(np.std(scores))\\n    print \"Took {}s\".format(end - start)', '_i8': u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nstart = time.time()\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\n\\ndef analyze(row_limit, k_folds=5, threshold_out=1, tree_count=10):\\n    df = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=row_limit)\\n    # Convert to timestamps \\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\n    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n    # Convert int64index to datetime index\\n    # Group using timegrouper and create new column for start period and stop period\\n    df = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\n    start_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\n    df[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\n    df = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\n    stop_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\n    df[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n    # Create two sub dataframes, grouping on and aggregating start data and then stop data\\n    grouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\n    df_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\n    df_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\n    grouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\n    df_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\n    df_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n    # Combine these two dataframes and fill N/A values to 0\\n    df_combined = pd.concat([df_start, df_stop])\\n    df_combined = df_combined.fillna(0)\\n\\n    # Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n    # And reset the multi-level index so we have a normal DataFrame\\n    aggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n    # Let\\'s construct a pivot table\\n    pivoted = pd.pivot_table(\\n        aggregate_data,\\n        index=[\"period\"],\\n        columns=[\"station_id\"],\\n        aggfunc=np.sum,\\n        fill_value=0)\\n\\n    # Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\n    deeper_cols = pivoted.columns.get_level_values(1)\\n    top_level_cols = pivoted.columns.get_level_values(0)\\n\\n    # Flattening the columns\\n    resultant_cols = []    \\n    for i, station_id in enumerate(deeper_cols):\\n        if top_level_cols[i] == \"start_count\":\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n        else:\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\n    pivoted.columns = resultant_cols\\n    pivoted = pivoted.reset_index()\\n    print \"{} rows in the pivoted table\".format(len(pivoted))\\n    X = pivoted.copy()\\n    # Turn number of out in station TARGET_STATION_ID into 1s and 0s\\n    answer_series = (\\n        pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > threshhold_out).apply(int)\\n    X = X[:-1]\\n    y = answer_series[1:]\\n\\n    classifier = RandomForestClassifier(n_estimators=tree_count)\\n    scores = cross_validation.cross_val_score(\\n        classifier,\\n        X,\\n        y,\\n        cv=k_folds\\n    )\\n\\n    end = time.time()\\n    print \"Rows: {}, k={}\".format(row_limit, k_folds)\\n    print \"Mean accuracy: {}\".format(np.mean(scores))\\n    print \"Standard deviation: {}\".format(np.std(scores))\\n    print \"Took {}s\".format(end - start)', '_i7': u'analyze(1000000)', '_i6': u'analyze(10000)', '_i5': u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nstart = time.time()\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\n\\ndef analyze(row_limit, k_folds=5):\\n    df = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=row_limit)\\n    # Convert to timestamps \\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\n    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n    # Convert int64index to datetime index\\n    # Group using timegrouper and create new column for start period and stop period\\n    df = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\n    start_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\n    df[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\n    df = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\n    stop_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\n    df[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n    # Create two sub dataframes, grouping on and aggregating start data and then stop data\\n    grouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\n    df_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\n    df_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\n    grouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\n    df_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\n    df_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n    # Combine these two dataframes and fill N/A values to 0\\n    df_combined = pd.concat([df_start, df_stop])\\n    df_combined = df_combined.fillna(0)\\n\\n    # Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n    # And reset the multi-level index so we have a normal DataFrame\\n    aggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n    # Let\\'s construct a pivot table\\n    pivoted = pd.pivot_table(\\n        aggregate_data,\\n        index=[\"period\"],\\n        columns=[\"station_id\"],\\n        aggfunc=np.sum,\\n        fill_value=0)\\n\\n    # Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\n    deeper_cols = pivoted.columns.get_level_values(1)\\n    top_level_cols = pivoted.columns.get_level_values(0)\\n\\n    # Flattening the columns\\n    resultant_cols = []    \\n    for i, station_id in enumerate(deeper_cols):\\n        if top_level_cols[i] == \"start_count\":\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n        else:\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\n    pivoted.columns = resultant_cols\\n    pivoted = pivoted.reset_index()\\n    print \"{} rows in the pivoted table\".format(len(pivoted))\\n    X = pivoted.copy()\\n    # Turn number of out in station TARGET_STATION_ID into 1s and 0s\\n    answer_series = (\\n        pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > 1).apply(int)\\n    X = X[:-1]\\n    y = answer_series[1:]\\n\\n    classifier = RandomForestClassifier()\\n    scores = cross_validation.cross_val_score(\\n        classifier,\\n        X,\\n        y,\\n        cv=k_folds\\n    )\\n\\n    end = time.time()\\n    print \"Rows: {}, k={}\".format(row_limit, k_folds)\\n    print \"Mean accuracy: {}\".format(np.mean(scores))\\n    print \"Standard deviation: {}\".format(np.std(scores))\\n    print \"Took {}s\".format(end - start)', '_i4': u'analyze(100000)', '_i3': u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nstart = time.time()\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\n\\ndef analyze(row_limit, k_folds=5):\\n    df = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=row_limit)\\n    # Convert to timestamps \\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\n    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n    # Convert int64index to datetime index\\n    # Group using timegrouper and create new column for start period and stop period\\n    df = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\n    start_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\n    df[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\n    df = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\n    stop_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\n    df[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n    # Create two sub dataframes, grouping on and aggregating start data and then stop data\\n    grouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\n    df_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\n    df_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\n    grouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\n    df_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\n    df_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n    # Combine these two dataframes and fill N/A values to 0\\n    df_combined = pd.concat([df_start, df_stop])\\n    df_combined = df_combined.fillna(0)\\n\\n    # Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n    # And reset the multi-level index so we have a normal DataFrame\\n    aggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n    # Let\\'s construct a pivot table\\n    pivoted = pd.pivot_table(\\n        aggregate_data,\\n        index=[\"period\"],\\n        columns=[\"station_id\"],\\n        aggfunc=np.sum,\\n        fill_value=0)\\n\\n    # Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\n    deeper_cols = pivoted.columns.get_level_values(1)\\n    top_level_cols = pivoted.columns.get_level_values(0)\\n\\n    # Flattening the columns\\n    resultant_cols = []    \\n    for i, station_id in enumerate(deeper_cols):\\n        if top_level_cols[i] == \"start_count\":\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n        else:\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\n    pivoted.columns = resultant_cols\\n    pivoted = pivoted.reset_index()\\n\\n    X = pivoted.copy()\\n    # Turn number of out in station TARGET_STATION_ID into 1s and 0s\\n    answer_series = (\\n        pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > 1).apply(int)\\n    X = X[:-1]\\n    y = answer_series[1:]\\n\\n    classifier = RandomForestClassifier()\\n    scores = cross_validation.cross_val_score(\\n        classifier,\\n        X,\\n        y,\\n        cv=k_folds\\n    )\\n\\n    end = time.time()\\n    print \"Rows: {}, k={}\".format(row_limit, k_folds)\\n    print \"Mean accuracy: {}\".format(np.mean(scores))\\n    print \"Standard deviation: {}\".format(np.std(scores))\\n    print \"Took {}s\".format(end - start)', '_i2': u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nstart = time.time()\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\ndf = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=ROW_LIMIT)\\n# Convert to timestamps \\ndf[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\ndf[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n# Convert int64index to datetime index\\n# Group using timegrouper and create new column for start period and stop period\\ndf = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\nstart_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\ndf[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\ndf = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\nstop_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\ndf[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n# Create two sub dataframes, grouping on and aggregating start data and then stop data\\ngrouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\ndf_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\ndf_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\ngrouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\ndf_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\ndf_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n# Combine these two dataframes and fill N/A values to 0\\ndf_combined = pd.concat([df_start, df_stop])\\ndf_combined = df_combined.fillna(0)\\n\\n# Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n# And reset the multi-level index so we have a normal DataFrame\\naggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n# Let\\'s construct a pivot table\\npivoted = pd.pivot_table(\\n    aggregate_data,\\n    index=[\"period\"],\\n    columns=[\"station_id\"],\\n    aggfunc=np.sum,\\n    fill_value=0)\\n\\n# Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\ndeeper_cols = pivoted.columns.get_level_values(1)\\ntop_level_cols = pivoted.columns.get_level_values(0)\\n\\n# Flattening the columns\\nresultant_cols = []    \\nfor i, station_id in enumerate(deeper_cols):\\n    if top_level_cols[i] == \"start_count\":\\n        resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n    else:\\n        resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\npivoted.columns = resultant_cols\\npivoted = pivoted.reset_index()\\n\\nX = pivoted.copy()\\n# Turn number of out in station TARGET_STATION_ID into 1s and 0s\\nanswer_series = (\\n    pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > 1).apply(int)\\nX = X[:-1]\\ny = answer_series[1:]\\n\\nclassifier = RandomForestClassifier()\\nscores = cross_validation.cross_val_score(\\n    classifier,\\n    X,\\n    y,\\n    cv=10\\n)\\n\\nprint scores\\nprint np.mean(scores)\\nprint np.std(scores)\\nend = time.time()\\nprint end - start', '_i1': u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\n\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\ndf = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=ROW_LIMIT)\\n# Convert to timestamps \\ndf[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\ndf[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n# Convert int64index to datetime index\\n# Group using timegrouper and create new column for start period and stop period\\ndf = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\nstart_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\ndf[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\ndf = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\nstop_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\ndf[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n# Combine these two dataframes and fill N/A values to 0\\ndf_combined = pd.concat([df_start, df_stop])\\ndf_combined = df_combined.fillna(0)\\n\\n# Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n# And reset the multi-level index so we have a normal DataFrame\\naggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n# Let\\'s construct a pivot table\\npivoted = pd.pivot_table(\\n    aggregate_data,\\n    index=[\"period\"],\\n    columns=[\"station_id\"],\\n    aggfunc=np.sum,\\n    fill_value=0)\\n\\n# Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\ndeeper_cols = pivoted.columns.get_level_values(1)\\ntop_level_cols = pivoted.columns.get_level_values(0)\\n\\n# Flattening the columns\\nresultant_cols = []    \\nfor i, station_id in enumerate(deeper_cols):\\n    if top_level_cols[i] == \"start_count\":\\n        resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n    else:\\n        resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\npivoted.columns = resultant_cols\\npivoted = pivoted.reset_index()\\n\\nX = pivoted.copy()\\n# Turn number of out in station TARGET_STATION_ID into 1s and 0s\\nanswer_series = (\\n    pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > 1).apply(int)\\nX = X[:-1]\\ny = answer_series[1:]\\n\\nclassifier = RandomForestClassifier()\\nscores = cross_validation.cross_val_score(\\n    classifier,\\n    X,\\n    y,\\n    cv=10\\n)\\n\\nprint scores\\nprint np.mean(scores)\\nprint np.std(scores)', 'figlegend': <function figlegend at 0x109d19410>, 'ERR_LOG': 5, 'right_shift': <ufunc 'right_shift'>, 'take': <function take at 0x104d3e7d0>, 'SecondLocator': <class 'matplotlib.dates.SecondLocator'>, 'byte_bounds': <function byte_bounds at 0x104df9b90>, 'trace': <function trace at 0x104d5a7d0>, 'normal': <built-in method normal of mtrand.RandomState object at 0x104ee18d0>, 'who': <function who at 0x104df9b18>, 'compress': <function compress at 0x104d5a9b0>, 'NullFormatter': <class 'matplotlib.ticker.NullFormatter'>, 'beta': <built-in method beta of mtrand.RandomState object at 0x104ee18d0>, 'multiply': <ufunc 'multiply'>, 'mask_indices': <function mask_indices at 0x104de9b18>, 'dist_point_to_segment': <function dist_point_to_segment at 0x1081d0848>, '_ii': u'df[df[\"stoptime\"].isnull() == True]', '_ih': ['', u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\n\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\ndf = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=ROW_LIMIT)\\n# Convert to timestamps \\ndf[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\ndf[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n# Convert int64index to datetime index\\n# Group using timegrouper and create new column for start period and stop period\\ndf = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\nstart_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\ndf[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\ndf = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\nstop_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\ndf[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n# Combine these two dataframes and fill N/A values to 0\\ndf_combined = pd.concat([df_start, df_stop])\\ndf_combined = df_combined.fillna(0)\\n\\n# Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n# And reset the multi-level index so we have a normal DataFrame\\naggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n# Let\\'s construct a pivot table\\npivoted = pd.pivot_table(\\n    aggregate_data,\\n    index=[\"period\"],\\n    columns=[\"station_id\"],\\n    aggfunc=np.sum,\\n    fill_value=0)\\n\\n# Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\ndeeper_cols = pivoted.columns.get_level_values(1)\\ntop_level_cols = pivoted.columns.get_level_values(0)\\n\\n# Flattening the columns\\nresultant_cols = []    \\nfor i, station_id in enumerate(deeper_cols):\\n    if top_level_cols[i] == \"start_count\":\\n        resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n    else:\\n        resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\npivoted.columns = resultant_cols\\npivoted = pivoted.reset_index()\\n\\nX = pivoted.copy()\\n# Turn number of out in station TARGET_STATION_ID into 1s and 0s\\nanswer_series = (\\n    pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > 1).apply(int)\\nX = X[:-1]\\ny = answer_series[1:]\\n\\nclassifier = RandomForestClassifier()\\nscores = cross_validation.cross_val_score(\\n    classifier,\\n    X,\\n    y,\\n    cv=10\\n)\\n\\nprint scores\\nprint np.mean(scores)\\nprint np.std(scores)', u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nstart = time.time()\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\ndf = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=ROW_LIMIT)\\n# Convert to timestamps \\ndf[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\ndf[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n# Convert int64index to datetime index\\n# Group using timegrouper and create new column for start period and stop period\\ndf = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\nstart_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\ndf[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\ndf = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\nstop_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\ndf[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n# Create two sub dataframes, grouping on and aggregating start data and then stop data\\ngrouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\ndf_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\ndf_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\ngrouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\ndf_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\ndf_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n# Combine these two dataframes and fill N/A values to 0\\ndf_combined = pd.concat([df_start, df_stop])\\ndf_combined = df_combined.fillna(0)\\n\\n# Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n# And reset the multi-level index so we have a normal DataFrame\\naggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n# Let\\'s construct a pivot table\\npivoted = pd.pivot_table(\\n    aggregate_data,\\n    index=[\"period\"],\\n    columns=[\"station_id\"],\\n    aggfunc=np.sum,\\n    fill_value=0)\\n\\n# Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\ndeeper_cols = pivoted.columns.get_level_values(1)\\ntop_level_cols = pivoted.columns.get_level_values(0)\\n\\n# Flattening the columns\\nresultant_cols = []    \\nfor i, station_id in enumerate(deeper_cols):\\n    if top_level_cols[i] == \"start_count\":\\n        resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n    else:\\n        resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\npivoted.columns = resultant_cols\\npivoted = pivoted.reset_index()\\n\\nX = pivoted.copy()\\n# Turn number of out in station TARGET_STATION_ID into 1s and 0s\\nanswer_series = (\\n    pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > 1).apply(int)\\nX = X[:-1]\\ny = answer_series[1:]\\n\\nclassifier = RandomForestClassifier()\\nscores = cross_validation.cross_val_score(\\n    classifier,\\n    X,\\n    y,\\n    cv=10\\n)\\n\\nprint scores\\nprint np.mean(scores)\\nprint np.std(scores)\\nend = time.time()\\nprint end - start', u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nstart = time.time()\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\n\\ndef analyze(row_limit, k_folds=5):\\n    df = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=row_limit)\\n    # Convert to timestamps \\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\n    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n    # Convert int64index to datetime index\\n    # Group using timegrouper and create new column for start period and stop period\\n    df = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\n    start_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\n    df[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\n    df = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\n    stop_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\n    df[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n    # Create two sub dataframes, grouping on and aggregating start data and then stop data\\n    grouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\n    df_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\n    df_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\n    grouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\n    df_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\n    df_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n    # Combine these two dataframes and fill N/A values to 0\\n    df_combined = pd.concat([df_start, df_stop])\\n    df_combined = df_combined.fillna(0)\\n\\n    # Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n    # And reset the multi-level index so we have a normal DataFrame\\n    aggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n    # Let\\'s construct a pivot table\\n    pivoted = pd.pivot_table(\\n        aggregate_data,\\n        index=[\"period\"],\\n        columns=[\"station_id\"],\\n        aggfunc=np.sum,\\n        fill_value=0)\\n\\n    # Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\n    deeper_cols = pivoted.columns.get_level_values(1)\\n    top_level_cols = pivoted.columns.get_level_values(0)\\n\\n    # Flattening the columns\\n    resultant_cols = []    \\n    for i, station_id in enumerate(deeper_cols):\\n        if top_level_cols[i] == \"start_count\":\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n        else:\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\n    pivoted.columns = resultant_cols\\n    pivoted = pivoted.reset_index()\\n\\n    X = pivoted.copy()\\n    # Turn number of out in station TARGET_STATION_ID into 1s and 0s\\n    answer_series = (\\n        pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > 1).apply(int)\\n    X = X[:-1]\\n    y = answer_series[1:]\\n\\n    classifier = RandomForestClassifier()\\n    scores = cross_validation.cross_val_score(\\n        classifier,\\n        X,\\n        y,\\n        cv=k_folds\\n    )\\n\\n    end = time.time()\\n    print \"Rows: {}, k={}\".format(row_limit, k_folds)\\n    print \"Mean accuracy: {}\".format(np.mean(scores))\\n    print \"Standard deviation: {}\".format(np.std(scores))\\n    print \"Took {}s\".format(end - start)', u'analyze(100000)', u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nstart = time.time()\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\n\\ndef analyze(row_limit, k_folds=5):\\n    df = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=row_limit)\\n    # Convert to timestamps \\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\n    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n    # Convert int64index to datetime index\\n    # Group using timegrouper and create new column for start period and stop period\\n    df = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\n    start_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\n    df[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\n    df = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\n    stop_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\n    df[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n    # Create two sub dataframes, grouping on and aggregating start data and then stop data\\n    grouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\n    df_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\n    df_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\n    grouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\n    df_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\n    df_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n    # Combine these two dataframes and fill N/A values to 0\\n    df_combined = pd.concat([df_start, df_stop])\\n    df_combined = df_combined.fillna(0)\\n\\n    # Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n    # And reset the multi-level index so we have a normal DataFrame\\n    aggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n    # Let\\'s construct a pivot table\\n    pivoted = pd.pivot_table(\\n        aggregate_data,\\n        index=[\"period\"],\\n        columns=[\"station_id\"],\\n        aggfunc=np.sum,\\n        fill_value=0)\\n\\n    # Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\n    deeper_cols = pivoted.columns.get_level_values(1)\\n    top_level_cols = pivoted.columns.get_level_values(0)\\n\\n    # Flattening the columns\\n    resultant_cols = []    \\n    for i, station_id in enumerate(deeper_cols):\\n        if top_level_cols[i] == \"start_count\":\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n        else:\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\n    pivoted.columns = resultant_cols\\n    pivoted = pivoted.reset_index()\\n    print \"{} rows in the pivoted table\".format(len(pivoted))\\n    X = pivoted.copy()\\n    # Turn number of out in station TARGET_STATION_ID into 1s and 0s\\n    answer_series = (\\n        pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > 1).apply(int)\\n    X = X[:-1]\\n    y = answer_series[1:]\\n\\n    classifier = RandomForestClassifier()\\n    scores = cross_validation.cross_val_score(\\n        classifier,\\n        X,\\n        y,\\n        cv=k_folds\\n    )\\n\\n    end = time.time()\\n    print \"Rows: {}, k={}\".format(row_limit, k_folds)\\n    print \"Mean accuracy: {}\".format(np.mean(scores))\\n    print \"Standard deviation: {}\".format(np.std(scores))\\n    print \"Took {}s\".format(end - start)', u'analyze(10000)', u'analyze(1000000)', u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nstart = time.time()\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\n\\ndef analyze(row_limit, k_folds=5, threshold_out=1, tree_count=10):\\n    df = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=row_limit)\\n    # Convert to timestamps \\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\n    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n    # Convert int64index to datetime index\\n    # Group using timegrouper and create new column for start period and stop period\\n    df = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\n    start_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\n    df[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\n    df = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\n    stop_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\n    df[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n    # Create two sub dataframes, grouping on and aggregating start data and then stop data\\n    grouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\n    df_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\n    df_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\n    grouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\n    df_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\n    df_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n    # Combine these two dataframes and fill N/A values to 0\\n    df_combined = pd.concat([df_start, df_stop])\\n    df_combined = df_combined.fillna(0)\\n\\n    # Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n    # And reset the multi-level index so we have a normal DataFrame\\n    aggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n    # Let\\'s construct a pivot table\\n    pivoted = pd.pivot_table(\\n        aggregate_data,\\n        index=[\"period\"],\\n        columns=[\"station_id\"],\\n        aggfunc=np.sum,\\n        fill_value=0)\\n\\n    # Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\n    deeper_cols = pivoted.columns.get_level_values(1)\\n    top_level_cols = pivoted.columns.get_level_values(0)\\n\\n    # Flattening the columns\\n    resultant_cols = []    \\n    for i, station_id in enumerate(deeper_cols):\\n        if top_level_cols[i] == \"start_count\":\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n        else:\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\n    pivoted.columns = resultant_cols\\n    pivoted = pivoted.reset_index()\\n    print \"{} rows in the pivoted table\".format(len(pivoted))\\n    X = pivoted.copy()\\n    # Turn number of out in station TARGET_STATION_ID into 1s and 0s\\n    answer_series = (\\n        pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > threshhold_out).apply(int)\\n    X = X[:-1]\\n    y = answer_series[1:]\\n\\n    classifier = RandomForestClassifier(n_estimators=tree_count)\\n    scores = cross_validation.cross_val_score(\\n        classifier,\\n        X,\\n        y,\\n        cv=k_folds\\n    )\\n\\n    end = time.time()\\n    print \"Rows: {}, k={}\".format(row_limit, k_folds)\\n    print \"Mean accuracy: {}\".format(np.mean(scores))\\n    print \"Standard deviation: {}\".format(np.std(scores))\\n    print \"Took {}s\".format(end - start)', u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nstart = time.time()\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\n\\ndef analyze(row_limit, k_folds=5, threshold_out=1, tree_count=10, period_minutes=5):\\n    \"\"\"\\n    We can tune the following parameters:\\n    - number of rows we analyze\\n    - number of folds in our standard k-fold cross-validation\\n    - number of bicycles taken out in the period to be considered in the positive class\\n    - number of trees in our random forest\\n    - number of minutes in our period\\n    \"\"\"\\n    df = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=row_limit)\\n    # Convert to timestamps \\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\n    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n    # Convert int64index to datetime index\\n    # Group using timegrouper and create new column for start period and stop period\\n    df = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\n    start_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\n    df[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\n    df = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\n    stop_time_group_by = df.groupby(pd.TimeGrouper(\\'{}Min\\'.format(period_minutes)),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\n    df[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n    # Create two sub dataframes, grouping on and aggregating start data and then stop data\\n    grouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\n    df_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\n    df_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\n    grouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\n    df_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\n    df_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n    # Combine these two dataframes and fill N/A values to 0\\n    df_combined = pd.concat([df_start, df_stop])\\n    df_combined = df_combined.fillna(0)\\n\\n    # Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n    # And reset the multi-level index so we have a normal DataFrame\\n    aggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n    # Let\\'s construct a pivot table\\n    pivoted = pd.pivot_table(\\n        aggregate_data,\\n        index=[\"period\"],\\n        columns=[\"station_id\"],\\n        aggfunc=np.sum,\\n        fill_value=0)\\n\\n    # Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\n    deeper_cols = pivoted.columns.get_level_values(1)\\n    top_level_cols = pivoted.columns.get_level_values(0)\\n\\n    # Flattening the columns\\n    resultant_cols = []    \\n    for i, station_id in enumerate(deeper_cols):\\n        if top_level_cols[i] == \"start_count\":\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n        else:\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\n    pivoted.columns = resultant_cols\\n    pivoted = pivoted.reset_index()\\n    print \"{} rows in the pivoted table\".format(len(pivoted))\\n    X = pivoted.copy()\\n    # Turn number of out in station TARGET_STATION_ID into 1s and 0s\\n    answer_series = (\\n        pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > threshhold_out).apply(int)\\n    X = X[:-1]\\n    y = answer_series[1:]\\n\\n    classifier = RandomForestClassifier(n_estimators=tree_count)\\n    scores = cross_validation.cross_val_score(\\n        classifier,\\n        X,\\n        y,\\n        cv=k_folds\\n    )\\n\\n    end = time.time()\\n    print \"Rows: {}, k={}\".format(row_limit, k_folds)\\n    print \"Mean accuracy: {}\".format(np.mean(scores))\\n    print \"Standard deviation: {}\".format(np.std(scores))\\n    print \"Took {}s\".format(end - start)', u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nstart = time.time()\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\n\\ndef analyze(row_limit, threshold_out=1, tree_count=10, period_minutes=5, k_folds=5):\\n    \"\"\"\\n    We can tune the following parameters:\\n    - number of rows we analyze\\n    - number of folds in our standard k-fold cross-validation\\n    - number of bicycles taken out in the period to be considered in the positive class\\n    - number of trees in our random forest\\n    - number of minutes in our period\\n    \"\"\"\\n    df = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=row_limit)\\n    # Convert to timestamps \\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\n    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n    # Convert int64index to datetime index\\n    # Group using timegrouper and create new column for start period and stop period\\n    df = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\n    start_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\n    df[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\n    df = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\n    stop_time_group_by = df.groupby(pd.TimeGrouper(\\'{}Min\\'.format(period_minutes)),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\n    df[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n    # Create two sub dataframes, grouping on and aggregating start data and then stop data\\n    grouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\n    df_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\n    df_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\n    grouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\n    df_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\n    df_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n    # Combine these two dataframes and fill N/A values to 0\\n    df_combined = pd.concat([df_start, df_stop])\\n    df_combined = df_combined.fillna(0)\\n\\n    # Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n    # And reset the multi-level index so we have a normal DataFrame\\n    aggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n    # Let\\'s construct a pivot table\\n    pivoted = pd.pivot_table(\\n        aggregate_data,\\n        index=[\"period\"],\\n        columns=[\"station_id\"],\\n        aggfunc=np.sum,\\n        fill_value=0)\\n\\n    # Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\n    deeper_cols = pivoted.columns.get_level_values(1)\\n    top_level_cols = pivoted.columns.get_level_values(0)\\n\\n    # Flattening the columns\\n    resultant_cols = []    \\n    for i, station_id in enumerate(deeper_cols):\\n        if top_level_cols[i] == \"start_count\":\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n        else:\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\n    pivoted.columns = resultant_cols\\n    pivoted = pivoted.reset_index()\\n    print \"{} rows in the pivoted table\".format(len(pivoted))\\n    X = pivoted.copy()\\n    # Turn number of out in station TARGET_STATION_ID into 1s and 0s\\n    answer_series = (\\n        pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > threshhold_out).apply(int)\\n    X = X[:-1]\\n    y = answer_series[1:]\\n\\n    classifier = RandomForestClassifier(n_estimators=tree_count)\\n    scores = cross_validation.cross_val_score(\\n        classifier,\\n        X,\\n        y,\\n        cv=k_folds\\n    )\\n\\n    end = time.time()\\n    print \"Rows: {}, k={}\".format(row_limit, k_folds)\\n    print \"Mean accuracy: {}\".format(np.mean(scores))\\n    print \"Standard deviation: {}\".format(np.std(scores))\\n    print \"Took {}s\".format(end - start)', u'for tc in [10, 20, 40]:\\n    analyze(10000, tree_count=tc)', u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nstart = time.time()\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\n\\ndef analyze(row_limit, threshold_out=1, tree_count=10, period_minutes=5, k_folds=5):\\n    \"\"\"\\n    We can tune the following parameters:\\n    - number of rows we analyze\\n    - number of folds in our standard k-fold cross-validation\\n    - number of bicycles taken out in the period to be considered in the positive class\\n    - number of trees in our random forest\\n    - number of minutes in our period\\n    \"\"\"\\n    df = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=row_limit)\\n    # Convert to timestamps \\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\n    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n    # Convert int64index to datetime index\\n    # Group using timegrouper and create new column for start period and stop period\\n    df = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\n    start_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\n    df[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\n    df = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\n    stop_time_group_by = df.groupby(pd.TimeGrouper(\\'{}Min\\'.format(period_minutes)),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\n    df[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n    # Create two sub dataframes, grouping on and aggregating start data and then stop data\\n    grouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\n    df_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\n    df_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\n    grouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\n    df_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\n    df_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n    # Combine these two dataframes and fill N/A values to 0\\n    df_combined = pd.concat([df_start, df_stop])\\n    df_combined = df_combined.fillna(0)\\n\\n    # Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n    # And reset the multi-level index so we have a normal DataFrame\\n    aggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n    # Let\\'s construct a pivot table\\n    pivoted = pd.pivot_table(\\n        aggregate_data,\\n        index=[\"period\"],\\n        columns=[\"station_id\"],\\n        aggfunc=np.sum,\\n        fill_value=0)\\n\\n    # Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\n    deeper_cols = pivoted.columns.get_level_values(1)\\n    top_level_cols = pivoted.columns.get_level_values(0)\\n\\n    # Flattening the columns\\n    resultant_cols = []    \\n    for i, station_id in enumerate(deeper_cols):\\n        if top_level_cols[i] == \"start_count\":\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n        else:\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\n    pivoted.columns = resultant_cols\\n    pivoted = pivoted.reset_index()\\n    print \"{} rows in the pivoted table\".format(len(pivoted))\\n    X = pivoted.copy()\\n    # Turn number of out in station TARGET_STATION_ID into 1s and 0s\\n    answer_series = (\\n        pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > threshold_out).apply(int)\\n    X = X[:-1]\\n    y = answer_series[1:]\\n\\n    classifier = RandomForestClassifier(n_estimators=tree_count)\\n    scores = cross_validation.cross_val_score(\\n        classifier,\\n        X,\\n        y,\\n        cv=k_folds\\n    )\\n\\n    end = time.time()\\n    print \"Rows: {}, k={}\".format(row_limit, k_folds)\\n    print \"Mean accuracy: {}\".format(np.mean(scores))\\n    print \"Standard deviation: {}\".format(np.std(scores))\\n    print \"Took {}s\".format(end - start)', u'for tc in [10, 20, 40]:\\n    print \"{} trees\".format(tc)\\n    analyze(10000, tree_count=tc)', u\"get_ipython().magic(u'pylab inline')\", u'from matplotlib import pyplot as plt', u'plt.plot([1, 2], [3, 4])', u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nstart = time.time()\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\n\\ndef analyze(row_limit, threshold_out=1, tree_count=10, period_minutes=5, k_folds=5):\\n    \"\"\"\\n    We can tune the following parameters:\\n    - number of rows we analyze\\n    - number of folds in our standard k-fold cross-validation\\n    - number of bicycles taken out in the period to be considered in the positive class\\n    - number of trees in our random forest\\n    - number of minutes in our period\\n    \"\"\"\\n    df = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=row_limit)\\n    # Convert to timestamps \\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\n    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n    # Convert int64index to datetime index\\n    # Group using timegrouper and create new column for start period and stop period\\n    df = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\n    start_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\n    df[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\n    df = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\n    stop_time_group_by = df.groupby(pd.TimeGrouper(\\'{}Min\\'.format(period_minutes)),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\n    df[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n    # Create two sub dataframes, grouping on and aggregating start data and then stop data\\n    grouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\n    df_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\n    df_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\n    grouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\n    df_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\n    df_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n    # Combine these two dataframes and fill N/A values to 0\\n    df_combined = pd.concat([df_start, df_stop])\\n    df_combined = df_combined.fillna(0)\\n\\n    # Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n    # And reset the multi-level index so we have a normal DataFrame\\n    aggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n    # Let\\'s construct a pivot table\\n    pivoted = pd.pivot_table(\\n        aggregate_data,\\n        index=[\"period\"],\\n        columns=[\"station_id\"],\\n        aggfunc=np.sum,\\n        fill_value=0)\\n\\n    # Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\n    deeper_cols = pivoted.columns.get_level_values(1)\\n    top_level_cols = pivoted.columns.get_level_values(0)\\n\\n    # Flattening the columns\\n    resultant_cols = []    \\n    for i, station_id in enumerate(deeper_cols):\\n        if top_level_cols[i] == \"start_count\":\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n        else:\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\n    pivoted.columns = resultant_cols\\n    pivoted = pivoted.reset_index()\\n    print \"{} rows in the pivoted table\".format(len(pivoted))\\n    X = pivoted.copy()\\n    # Turn number of out in station TARGET_STATION_ID into 1s and 0s\\n    answer_series = (\\n        pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > threshold_out).apply(int)\\n    X = X[:-1]\\n    y = answer_series[1:]\\n\\n    classifier = RandomForestClassifier(n_estimators=tree_count)\\n    scores = cross_validation.cross_val_score(\\n        classifier,\\n        X,\\n        y,\\n        cv=k_folds\\n    )\\n\\n    end = time.time()\\n    mean_accuracy = np.mean(scores)\\n    print \"Rows: {}, k={}\".format(row_limit, k_folds)\\n    print \"Mean accuracy: {}\".format(mean_accuracy)\\n    print \"Standard deviation: {}\".format(np.std(scores))\\n    print \"Took {}s\".format(end - start)\\n    return mean_accuracy', u'counts = [10, 20, 40]\\naccs = []\\nfor tc in counts:\\n    print \"{} trees\".format(tc)\\n    accs.append(analyze(10000, tree_count=tc))\\nplt.plot(counts, accs)', u'counts = [10, 20, 40, 100]\\naccs = []\\nfor tc in counts:\\n    print \"{} trees\".format(tc)\\n    accs.append(analyze(10000, tree_count=tc))\\n    print \"\\\\n\"\\nplt.plot(counts, accs)', u'thresholds = [1, 2, 3]\\nfor to in thresholds:\\n    accs.append(analyze(10000, tree_count=40, threshold_out=to))\\n    print \"\\\\n\"\\nplt.plot(thresholds, accs)', u'thresholds = [1, 2, 3]\\naccs = []\\nfor to in thresholds:\\n    accs.append(analyze(10000, tree_count=40, threshold_out=to))\\n    print \"\\\\n\"\\nplt.plot(thresholds, accs)', u'lengths = [2, 5, 10, 15]\\naccs = []\\nfor length in lengths:\\n    accs.append(analyze(50000, tree_count=40, threshold_out=1, period_minutes=length))\\n    print \"\\\\n\"\\nplt.plot(lengths, accs)', u'tree_counts = [40, 100, 200]\\naccs = []\\nfor tc in tree_counts:\\n    accs.append(analyze(50000, tree_count=tc, threshold_out=1, period_minutes=5))\\n    print \"\\\\n\"\\nplt.plot(lengths, tree_counts)', u'plt.plot(tree_counts, accs)', u'analyze(1000000, tree_count=200, threshold_out=1, period_minutes=5)', u'analyze(1200000, tree_count=500, threshold_out=1, period_minutes=5)', u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\n\\ndef analyze(row_limit, threshold_out=1, tree_count=10, period_minutes=5, k_folds=5):\\n    \"\"\"\\n    We can tune the following parameters:\\n    - number of rows we analyze\\n    - number of folds in our standard k-fold cross-validation\\n    - number of bicycles taken out in the period to be considered in the positive class\\n    - number of trees in our random forest\\n    - number of minutes in our period\\n    \"\"\"\\n    start = time.time()\\n    df = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=row_limit)\\n    # Convert to timestamps \\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\n    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n    # Convert int64index to datetime index\\n    # Group using timegrouper and create new column for start period and stop period\\n    df = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\n    start_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\n    df[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\n    df = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\n    stop_time_group_by = df.groupby(pd.TimeGrouper(\\'{}Min\\'.format(period_minutes)),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\n    df[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n    # Create two sub dataframes, grouping on and aggregating start data and then stop data\\n    grouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\n    df_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\n    df_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\n    grouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\n    df_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\n    df_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n    # Combine these two dataframes and fill N/A values to 0\\n    df_combined = pd.concat([df_start, df_stop])\\n    df_combined = df_combined.fillna(0)\\n\\n    # Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n    # And reset the multi-level index so we have a normal DataFrame\\n    aggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n    # Let\\'s construct a pivot table\\n    pivoted = pd.pivot_table(\\n        aggregate_data,\\n        index=[\"period\"],\\n        columns=[\"station_id\"],\\n        aggfunc=np.sum,\\n        fill_value=0)\\n\\n    # Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\n    deeper_cols = pivoted.columns.get_level_values(1)\\n    top_level_cols = pivoted.columns.get_level_values(0)\\n\\n    # Flattening the columns\\n    resultant_cols = []    \\n    for i, station_id in enumerate(deeper_cols):\\n        if top_level_cols[i] == \"start_count\":\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n        else:\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\n    pivoted.columns = resultant_cols\\n    pivoted = pivoted.reset_index()\\n    print \"{} rows in the pivoted table\".format(len(pivoted))\\n    X = pivoted.copy()\\n    # Turn number of out in station TARGET_STATION_ID into 1s and 0s\\n    answer_series = (\\n        pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > threshold_out).apply(int)\\n    X = X[:-1]\\n    y = answer_series[1:]\\n\\n    classifier = RandomForestClassifier(n_estimators=tree_count)\\n    scores = cross_validation.cross_val_score(\\n        classifier,\\n        X,\\n        y,\\n        cv=k_folds\\n    )\\n\\n    end = time.time()\\n    mean_accuracy = np.mean(scores)\\n    print \"Rows: {}, k={}\".format(row_limit, k_folds)\\n    print \"Mean accuracy: {}\".format(mean_accuracy)\\n    print \"Standard deviation: {}\".format(np.std(scores))\\n    print \"Took {}s\".format(end - start)\\n    return mean_accuracy', u'analyze(20000, tree_count=500, threshold_out=1, period_minutes=5)', u'analyze(1000000, tree_count=200, threshold_out=1, period_minutes=5)', u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\n\\ndef analyze(row_limit, threshold_out=1, tree_count=10, period_minutes=5, k_folds=5):\\n    \"\"\"\\n    We can tune the following parameters:\\n    - number of rows we analyze\\n    - number of folds in our standard k-fold cross-validation\\n    - number of bicycles taken out in the period to be considered in the positive class\\n    - number of trees in our random forest\\n    - number of minutes in our period\\n    \"\"\"\\n    start = time.time()\\n    df = pd.read_csv(\"data/july_thru_sept.csv\", usecols=COLUMNS, nrows=row_limit)\\n    # Convert to timestamps \\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\n    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n    # Convert int64index to datetime index\\n    # Group using timegrouper and create new column for start period and stop period\\n    df = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\n    start_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\n    df[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\n    df = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\n    stop_time_group_by = df.groupby(pd.TimeGrouper(\\'{}Min\\'.format(period_minutes)),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\n    df[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n    # Create two sub dataframes, grouping on and aggregating start data and then stop data\\n    grouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\n    df_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\n    df_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\n    grouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\n    df_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\n    df_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n    # Combine these two dataframes and fill N/A values to 0\\n    df_combined = pd.concat([df_start, df_stop])\\n    df_combined = df_combined.fillna(0)\\n\\n    # Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n    # And reset the multi-level index so we have a normal DataFrame\\n    aggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n    # Let\\'s construct a pivot table\\n    pivoted = pd.pivot_table(\\n        aggregate_data,\\n        index=[\"period\"],\\n        columns=[\"station_id\"],\\n        aggfunc=np.sum,\\n        fill_value=0)\\n\\n    # Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\n    deeper_cols = pivoted.columns.get_level_values(1)\\n    top_level_cols = pivoted.columns.get_level_values(0)\\n\\n    # Flattening the columns\\n    resultant_cols = []    \\n    for i, station_id in enumerate(deeper_cols):\\n        if top_level_cols[i] == \"start_count\":\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n        else:\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\n    pivoted.columns = resultant_cols\\n    pivoted = pivoted.reset_index()\\n    print \"{} rows in the pivoted table\".format(len(pivoted))\\n    X = pivoted.copy()\\n    # Turn number of out in station TARGET_STATION_ID into 1s and 0s\\n    answer_series = (\\n        pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > threshold_out).apply(int)\\n    X = X[:-1]\\n    y = answer_series[1:]\\n\\n    classifier = RandomForestClassifier(n_estimators=tree_count)\\n    scores = cross_validation.cross_val_score(\\n        classifier,\\n        X,\\n        y,\\n        cv=k_folds\\n    )\\n\\n    end = time.time()\\n    mean_accuracy = np.mean(scores)\\n    print \"Rows: {}, k={}\".format(row_limit, k_folds)\\n    print \"Mean accuracy: {}\".format(mean_accuracy)\\n    print \"Standard deviation: {}\".format(np.std(scores))\\n    print \"Took {}s\".format(end - start)\\n    return mean_accuracy', u'analyze(500000000, tree_count=500, threshold_out=1, period_minutes=5)', u'df', u'len(df)', u'df = pd.read_csv(\"data/july_thru_sept.csv\", usecols=COLUMNS)', u'def.size', u'df.dize', u'df.size()', u'df.size', u'df.isnull(df[\"starttime\"])', u'df[\"starttime\"].isnull()', u'df[\"starttime\"].isnull() == True', u'df[df[\"starttime\"].isnull() == True]', u'df[df[\"stoptime\"].isnull() == True]', u'df = pd.read_csv(\"data/july_thru_sept.csv\", usecols=COLUMNS)\\n# Convert to timestamps \\ndf[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\ndf[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])', u'df = pd.read_csv(\"data/july_thru_sept.csv\", usecols=COLUMNS)\\n# Convert to timestamps \\ntry:\\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\nexcept Exception as e:\\n    import pdb; pdb.set_trace()'], 'axvspan': <function axvspan at 0x109d460c8>, 'result_type': <built-in function result_type>, 'int0': <type 'numpy.int64'>, 'WE': WE, 'nanprod': <function nanprod at 0x104e13398>, 'draw_if_interactive': <function wrapper at 0x109d56410>, 'show': <function show at 0x109d1c938>, 'text': <function text at 0x109d47938>, 'random_integers': <built-in method random_integers of mtrand.RandomState object at 0x104ee18d0>, 'datetime': <module 'datetime' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/lib-dynload/datetime.so'>, 'stackplot': <function stackplot at 0x109d471b8>, 'pause': <function pause at 0x109d1cb18>, 'title': <function title at 0x109d19ed8>, 'frexp': <ufunc 'frexp'>, 'PolarAxes': <class 'matplotlib.projections.polar.PolarAxes'>, 'over': <function over at 0x109d19848>, 'complex256': <type 'numpy.complex256'>, 'ModuleDeprecationWarning': <class 'numpy.ModuleDeprecationWarning'>, 'get': <function getp at 0x10962c050>, 'NZERO': -0.0, 'ones': <function ones at 0x104d40e60>, 'count_nonzero': <built-in function count_nonzero>, 'gray': <function gray at 0x109d47e60>, 'using_mklfft': False, 'deprecate': <function deprecate at 0x104df9d70>, 'median': <function median at 0x104e041b8>, 'convolve': <function convolve at 0x104d40668>, 'where': <built-in function where>, 'rcParamsDefault': RcParams({u'agg.path.chunksize': 0,\n",
      "          u'animation.avconv_args': [],\n",
      "          u'animation.avconv_path': u'avconv',\n",
      "          u'animation.bitrate': -1,\n",
      "          u'animation.codec': u'mpeg4',\n",
      "          u'animation.convert_args': [],\n",
      "          u'animation.convert_path': u'convert',\n",
      "          u'animation.ffmpeg_args': [],\n",
      "          u'animation.ffmpeg_path': u'ffmpeg',\n",
      "          u'animation.frame_format': u'png',\n",
      "          u'animation.mencoder_args': [],\n",
      "          u'animation.mencoder_path': u'mencoder',\n",
      "          u'animation.writer': u'ffmpeg',\n",
      "          u'axes.axisbelow': False,\n",
      "          u'axes.color_cycle': [u'b', u'g', u'r', u'c', u'm', u'y', u'k'],\n",
      "          u'axes.edgecolor': u'k',\n",
      "          u'axes.facecolor': u'w',\n",
      "          u'axes.formatter.limits': [-7, 7],\n",
      "          u'axes.formatter.use_locale': False,\n",
      "          u'axes.formatter.use_mathtext': False,\n",
      "          u'axes.formatter.useoffset': True,\n",
      "          u'axes.grid': False,\n",
      "          u'axes.grid.which': u'major',\n",
      "          u'axes.hold': True,\n",
      "          u'axes.labelcolor': u'k',\n",
      "          u'axes.labelsize': u'medium',\n",
      "          u'axes.labelweight': u'normal',\n",
      "          u'axes.linewidth': 1.0,\n",
      "          u'axes.titlesize': u'large',\n",
      "          u'axes.titleweight': u'normal',\n",
      "          u'axes.unicode_minus': True,\n",
      "          u'axes.xmargin': 0.0,\n",
      "          u'axes.ymargin': 0.0,\n",
      "          u'axes3d.grid': True,\n",
      "          u'backend': u'agg',\n",
      "          u'backend.qt4': u'PyQt4',\n",
      "          u'backend.qt5': u'PyQt5',\n",
      "          u'backend_fallback': True,\n",
      "          u'contour.negative_linestyle': u'dashed',\n",
      "          u'datapath': u'/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/matplotlib/mpl-data',\n",
      "          u'docstring.hardcopy': False,\n",
      "          u'examples.directory': u'',\n",
      "          u'figure.autolayout': False,\n",
      "          u'figure.dpi': 80.0,\n",
      "          u'figure.edgecolor': u'w',\n",
      "          u'figure.facecolor': u'0.75',\n",
      "          u'figure.figsize': [8.0, 6.0],\n",
      "          u'figure.frameon': True,\n",
      "          u'figure.max_open_warning': 20,\n",
      "          u'figure.subplot.bottom': 0.1,\n",
      "          u'figure.subplot.hspace': 0.2,\n",
      "          u'figure.subplot.left': 0.125,\n",
      "          u'figure.subplot.right': 0.9,\n",
      "          u'figure.subplot.top': 0.9,\n",
      "          u'figure.subplot.wspace': 0.2,\n",
      "          u'font.cursive': [u'Apple Chancery',\n",
      "                            u'Textile',\n",
      "                            u'Zapf Chancery',\n",
      "                            u'Sand',\n",
      "                            u'cursive'],\n",
      "          u'font.family': [u'sans-serif'],\n",
      "          u'font.fantasy': [u'Comic Sans MS',\n",
      "                            u'Chicago',\n",
      "                            u'Charcoal',\n",
      "                            u'ImpactWestern',\n",
      "                            u'fantasy'],\n",
      "          u'font.monospace': [u'Bitstream Vera Sans Mono',\n",
      "                              u'DejaVu Sans Mono',\n",
      "                              u'Andale Mono',\n",
      "                              u'Nimbus Mono L',\n",
      "                              u'Courier New',\n",
      "                              u'Courier',\n",
      "                              u'Fixed',\n",
      "                              u'Terminal',\n",
      "                              u'monospace'],\n",
      "          u'font.sans-serif': [u'Bitstream Vera Sans',\n",
      "                               u'DejaVu Sans',\n",
      "                               u'Lucida Grande',\n",
      "                               u'Verdana',\n",
      "                               u'Geneva',\n",
      "                               u'Lucid',\n",
      "                               u'Arial',\n",
      "                               u'Helvetica',\n",
      "                               u'Avant Garde',\n",
      "                               u'sans-serif'],\n",
      "          u'font.serif': [u'Bitstream Vera Serif',\n",
      "                          u'DejaVu Serif',\n",
      "                          u'New Century Schoolbook',\n",
      "                          u'Century Schoolbook L',\n",
      "                          u'Utopia',\n",
      "                          u'ITC Bookman',\n",
      "                          u'Bookman',\n",
      "                          u'Nimbus Roman No9 L',\n",
      "                          u'Times New Roman',\n",
      "                          u'Times',\n",
      "                          u'Palatino',\n",
      "                          u'Charter',\n",
      "                          u'serif'],\n",
      "          u'font.size': 12.0,\n",
      "          u'font.stretch': u'normal',\n",
      "          u'font.style': u'normal',\n",
      "          u'font.variant': u'normal',\n",
      "          u'font.weight': u'normal',\n",
      "          u'grid.alpha': 1.0,\n",
      "          u'grid.color': u'k',\n",
      "          u'grid.linestyle': u':',\n",
      "          u'grid.linewidth': 0.5,\n",
      "          u'image.aspect': u'equal',\n",
      "          u'image.cmap': u'jet',\n",
      "          u'image.interpolation': u'bilinear',\n",
      "          u'image.lut': 256,\n",
      "          u'image.origin': u'upper',\n",
      "          u'image.resample': False,\n",
      "          u'interactive': False,\n",
      "          u'keymap.all_axes': [u'a'],\n",
      "          u'keymap.back': [u'left', u'c', u'backspace'],\n",
      "          u'keymap.forward': [u'right', u'v'],\n",
      "          u'keymap.fullscreen': [u'f', u'ctrl+f'],\n",
      "          u'keymap.grid': [u'g'],\n",
      "          u'keymap.home': [u'h', u'r', u'home'],\n",
      "          u'keymap.pan': [u'p'],\n",
      "          u'keymap.quit': [u'ctrl+w', u'cmd+w'],\n",
      "          u'keymap.save': [u's', u'ctrl+s'],\n",
      "          u'keymap.xscale': [u'k', u'L'],\n",
      "          u'keymap.yscale': [u'l'],\n",
      "          u'keymap.zoom': [u'o'],\n",
      "          u'legend.borderaxespad': 0.5,\n",
      "          u'legend.borderpad': 0.4,\n",
      "          u'legend.columnspacing': 2.0,\n",
      "          u'legend.fancybox': False,\n",
      "          u'legend.fontsize': u'large',\n",
      "          u'legend.framealpha': None,\n",
      "          u'legend.frameon': True,\n",
      "          u'legend.handleheight': 0.7,\n",
      "          u'legend.handlelength': 2.0,\n",
      "          u'legend.handletextpad': 0.8,\n",
      "          u'legend.isaxes': True,\n",
      "          u'legend.labelspacing': 0.5,\n",
      "          u'legend.loc': u'upper right',\n",
      "          u'legend.markerscale': 1.0,\n",
      "          u'legend.numpoints': 2,\n",
      "          u'legend.scatterpoints': 3,\n",
      "          u'legend.shadow': False,\n",
      "          u'lines.antialiased': True,\n",
      "          u'lines.color': u'b',\n",
      "          u'lines.dash_capstyle': u'butt',\n",
      "          u'lines.dash_joinstyle': u'round',\n",
      "          u'lines.linestyle': u'-',\n",
      "          u'lines.linewidth': 1.0,\n",
      "          u'lines.marker': u'None',\n",
      "          u'lines.markeredgewidth': 0.5,\n",
      "          u'lines.markersize': 6.0,\n",
      "          u'lines.solid_capstyle': u'projecting',\n",
      "          u'lines.solid_joinstyle': u'round',\n",
      "          u'mathtext.bf': u'serif:bold',\n",
      "          u'mathtext.cal': u'cursive',\n",
      "          u'mathtext.default': u'it',\n",
      "          u'mathtext.fallback_to_cm': True,\n",
      "          u'mathtext.fontset': u'cm',\n",
      "          u'mathtext.it': u'serif:italic',\n",
      "          u'mathtext.rm': u'serif',\n",
      "          u'mathtext.sf': u'sans\\\\-serif',\n",
      "          u'mathtext.tt': u'monospace',\n",
      "          u'nbagg.transparent': True,\n",
      "          u'patch.antialiased': True,\n",
      "          u'patch.edgecolor': u'k',\n",
      "          u'patch.facecolor': u'b',\n",
      "          u'patch.linewidth': 1.0,\n",
      "          u'path.effects': [],\n",
      "          u'path.simplify': True,\n",
      "          u'path.simplify_threshold': 0.1111111111111111,\n",
      "          u'path.sketch': None,\n",
      "          u'path.snap': True,\n",
      "          u'pdf.compression': 6,\n",
      "          u'pdf.fonttype': 3,\n",
      "          u'pdf.inheritcolor': False,\n",
      "          u'pdf.use14corefonts': False,\n",
      "          u'pgf.debug': False,\n",
      "          u'pgf.preamble': [],\n",
      "          u'pgf.rcfonts': True,\n",
      "          u'pgf.texsystem': u'xelatex',\n",
      "          u'plugins.directory': u'.matplotlib_plugins',\n",
      "          u'polaraxes.grid': True,\n",
      "          u'ps.distiller.res': 6000,\n",
      "          u'ps.fonttype': 3,\n",
      "          u'ps.papersize': u'letter',\n",
      "          u'ps.useafm': False,\n",
      "          u'ps.usedistiller': False,\n",
      "          u'savefig.bbox': None,\n",
      "          u'savefig.directory': u'~',\n",
      "          u'savefig.dpi': 100.0,\n",
      "          u'savefig.edgecolor': u'w',\n",
      "          u'savefig.facecolor': u'w',\n",
      "          u'savefig.format': u'png',\n",
      "          u'savefig.frameon': True,\n",
      "          u'savefig.jpeg_quality': 95,\n",
      "          u'savefig.orientation': u'portrait',\n",
      "          u'savefig.pad_inches': 0.1,\n",
      "          u'savefig.transparent': False,\n",
      "          u'svg.fonttype': u'path',\n",
      "          u'svg.image_inline': True,\n",
      "          u'svg.image_noscale': False,\n",
      "          u'text.antialiased': True,\n",
      "          u'text.color': u'k',\n",
      "          u'text.dvipnghack': None,\n",
      "          u'text.hinting': True,\n",
      "          u'text.hinting_factor': 8,\n",
      "          u'text.latex.preamble': [],\n",
      "          u'text.latex.preview': False,\n",
      "          u'text.latex.unicode': False,\n",
      "          u'text.usetex': False,\n",
      "          u'timezone': u'UTC',\n",
      "          u'tk.window_focus': False,\n",
      "          u'toolbar': u'toolbar2',\n",
      "          u'verbose.fileo': u'sys.stdout',\n",
      "          u'verbose.level': u'silent',\n",
      "          u'webagg.open_in_browser': True,\n",
      "          u'webagg.port': 8988,\n",
      "          u'webagg.port_retries': 50,\n",
      "          u'xtick.color': u'k',\n",
      "          u'xtick.direction': u'in',\n",
      "          u'xtick.labelsize': u'medium',\n",
      "          u'xtick.major.pad': 4.0,\n",
      "          u'xtick.major.size': 4.0,\n",
      "          u'xtick.major.width': 0.5,\n",
      "          u'xtick.minor.pad': 4.0,\n",
      "          u'xtick.minor.size': 2.0,\n",
      "          u'xtick.minor.width': 0.5,\n",
      "          u'ytick.color': u'k',\n",
      "          u'ytick.direction': u'in',\n",
      "          u'ytick.labelsize': u'medium',\n",
      "          u'ytick.major.pad': 4.0,\n",
      "          u'ytick.major.size': 4.0,\n",
      "          u'ytick.major.width': 0.5,\n",
      "          u'ytick.minor.pad': 4.0,\n",
      "          u'ytick.minor.size': 2.0,\n",
      "          u'ytick.minor.width': 0.5}), 'SHIFT_UNDERFLOW': 6, 'argmax': <function argmax at 0x104d5a500>, 'prctile': <function prctile at 0x1081d02a8>, 'polyder': <function polyder at 0x104e2c578>, 'imread': <function imread at 0x109d20a28>, 'DayLocator': <class 'matplotlib.dates.DayLocator'>, 'Formatter': <class 'matplotlib.ticker.Formatter'>, 'isnan': <ufunc 'isnan'>, 'autoscale': <function autoscale at 0x109d47c08>, 'hist': <function hist at 0x109d46848>, 'NINF': -inf, 'geometric': <built-in method geometric of mtrand.RandomState object at 0x104ee18d0>, 'sort_complex': <function sort_complex at 0x104e00578>, 'vdot': <built-in function vdot>, '_i44': u'    df = pd.read_csv(\"data/july_thru_sept.csv\", usecols=COLUMNS)\\n    # Convert to timestamps \\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\n    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])', 'fromregex': <function fromregex at 0x104e75500>, 'transpose': <function transpose at 0x104d5a2a8>, '_i41': u'df[\"starttime\"].isnull() == True', '_i42': u'df[df[\"starttime\"].isnull() == True]', '_i43': u'df[df[\"stoptime\"].isnull() == True]', 'detrend': <function detrend at 0x10a9b9488>, 'disconnect': <function disconnect at 0x109d192a8>, 'set_printoptions': <function set_printoptions at 0x104d5c5f0>, 'float64': <type 'numpy.float64'>, 'DateFormatter': <class 'matplotlib.dates.DateFormatter'>, 'equal': <ufunc 'equal'>, 'laplace': <built-in method laplace of mtrand.RandomState object at 0x104ee18d0>, '_i39': u'df.isnull(df[\"starttime\"])', 'Locator': <class 'matplotlib.ticker.Locator'>, '_i31': u'analyze(500000000, tree_count=500, threshold_out=1, period_minutes=5)', 'geterrobj': <built-in function geterrobj>, '_i33': u'len(df)', '_i32': u'df', '_i35': u'def.size', 'clf': <function clf at 0x109d19320>, '_i37': u'df.size()', '_i36': u'df.dize', 'wald': <built-in method wald of mtrand.RandomState object at 0x104ee18d0>, 'fromiter': <built-in function fromiter>, 'prctile_rank': <function prctile_rank at 0x1081d0500>, 'cm': <module 'matplotlib.cm' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/matplotlib/cm.pyc'>, 'poly': <function poly at 0x104e2c050>, 'bitwise_or': <ufunc 'bitwise_or'>, 'figtext': <function figtext at 0x109d195f0>, 'norm_flat': <function norm_flat at 0x10a99c050>, 'tricontourf': <function tricontourf at 0x109d47410>, 'table': <function table at 0x109d478c0>, 'cohere': <function cohere at 0x109d46320>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x103af2550>, 'tensordot': <function tensordot at 0x104d40488>, 'piecewise': <function piecewise at 0x104e00050>, 'hlines': <function hlines at 0x109d46938>, 'invert': <ufunc 'invert'>, 'c_': <numpy.lib.index_tricks.CClass object at 0x104e05e90>, 'matrix_rank': <function matrix_rank at 0x104e15d70>, 'degrees': <ufunc 'degrees'>, 'switch_backend': <function switch_backend at 0x109d1c8c0>, 'random_sample': <built-in method random_sample of mtrand.RandomState object at 0x104ee18d0>, 'path_length': <function path_length at 0x10a99fed8>, 'arcsin': <ufunc 'arcsin'>, 'sctypeNA': {<type 'numpy.uint8'>: 'UInt8', <type 'numpy.object_'>: 'Object0', <type 'numpy.complex64'>: 'Complex32', 'Int32': <type 'numpy.int32'>, 'Complex64': <type 'numpy.complex128'>, <type 'numpy.complex128'>: 'Complex64', 'm8': 'Timedelta64', <type 'numpy.string_'>: 'String0', 'UInt32': <type 'numpy.uint32'>, <type 'numpy.complex256'>: 'Complex128', 'D': 'Complex64', 'H': 'UInt16', 'L': 'UInt64', <type 'numpy.unicode_'>: 'Unicode0', 'd': 'Float64', 'h': 'Int16', 'l': 'Int64', 'c32': 'Complex128', <type 'numpy.int8'>: 'Int8', 'Timedelta64': <type 'numpy.timedelta64'>, <type 'numpy.void'>: 'Void0', 'b1': 'Bool', 'M8': 'Datetime64', 'String0': <type 'numpy.string_'>, 'I': 'UInt32', <type 'numpy.int32'>: 'Int32', '?': 'Bool', 'Void0': <type 'numpy.void'>, 'Float64': <type 'numpy.float64'>, 'G': 'Complex128', 'O': 'Object0', <type 'numpy.int64'>: 'Int64', 'S': 'String0', <type 'numpy.bool_'>: 'Bool', 'UInt64': <type 'numpy.uint64'>, 'g': 'Float128', <type 'numpy.int64'>: 'Int64', 'UInt8': <type 'numpy.uint8'>, 'Float16': <type 'numpy.float16'>, 'Bool': <type 'numpy.bool_'>, <type 'numpy.uint16'>: 'UInt16', 'u8': <type 'numpy.uint64'>, 'u4': <type 'numpy.uint32'>, 'Unicode0': <type 'numpy.unicode_'>, 'u1': <type 'numpy.uint8'>, 'u2': <type 'numpy.uint16'>, <type 'numpy.uint32'>: 'UInt32', 'Datetime64': <type 'numpy.datetime64'>, 'Int8': <type 'numpy.int8'>, 'B': 'UInt8', 'F': 'Complex32', <type 'numpy.uint64'>: 'UInt64', 'c8': 'Complex32', 'Int64': <type 'numpy.int64'>, 'Complex32': <type 'numpy.complex64'>, 'V': 'Void0', 'Float32': <type 'numpy.float32'>, <type 'numpy.uint64'>: 'UInt64', 'b': 'Int8', 'f': 'Float32', 'c16': 'Complex64', <type 'numpy.float16'>: 'Float16', 'f16': 'Float128', 'f2': 'Float16', 'f4': 'Float32', 'f8': 'Float64', 'Complex128': <type 'numpy.complex256'>, <type 'numpy.float32'>: 'Float32', 'Object0': <type 'numpy.object_'>, 'Int16': <type 'numpy.int16'>, <type 'numpy.float64'>: 'Float64', 'UInt16': <type 'numpy.uint16'>, <type 'numpy.int16'>: 'Int16', 'i8': <type 'numpy.int64'>, <type 'numpy.float128'>: 'Float128', 'i1': <type 'numpy.int8'>, 'i2': <type 'numpy.int16'>, 'M': 'Datetime64', 'i4': <type 'numpy.int32'>, 'Q': 'UInt64', 'U': 'Unicode0', <type 'numpy.datetime64'>: 'Datetime64', 'e': 'Float16', 'i': 'Int32', 'm': 'Timedelta64', 'q': 'Int64', <type 'numpy.timedelta64'>: 'Timedelta64', 'Float128': <type 'numpy.float128'>}, 'singlecomplex': <type 'numpy.complex64'>, 'sort': <function sort at 0x104d5a410>, 'standard_t': <built-in method standard_t of mtrand.RandomState object at 0x104ee18d0>, 'csv2rec': <function csv2rec at 0x10a99c848>, 'new_figure_manager': <function new_figure_manager at 0x109d18320>, 'dstack': <function dstack at 0x104e13c08>, 'colorbar': <function colorbar at 0x109d20848>, 'cast': {<type 'numpy.uint8'>: <function <lambda> at 0x104a90d70>, <type 'numpy.int8'>: <function <lambda> at 0x104a90de8>, <type 'numpy.object_'>: <function <lambda> at 0x104a90e60>, <type 'numpy.complex64'>: <function <lambda> at 0x104a90ed8>, <type 'numpy.float32'>: <function <lambda> at 0x104a90f50>, <type 'numpy.uint16'>: <function <lambda> at 0x104a9d050>, <type 'numpy.int16'>: <function <lambda> at 0x104a9d0c8>, <type 'numpy.bool_'>: <function <lambda> at 0x104a9d140>, <type 'numpy.complex128'>: <function <lambda> at 0x104a9d1b8>, <type 'numpy.float64'>: <function <lambda> at 0x104a9d230>, <type 'numpy.uint32'>: <function <lambda> at 0x104a9d2a8>, <type 'numpy.int32'>: <function <lambda> at 0x104a9d320>, <type 'numpy.string_'>: <function <lambda> at 0x104a9d398>, <type 'numpy.complex256'>: <function <lambda> at 0x104a9d410>, <type 'numpy.float128'>: <function <lambda> at 0x104a9d488>, <type 'numpy.uint64'>: <function <lambda> at 0x104a9d500>, <type 'numpy.int64'>: <function <lambda> at 0x104a9d578>, <type 'numpy.unicode_'>: <function <lambda> at 0x104a9d5f0>, <type 'numpy.datetime64'>: <function <lambda> at 0x104a9d668>, <type 'numpy.uint64'>: <function <lambda> at 0x104a9d6e0>, <type 'numpy.int64'>: <function <lambda> at 0x104a9d758>, <type 'numpy.void'>: <function <lambda> at 0x104a9d7d0>, <type 'numpy.timedelta64'>: <function <lambda> at 0x104a9d848>, <type 'numpy.float16'>: <function <lambda> at 0x104a9d8c0>}, 'eig': <function eig at 0x104e15f50>, 'mgrid': <numpy.lib.index_tricks.nd_grid object at 0x104e05cd0>, 'ushort': <type 'numpy.uint16'>, 'Polygon': <class 'matplotlib.patches.Polygon'>, 'helper': <module 'numpy.fft.helper' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/numpy/fft/helper.pyc'>, 'einsum': <built-in function einsum>, 'signbit': <ufunc 'signbit'>, 'chisquare': <built-in method chisquare of mtrand.RandomState object at 0x104ee18d0>, 'magnitude_spectrum': <function magnitude_spectrum at 0x109d46aa0>, 'asmatrix': <function asmatrix at 0x104e04938>, 'bitwise_xor': <ufunc 'bitwise_xor'>, 'fabs': <ufunc 'fabs'>, '_i38': u'df.size', 'generic': <type 'numpy.generic'>, 'reshape': <function reshape at 0x104d5a050>, 'LinAlgError': <class 'numpy.linalg.linalg.LinAlgError'>, 'sqrt': <ufunc 'sqrt'>, '__package__': None, 'longcomplex': <type 'numpy.complex256'>, 'poly_between': <function poly_between at 0x10a99fb90>, 'pad': <function pad at 0x104e7e398>, 'getp': <function getp at 0x10962c050>, 'floor_divide': <ufunc 'floor_divide'>, '__version__': '1.10.1', 'format_parser': <class numpy.core.records.format_parser at 0x104d616d0>, 'dedent': <function dedent at 0x105b49d70>, 'flipud': <function flipud at 0x104de9668>, 'iscomplexobj': <function iscomplexobj at 0x104dcdde8>, 'average': <function average at 0x104e001b8>, 'array2string': <function array2string at 0x104d5c9b0>, 'mafromtxt': <function mafromtxt at 0x104e75668>, 'drange': <function drange at 0x106041e60>, 'greater_equal': <ufunc 'greater_equal'>, 'i': 813, 'Tester': <class 'numpy.testing.nosetester.NoseTester'>, 'trapz': <function trapz at 0x104e04398>, 'rec_drop_fields': <function rec_drop_fields at 0x10a99c578>, 'recfromtxt': <function recfromtxt at 0x104e756e0>, 'setp': <function setp at 0x109d1ce60>, 'In': ['', u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\n\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\ndf = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=ROW_LIMIT)\\n# Convert to timestamps \\ndf[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\ndf[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n# Convert int64index to datetime index\\n# Group using timegrouper and create new column for start period and stop period\\ndf = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\nstart_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\ndf[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\ndf = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\nstop_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\ndf[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n# Combine these two dataframes and fill N/A values to 0\\ndf_combined = pd.concat([df_start, df_stop])\\ndf_combined = df_combined.fillna(0)\\n\\n# Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n# And reset the multi-level index so we have a normal DataFrame\\naggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n# Let\\'s construct a pivot table\\npivoted = pd.pivot_table(\\n    aggregate_data,\\n    index=[\"period\"],\\n    columns=[\"station_id\"],\\n    aggfunc=np.sum,\\n    fill_value=0)\\n\\n# Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\ndeeper_cols = pivoted.columns.get_level_values(1)\\ntop_level_cols = pivoted.columns.get_level_values(0)\\n\\n# Flattening the columns\\nresultant_cols = []    \\nfor i, station_id in enumerate(deeper_cols):\\n    if top_level_cols[i] == \"start_count\":\\n        resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n    else:\\n        resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\npivoted.columns = resultant_cols\\npivoted = pivoted.reset_index()\\n\\nX = pivoted.copy()\\n# Turn number of out in station TARGET_STATION_ID into 1s and 0s\\nanswer_series = (\\n    pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > 1).apply(int)\\nX = X[:-1]\\ny = answer_series[1:]\\n\\nclassifier = RandomForestClassifier()\\nscores = cross_validation.cross_val_score(\\n    classifier,\\n    X,\\n    y,\\n    cv=10\\n)\\n\\nprint scores\\nprint np.mean(scores)\\nprint np.std(scores)', u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nstart = time.time()\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\ndf = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=ROW_LIMIT)\\n# Convert to timestamps \\ndf[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\ndf[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n# Convert int64index to datetime index\\n# Group using timegrouper and create new column for start period and stop period\\ndf = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\nstart_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\ndf[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\ndf = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\nstop_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\ndf[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n# Create two sub dataframes, grouping on and aggregating start data and then stop data\\ngrouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\ndf_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\ndf_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\ngrouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\ndf_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\ndf_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n# Combine these two dataframes and fill N/A values to 0\\ndf_combined = pd.concat([df_start, df_stop])\\ndf_combined = df_combined.fillna(0)\\n\\n# Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n# And reset the multi-level index so we have a normal DataFrame\\naggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n# Let\\'s construct a pivot table\\npivoted = pd.pivot_table(\\n    aggregate_data,\\n    index=[\"period\"],\\n    columns=[\"station_id\"],\\n    aggfunc=np.sum,\\n    fill_value=0)\\n\\n# Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\ndeeper_cols = pivoted.columns.get_level_values(1)\\ntop_level_cols = pivoted.columns.get_level_values(0)\\n\\n# Flattening the columns\\nresultant_cols = []    \\nfor i, station_id in enumerate(deeper_cols):\\n    if top_level_cols[i] == \"start_count\":\\n        resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n    else:\\n        resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\npivoted.columns = resultant_cols\\npivoted = pivoted.reset_index()\\n\\nX = pivoted.copy()\\n# Turn number of out in station TARGET_STATION_ID into 1s and 0s\\nanswer_series = (\\n    pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > 1).apply(int)\\nX = X[:-1]\\ny = answer_series[1:]\\n\\nclassifier = RandomForestClassifier()\\nscores = cross_validation.cross_val_score(\\n    classifier,\\n    X,\\n    y,\\n    cv=10\\n)\\n\\nprint scores\\nprint np.mean(scores)\\nprint np.std(scores)\\nend = time.time()\\nprint end - start', u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nstart = time.time()\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\n\\ndef analyze(row_limit, k_folds=5):\\n    df = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=row_limit)\\n    # Convert to timestamps \\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\n    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n    # Convert int64index to datetime index\\n    # Group using timegrouper and create new column for start period and stop period\\n    df = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\n    start_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\n    df[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\n    df = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\n    stop_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\n    df[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n    # Create two sub dataframes, grouping on and aggregating start data and then stop data\\n    grouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\n    df_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\n    df_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\n    grouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\n    df_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\n    df_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n    # Combine these two dataframes and fill N/A values to 0\\n    df_combined = pd.concat([df_start, df_stop])\\n    df_combined = df_combined.fillna(0)\\n\\n    # Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n    # And reset the multi-level index so we have a normal DataFrame\\n    aggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n    # Let\\'s construct a pivot table\\n    pivoted = pd.pivot_table(\\n        aggregate_data,\\n        index=[\"period\"],\\n        columns=[\"station_id\"],\\n        aggfunc=np.sum,\\n        fill_value=0)\\n\\n    # Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\n    deeper_cols = pivoted.columns.get_level_values(1)\\n    top_level_cols = pivoted.columns.get_level_values(0)\\n\\n    # Flattening the columns\\n    resultant_cols = []    \\n    for i, station_id in enumerate(deeper_cols):\\n        if top_level_cols[i] == \"start_count\":\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n        else:\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\n    pivoted.columns = resultant_cols\\n    pivoted = pivoted.reset_index()\\n\\n    X = pivoted.copy()\\n    # Turn number of out in station TARGET_STATION_ID into 1s and 0s\\n    answer_series = (\\n        pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > 1).apply(int)\\n    X = X[:-1]\\n    y = answer_series[1:]\\n\\n    classifier = RandomForestClassifier()\\n    scores = cross_validation.cross_val_score(\\n        classifier,\\n        X,\\n        y,\\n        cv=k_folds\\n    )\\n\\n    end = time.time()\\n    print \"Rows: {}, k={}\".format(row_limit, k_folds)\\n    print \"Mean accuracy: {}\".format(np.mean(scores))\\n    print \"Standard deviation: {}\".format(np.std(scores))\\n    print \"Took {}s\".format(end - start)', u'analyze(100000)', u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nstart = time.time()\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\n\\ndef analyze(row_limit, k_folds=5):\\n    df = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=row_limit)\\n    # Convert to timestamps \\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\n    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n    # Convert int64index to datetime index\\n    # Group using timegrouper and create new column for start period and stop period\\n    df = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\n    start_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\n    df[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\n    df = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\n    stop_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\n    df[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n    # Create two sub dataframes, grouping on and aggregating start data and then stop data\\n    grouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\n    df_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\n    df_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\n    grouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\n    df_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\n    df_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n    # Combine these two dataframes and fill N/A values to 0\\n    df_combined = pd.concat([df_start, df_stop])\\n    df_combined = df_combined.fillna(0)\\n\\n    # Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n    # And reset the multi-level index so we have a normal DataFrame\\n    aggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n    # Let\\'s construct a pivot table\\n    pivoted = pd.pivot_table(\\n        aggregate_data,\\n        index=[\"period\"],\\n        columns=[\"station_id\"],\\n        aggfunc=np.sum,\\n        fill_value=0)\\n\\n    # Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\n    deeper_cols = pivoted.columns.get_level_values(1)\\n    top_level_cols = pivoted.columns.get_level_values(0)\\n\\n    # Flattening the columns\\n    resultant_cols = []    \\n    for i, station_id in enumerate(deeper_cols):\\n        if top_level_cols[i] == \"start_count\":\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n        else:\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\n    pivoted.columns = resultant_cols\\n    pivoted = pivoted.reset_index()\\n    print \"{} rows in the pivoted table\".format(len(pivoted))\\n    X = pivoted.copy()\\n    # Turn number of out in station TARGET_STATION_ID into 1s and 0s\\n    answer_series = (\\n        pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > 1).apply(int)\\n    X = X[:-1]\\n    y = answer_series[1:]\\n\\n    classifier = RandomForestClassifier()\\n    scores = cross_validation.cross_val_score(\\n        classifier,\\n        X,\\n        y,\\n        cv=k_folds\\n    )\\n\\n    end = time.time()\\n    print \"Rows: {}, k={}\".format(row_limit, k_folds)\\n    print \"Mean accuracy: {}\".format(np.mean(scores))\\n    print \"Standard deviation: {}\".format(np.std(scores))\\n    print \"Took {}s\".format(end - start)', u'analyze(10000)', u'analyze(1000000)', u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nstart = time.time()\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\n\\ndef analyze(row_limit, k_folds=5, threshold_out=1, tree_count=10):\\n    df = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=row_limit)\\n    # Convert to timestamps \\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\n    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n    # Convert int64index to datetime index\\n    # Group using timegrouper and create new column for start period and stop period\\n    df = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\n    start_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\n    df[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\n    df = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\n    stop_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\n    df[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n    # Create two sub dataframes, grouping on and aggregating start data and then stop data\\n    grouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\n    df_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\n    df_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\n    grouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\n    df_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\n    df_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n    # Combine these two dataframes and fill N/A values to 0\\n    df_combined = pd.concat([df_start, df_stop])\\n    df_combined = df_combined.fillna(0)\\n\\n    # Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n    # And reset the multi-level index so we have a normal DataFrame\\n    aggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n    # Let\\'s construct a pivot table\\n    pivoted = pd.pivot_table(\\n        aggregate_data,\\n        index=[\"period\"],\\n        columns=[\"station_id\"],\\n        aggfunc=np.sum,\\n        fill_value=0)\\n\\n    # Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\n    deeper_cols = pivoted.columns.get_level_values(1)\\n    top_level_cols = pivoted.columns.get_level_values(0)\\n\\n    # Flattening the columns\\n    resultant_cols = []    \\n    for i, station_id in enumerate(deeper_cols):\\n        if top_level_cols[i] == \"start_count\":\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n        else:\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\n    pivoted.columns = resultant_cols\\n    pivoted = pivoted.reset_index()\\n    print \"{} rows in the pivoted table\".format(len(pivoted))\\n    X = pivoted.copy()\\n    # Turn number of out in station TARGET_STATION_ID into 1s and 0s\\n    answer_series = (\\n        pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > threshhold_out).apply(int)\\n    X = X[:-1]\\n    y = answer_series[1:]\\n\\n    classifier = RandomForestClassifier(n_estimators=tree_count)\\n    scores = cross_validation.cross_val_score(\\n        classifier,\\n        X,\\n        y,\\n        cv=k_folds\\n    )\\n\\n    end = time.time()\\n    print \"Rows: {}, k={}\".format(row_limit, k_folds)\\n    print \"Mean accuracy: {}\".format(np.mean(scores))\\n    print \"Standard deviation: {}\".format(np.std(scores))\\n    print \"Took {}s\".format(end - start)', u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nstart = time.time()\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\n\\ndef analyze(row_limit, k_folds=5, threshold_out=1, tree_count=10, period_minutes=5):\\n    \"\"\"\\n    We can tune the following parameters:\\n    - number of rows we analyze\\n    - number of folds in our standard k-fold cross-validation\\n    - number of bicycles taken out in the period to be considered in the positive class\\n    - number of trees in our random forest\\n    - number of minutes in our period\\n    \"\"\"\\n    df = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=row_limit)\\n    # Convert to timestamps \\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\n    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n    # Convert int64index to datetime index\\n    # Group using timegrouper and create new column for start period and stop period\\n    df = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\n    start_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\n    df[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\n    df = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\n    stop_time_group_by = df.groupby(pd.TimeGrouper(\\'{}Min\\'.format(period_minutes)),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\n    df[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n    # Create two sub dataframes, grouping on and aggregating start data and then stop data\\n    grouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\n    df_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\n    df_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\n    grouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\n    df_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\n    df_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n    # Combine these two dataframes and fill N/A values to 0\\n    df_combined = pd.concat([df_start, df_stop])\\n    df_combined = df_combined.fillna(0)\\n\\n    # Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n    # And reset the multi-level index so we have a normal DataFrame\\n    aggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n    # Let\\'s construct a pivot table\\n    pivoted = pd.pivot_table(\\n        aggregate_data,\\n        index=[\"period\"],\\n        columns=[\"station_id\"],\\n        aggfunc=np.sum,\\n        fill_value=0)\\n\\n    # Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\n    deeper_cols = pivoted.columns.get_level_values(1)\\n    top_level_cols = pivoted.columns.get_level_values(0)\\n\\n    # Flattening the columns\\n    resultant_cols = []    \\n    for i, station_id in enumerate(deeper_cols):\\n        if top_level_cols[i] == \"start_count\":\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n        else:\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\n    pivoted.columns = resultant_cols\\n    pivoted = pivoted.reset_index()\\n    print \"{} rows in the pivoted table\".format(len(pivoted))\\n    X = pivoted.copy()\\n    # Turn number of out in station TARGET_STATION_ID into 1s and 0s\\n    answer_series = (\\n        pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > threshhold_out).apply(int)\\n    X = X[:-1]\\n    y = answer_series[1:]\\n\\n    classifier = RandomForestClassifier(n_estimators=tree_count)\\n    scores = cross_validation.cross_val_score(\\n        classifier,\\n        X,\\n        y,\\n        cv=k_folds\\n    )\\n\\n    end = time.time()\\n    print \"Rows: {}, k={}\".format(row_limit, k_folds)\\n    print \"Mean accuracy: {}\".format(np.mean(scores))\\n    print \"Standard deviation: {}\".format(np.std(scores))\\n    print \"Took {}s\".format(end - start)', u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nstart = time.time()\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\n\\ndef analyze(row_limit, threshold_out=1, tree_count=10, period_minutes=5, k_folds=5):\\n    \"\"\"\\n    We can tune the following parameters:\\n    - number of rows we analyze\\n    - number of folds in our standard k-fold cross-validation\\n    - number of bicycles taken out in the period to be considered in the positive class\\n    - number of trees in our random forest\\n    - number of minutes in our period\\n    \"\"\"\\n    df = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=row_limit)\\n    # Convert to timestamps \\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\n    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n    # Convert int64index to datetime index\\n    # Group using timegrouper and create new column for start period and stop period\\n    df = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\n    start_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\n    df[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\n    df = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\n    stop_time_group_by = df.groupby(pd.TimeGrouper(\\'{}Min\\'.format(period_minutes)),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\n    df[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n    # Create two sub dataframes, grouping on and aggregating start data and then stop data\\n    grouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\n    df_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\n    df_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\n    grouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\n    df_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\n    df_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n    # Combine these two dataframes and fill N/A values to 0\\n    df_combined = pd.concat([df_start, df_stop])\\n    df_combined = df_combined.fillna(0)\\n\\n    # Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n    # And reset the multi-level index so we have a normal DataFrame\\n    aggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n    # Let\\'s construct a pivot table\\n    pivoted = pd.pivot_table(\\n        aggregate_data,\\n        index=[\"period\"],\\n        columns=[\"station_id\"],\\n        aggfunc=np.sum,\\n        fill_value=0)\\n\\n    # Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\n    deeper_cols = pivoted.columns.get_level_values(1)\\n    top_level_cols = pivoted.columns.get_level_values(0)\\n\\n    # Flattening the columns\\n    resultant_cols = []    \\n    for i, station_id in enumerate(deeper_cols):\\n        if top_level_cols[i] == \"start_count\":\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n        else:\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\n    pivoted.columns = resultant_cols\\n    pivoted = pivoted.reset_index()\\n    print \"{} rows in the pivoted table\".format(len(pivoted))\\n    X = pivoted.copy()\\n    # Turn number of out in station TARGET_STATION_ID into 1s and 0s\\n    answer_series = (\\n        pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > threshhold_out).apply(int)\\n    X = X[:-1]\\n    y = answer_series[1:]\\n\\n    classifier = RandomForestClassifier(n_estimators=tree_count)\\n    scores = cross_validation.cross_val_score(\\n        classifier,\\n        X,\\n        y,\\n        cv=k_folds\\n    )\\n\\n    end = time.time()\\n    print \"Rows: {}, k={}\".format(row_limit, k_folds)\\n    print \"Mean accuracy: {}\".format(np.mean(scores))\\n    print \"Standard deviation: {}\".format(np.std(scores))\\n    print \"Took {}s\".format(end - start)', u'for tc in [10, 20, 40]:\\n    analyze(10000, tree_count=tc)', u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nstart = time.time()\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\n\\ndef analyze(row_limit, threshold_out=1, tree_count=10, period_minutes=5, k_folds=5):\\n    \"\"\"\\n    We can tune the following parameters:\\n    - number of rows we analyze\\n    - number of folds in our standard k-fold cross-validation\\n    - number of bicycles taken out in the period to be considered in the positive class\\n    - number of trees in our random forest\\n    - number of minutes in our period\\n    \"\"\"\\n    df = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=row_limit)\\n    # Convert to timestamps \\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\n    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n    # Convert int64index to datetime index\\n    # Group using timegrouper and create new column for start period and stop period\\n    df = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\n    start_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\n    df[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\n    df = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\n    stop_time_group_by = df.groupby(pd.TimeGrouper(\\'{}Min\\'.format(period_minutes)),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\n    df[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n    # Create two sub dataframes, grouping on and aggregating start data and then stop data\\n    grouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\n    df_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\n    df_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\n    grouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\n    df_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\n    df_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n    # Combine these two dataframes and fill N/A values to 0\\n    df_combined = pd.concat([df_start, df_stop])\\n    df_combined = df_combined.fillna(0)\\n\\n    # Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n    # And reset the multi-level index so we have a normal DataFrame\\n    aggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n    # Let\\'s construct a pivot table\\n    pivoted = pd.pivot_table(\\n        aggregate_data,\\n        index=[\"period\"],\\n        columns=[\"station_id\"],\\n        aggfunc=np.sum,\\n        fill_value=0)\\n\\n    # Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\n    deeper_cols = pivoted.columns.get_level_values(1)\\n    top_level_cols = pivoted.columns.get_level_values(0)\\n\\n    # Flattening the columns\\n    resultant_cols = []    \\n    for i, station_id in enumerate(deeper_cols):\\n        if top_level_cols[i] == \"start_count\":\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n        else:\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\n    pivoted.columns = resultant_cols\\n    pivoted = pivoted.reset_index()\\n    print \"{} rows in the pivoted table\".format(len(pivoted))\\n    X = pivoted.copy()\\n    # Turn number of out in station TARGET_STATION_ID into 1s and 0s\\n    answer_series = (\\n        pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > threshold_out).apply(int)\\n    X = X[:-1]\\n    y = answer_series[1:]\\n\\n    classifier = RandomForestClassifier(n_estimators=tree_count)\\n    scores = cross_validation.cross_val_score(\\n        classifier,\\n        X,\\n        y,\\n        cv=k_folds\\n    )\\n\\n    end = time.time()\\n    print \"Rows: {}, k={}\".format(row_limit, k_folds)\\n    print \"Mean accuracy: {}\".format(np.mean(scores))\\n    print \"Standard deviation: {}\".format(np.std(scores))\\n    print \"Took {}s\".format(end - start)', u'for tc in [10, 20, 40]:\\n    print \"{} trees\".format(tc)\\n    analyze(10000, tree_count=tc)', u\"get_ipython().magic(u'pylab inline')\", u'from matplotlib import pyplot as plt', u'plt.plot([1, 2], [3, 4])', u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nstart = time.time()\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\n\\ndef analyze(row_limit, threshold_out=1, tree_count=10, period_minutes=5, k_folds=5):\\n    \"\"\"\\n    We can tune the following parameters:\\n    - number of rows we analyze\\n    - number of folds in our standard k-fold cross-validation\\n    - number of bicycles taken out in the period to be considered in the positive class\\n    - number of trees in our random forest\\n    - number of minutes in our period\\n    \"\"\"\\n    df = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=row_limit)\\n    # Convert to timestamps \\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\n    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n    # Convert int64index to datetime index\\n    # Group using timegrouper and create new column for start period and stop period\\n    df = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\n    start_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\n    df[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\n    df = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\n    stop_time_group_by = df.groupby(pd.TimeGrouper(\\'{}Min\\'.format(period_minutes)),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\n    df[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n    # Create two sub dataframes, grouping on and aggregating start data and then stop data\\n    grouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\n    df_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\n    df_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\n    grouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\n    df_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\n    df_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n    # Combine these two dataframes and fill N/A values to 0\\n    df_combined = pd.concat([df_start, df_stop])\\n    df_combined = df_combined.fillna(0)\\n\\n    # Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n    # And reset the multi-level index so we have a normal DataFrame\\n    aggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n    # Let\\'s construct a pivot table\\n    pivoted = pd.pivot_table(\\n        aggregate_data,\\n        index=[\"period\"],\\n        columns=[\"station_id\"],\\n        aggfunc=np.sum,\\n        fill_value=0)\\n\\n    # Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\n    deeper_cols = pivoted.columns.get_level_values(1)\\n    top_level_cols = pivoted.columns.get_level_values(0)\\n\\n    # Flattening the columns\\n    resultant_cols = []    \\n    for i, station_id in enumerate(deeper_cols):\\n        if top_level_cols[i] == \"start_count\":\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n        else:\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\n    pivoted.columns = resultant_cols\\n    pivoted = pivoted.reset_index()\\n    print \"{} rows in the pivoted table\".format(len(pivoted))\\n    X = pivoted.copy()\\n    # Turn number of out in station TARGET_STATION_ID into 1s and 0s\\n    answer_series = (\\n        pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > threshold_out).apply(int)\\n    X = X[:-1]\\n    y = answer_series[1:]\\n\\n    classifier = RandomForestClassifier(n_estimators=tree_count)\\n    scores = cross_validation.cross_val_score(\\n        classifier,\\n        X,\\n        y,\\n        cv=k_folds\\n    )\\n\\n    end = time.time()\\n    mean_accuracy = np.mean(scores)\\n    print \"Rows: {}, k={}\".format(row_limit, k_folds)\\n    print \"Mean accuracy: {}\".format(mean_accuracy)\\n    print \"Standard deviation: {}\".format(np.std(scores))\\n    print \"Took {}s\".format(end - start)\\n    return mean_accuracy', u'counts = [10, 20, 40]\\naccs = []\\nfor tc in counts:\\n    print \"{} trees\".format(tc)\\n    accs.append(analyze(10000, tree_count=tc))\\nplt.plot(counts, accs)', u'counts = [10, 20, 40, 100]\\naccs = []\\nfor tc in counts:\\n    print \"{} trees\".format(tc)\\n    accs.append(analyze(10000, tree_count=tc))\\n    print \"\\\\n\"\\nplt.plot(counts, accs)', u'thresholds = [1, 2, 3]\\nfor to in thresholds:\\n    accs.append(analyze(10000, tree_count=40, threshold_out=to))\\n    print \"\\\\n\"\\nplt.plot(thresholds, accs)', u'thresholds = [1, 2, 3]\\naccs = []\\nfor to in thresholds:\\n    accs.append(analyze(10000, tree_count=40, threshold_out=to))\\n    print \"\\\\n\"\\nplt.plot(thresholds, accs)', u'lengths = [2, 5, 10, 15]\\naccs = []\\nfor length in lengths:\\n    accs.append(analyze(50000, tree_count=40, threshold_out=1, period_minutes=length))\\n    print \"\\\\n\"\\nplt.plot(lengths, accs)', u'tree_counts = [40, 100, 200]\\naccs = []\\nfor tc in tree_counts:\\n    accs.append(analyze(50000, tree_count=tc, threshold_out=1, period_minutes=5))\\n    print \"\\\\n\"\\nplt.plot(lengths, tree_counts)', u'plt.plot(tree_counts, accs)', u'analyze(1000000, tree_count=200, threshold_out=1, period_minutes=5)', u'analyze(1200000, tree_count=500, threshold_out=1, period_minutes=5)', u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\n\\ndef analyze(row_limit, threshold_out=1, tree_count=10, period_minutes=5, k_folds=5):\\n    \"\"\"\\n    We can tune the following parameters:\\n    - number of rows we analyze\\n    - number of folds in our standard k-fold cross-validation\\n    - number of bicycles taken out in the period to be considered in the positive class\\n    - number of trees in our random forest\\n    - number of minutes in our period\\n    \"\"\"\\n    start = time.time()\\n    df = pd.read_csv(\"data/raw_data.csv\", usecols=COLUMNS, nrows=row_limit)\\n    # Convert to timestamps \\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\n    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n    # Convert int64index to datetime index\\n    # Group using timegrouper and create new column for start period and stop period\\n    df = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\n    start_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\n    df[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\n    df = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\n    stop_time_group_by = df.groupby(pd.TimeGrouper(\\'{}Min\\'.format(period_minutes)),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\n    df[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n    # Create two sub dataframes, grouping on and aggregating start data and then stop data\\n    grouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\n    df_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\n    df_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\n    grouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\n    df_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\n    df_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n    # Combine these two dataframes and fill N/A values to 0\\n    df_combined = pd.concat([df_start, df_stop])\\n    df_combined = df_combined.fillna(0)\\n\\n    # Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n    # And reset the multi-level index so we have a normal DataFrame\\n    aggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n    # Let\\'s construct a pivot table\\n    pivoted = pd.pivot_table(\\n        aggregate_data,\\n        index=[\"period\"],\\n        columns=[\"station_id\"],\\n        aggfunc=np.sum,\\n        fill_value=0)\\n\\n    # Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\n    deeper_cols = pivoted.columns.get_level_values(1)\\n    top_level_cols = pivoted.columns.get_level_values(0)\\n\\n    # Flattening the columns\\n    resultant_cols = []    \\n    for i, station_id in enumerate(deeper_cols):\\n        if top_level_cols[i] == \"start_count\":\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n        else:\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\n    pivoted.columns = resultant_cols\\n    pivoted = pivoted.reset_index()\\n    print \"{} rows in the pivoted table\".format(len(pivoted))\\n    X = pivoted.copy()\\n    # Turn number of out in station TARGET_STATION_ID into 1s and 0s\\n    answer_series = (\\n        pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > threshold_out).apply(int)\\n    X = X[:-1]\\n    y = answer_series[1:]\\n\\n    classifier = RandomForestClassifier(n_estimators=tree_count)\\n    scores = cross_validation.cross_val_score(\\n        classifier,\\n        X,\\n        y,\\n        cv=k_folds\\n    )\\n\\n    end = time.time()\\n    mean_accuracy = np.mean(scores)\\n    print \"Rows: {}, k={}\".format(row_limit, k_folds)\\n    print \"Mean accuracy: {}\".format(mean_accuracy)\\n    print \"Standard deviation: {}\".format(np.std(scores))\\n    print \"Took {}s\".format(end - start)\\n    return mean_accuracy', u'analyze(20000, tree_count=500, threshold_out=1, period_minutes=5)', u'analyze(1000000, tree_count=200, threshold_out=1, period_minutes=5)', u'import time\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\n\\nROW_LIMIT = 10000\\nCOLUMNS = [\"starttime\", \"stoptime\", \"start station id\", \"end station id\"]\\nTARGET_STATION_ID = \"529\"\\n\\n\\ndef analyze(row_limit, threshold_out=1, tree_count=10, period_minutes=5, k_folds=5):\\n    \"\"\"\\n    We can tune the following parameters:\\n    - number of rows we analyze\\n    - number of folds in our standard k-fold cross-validation\\n    - number of bicycles taken out in the period to be considered in the positive class\\n    - number of trees in our random forest\\n    - number of minutes in our period\\n    \"\"\"\\n    start = time.time()\\n    df = pd.read_csv(\"data/july_thru_sept.csv\", usecols=COLUMNS, nrows=row_limit)\\n    # Convert to timestamps \\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\n    df[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])\\n\\n    # Convert int64index to datetime index\\n    # Group using timegrouper and create new column for start period and stop period\\n    df = df.set_index(pd.DatetimeIndex(df[\\'starttime\\']))\\n    start_time_group_by = df.groupby(pd.TimeGrouper(\\'5Min\\'),as_index=False).apply(lambda x: x[\\'starttime\\'])\\n    df[\\'start_period\\'] = start_time_group_by.index.get_level_values(0)\\n\\n    df = df.set_index(pd.DatetimeIndex(df[\\'stoptime\\']))\\n    stop_time_group_by = df.groupby(pd.TimeGrouper(\\'{}Min\\'.format(period_minutes)),as_index=False).apply(lambda x: x[\\'stoptime\\'])\\n    df[\\'stop_period\\'] = stop_time_group_by.index.get_level_values(0)\\n\\n    # Create two sub dataframes, grouping on and aggregating start data and then stop data\\n    grouped_by = df.groupby([\\'start_period\\', \\'start station id\\'])\\n    df_start = pd.DataFrame({\\'started_count\\' : grouped_by.size()}).reset_index()\\n    df_start.columns = [\"period\", \"station_id\", \"start_count\"]\\n\\n    grouped_by = df.groupby([\\'stop_period\\', \\'end station id\\'])\\n    df_stop = pd.DataFrame({\\'stopped_count\\' : grouped_by.size()}).reset_index()\\n    df_stop.columns = [\"period\", \"station_id\", \"stop_count\"]\\n\\n    # Combine these two dataframes and fill N/A values to 0\\n    df_combined = pd.concat([df_start, df_stop])\\n    df_combined = df_combined.fillna(0)\\n\\n    # Let\\'s group on period and station_id and then sum up along start_count and stop_count\\n    # And reset the multi-level index so we have a normal DataFrame\\n    aggregate_data = df_combined.groupby([\\'period\\', \\'station_id\\']).sum().reset_index()\\n\\n    # Let\\'s construct a pivot table\\n    pivoted = pd.pivot_table(\\n        aggregate_data,\\n        index=[\"period\"],\\n        columns=[\"station_id\"],\\n        aggfunc=np.sum,\\n        fill_value=0)\\n\\n    # Go from multilevel index of start > station_id and stop > station_id to {station_id}_start and {station_id}_stop\\n    deeper_cols = pivoted.columns.get_level_values(1)\\n    top_level_cols = pivoted.columns.get_level_values(0)\\n\\n    # Flattening the columns\\n    resultant_cols = []    \\n    for i, station_id in enumerate(deeper_cols):\\n        if top_level_cols[i] == \"start_count\":\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"out\"))\\n        else:\\n            resultant_cols.append(\"{}_{}\".format(station_id, \"in\"))\\n    pivoted.columns = resultant_cols\\n    pivoted = pivoted.reset_index()\\n    print \"{} rows in the pivoted table\".format(len(pivoted))\\n    X = pivoted.copy()\\n    # Turn number of out in station TARGET_STATION_ID into 1s and 0s\\n    answer_series = (\\n        pivoted[\"{}_out\".format(TARGET_STATION_ID) ] > threshold_out).apply(int)\\n    X = X[:-1]\\n    y = answer_series[1:]\\n\\n    classifier = RandomForestClassifier(n_estimators=tree_count)\\n    scores = cross_validation.cross_val_score(\\n        classifier,\\n        X,\\n        y,\\n        cv=k_folds\\n    )\\n\\n    end = time.time()\\n    mean_accuracy = np.mean(scores)\\n    print \"Rows: {}, k={}\".format(row_limit, k_folds)\\n    print \"Mean accuracy: {}\".format(mean_accuracy)\\n    print \"Standard deviation: {}\".format(np.std(scores))\\n    print \"Took {}s\".format(end - start)\\n    return mean_accuracy', u'analyze(500000000, tree_count=500, threshold_out=1, period_minutes=5)', u'df', u'len(df)', u'df = pd.read_csv(\"data/july_thru_sept.csv\", usecols=COLUMNS)', u'def.size', u'df.dize', u'df.size()', u'df.size', u'df.isnull(df[\"starttime\"])', u'df[\"starttime\"].isnull()', u'df[\"starttime\"].isnull() == True', u'df[df[\"starttime\"].isnull() == True]', u'df[df[\"stoptime\"].isnull() == True]', u'df = pd.read_csv(\"data/july_thru_sept.csv\", usecols=COLUMNS)\\n# Convert to timestamps \\ndf[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\ndf[\"stoptime\"] = pd.to_datetime(df[\"stoptime\"])', u'df = pd.read_csv(\"data/july_thru_sept.csv\", usecols=COLUMNS)\\n# Convert to timestamps \\ntry:\\n    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\\nexcept Exception as e:\\n    import pdb; pdb.set_trace()'], 'RankWarning': <class 'numpy.lib.polynomial.RankWarning'>, 'ascontiguousarray': <function ascontiguousarray at 0x104d40aa0>, 'summer': <function summer at 0x109d49230>, 'hexbin': <function hexbin at 0x109d467d0>, 'Arrow': <class 'matplotlib.patches.Arrow'>, 'less': <ufunc 'less'>, 'ERR_CALL': 3, 'nan': nan, 'half': <type 'numpy.float16'>, 'NAN': nan, 'absolute_import': _Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0), 16384), 'typeDict': {0: <type 'numpy.bool_'>, 1: <type 'numpy.int8'>, 2: <type 'numpy.uint8'>, 3: <type 'numpy.int16'>, 4: <type 'numpy.uint16'>, 5: <type 'numpy.int32'>, 6: <type 'numpy.uint32'>, 7: <type 'numpy.int64'>, 8: <type 'numpy.uint64'>, 9: <type 'numpy.int64'>, 10: <type 'numpy.uint64'>, 11: <type 'numpy.float32'>, 12: <type 'numpy.float64'>, 13: <type 'numpy.float128'>, 14: <type 'numpy.complex64'>, 15: <type 'numpy.complex128'>, 16: <type 'numpy.complex256'>, 17: <type 'numpy.object_'>, 18: <type 'numpy.string_'>, 19: <type 'numpy.unicode_'>, 20: <type 'numpy.void'>, 21: <type 'numpy.datetime64'>, 'unicode': <type 'numpy.unicode_'>, 23: <type 'numpy.float16'>, 'cfloat': <type 'numpy.complex128'>, 'longfloat': <type 'numpy.float128'>, 'Int32': <type 'numpy.int32'>, 'Complex64': <type 'numpy.complex128'>, 'unicode_': <type 'numpy.unicode_'>, 'complex': <type 'numpy.complex128'>, 'timedelta64': <type 'numpy.timedelta64'>, 'uint16': <type 'numpy.uint16'>, 'c16': <type 'numpy.complex128'>, 'float32': <type 'numpy.float32'>, 'complex256': <type 'numpy.complex256'>, 'D': <type 'numpy.complex128'>, 'H': <type 'numpy.uint16'>, 'void': <type 'numpy.void'>, 'unicode0': <type 'numpy.unicode_'>, 'L': <type 'numpy.uint64'>, 'P': <type 'numpy.uint64'>, 'half': <type 'numpy.float16'>, 'void0': <type 'numpy.void'>, 'd': <type 'numpy.float64'>, 'h': <type 'numpy.int16'>, 'l': <type 'numpy.int64'>, 'p': <type 'numpy.int64'>, 'c32': <type 'numpy.complex256'>, 22: <type 'numpy.timedelta64'>, 'Timedelta64': <type 'numpy.timedelta64'>, 'object0': <type 'numpy.object_'>, 'b1': <type 'numpy.bool_'>, 'float128': <type 'numpy.float128'>, 'M8': <type 'numpy.datetime64'>, 'String0': <type 'numpy.string_'>, 'float16': <type 'numpy.float16'>, 'ulonglong': <type 'numpy.uint64'>, 'i1': <type 'numpy.int8'>, 'uint32': <type 'numpy.uint32'>, '?': <type 'numpy.bool_'>, 'Void0': <type 'numpy.void'>, 'complex64': <type 'numpy.complex64'>, 'G': <type 'numpy.complex256'>, 'O': <type 'numpy.object_'>, 'UInt8': <type 'numpy.uint8'>, 'S': <type 'numpy.string_'>, 'byte': <type 'numpy.int8'>, 'UInt64': <type 'numpy.uint64'>, 'g': <type 'numpy.float128'>, 'float64': <type 'numpy.float64'>, 'ushort': <type 'numpy.uint16'>, 'float_': <type 'numpy.float64'>, 'uint': <type 'numpy.uint64'>, 'object_': <type 'numpy.object_'>, 'Float16': <type 'numpy.float16'>, 'complex_': <type 'numpy.complex128'>, 'Unicode0': <type 'numpy.unicode_'>, 'uintp': <type 'numpy.uint64'>, 'intc': <type 'numpy.int32'>, 'csingle': <type 'numpy.complex64'>, 'datetime64': <type 'numpy.datetime64'>, 'float': <type 'numpy.float64'>, 'bool8': <type 'numpy.bool_'>, 'Bool': <type 'numpy.bool_'>, 'intp': <type 'numpy.int64'>, 'uintc': <type 'numpy.uint32'>, 'bytes_': <type 'numpy.string_'>, 'u8': <type 'numpy.uint64'>, 'u4': <type 'numpy.uint32'>, 'int_': <type 'numpy.int64'>, 'cdouble': <type 'numpy.complex128'>, 'u1': <type 'numpy.uint8'>, 'complex128': <type 'numpy.complex128'>, 'u2': <type 'numpy.uint16'>, 'f8': <type 'numpy.float64'>, 'Datetime64': <type 'numpy.datetime64'>, 'ubyte': <type 'numpy.uint8'>, 'm8': <type 'numpy.timedelta64'>, 'B': <type 'numpy.uint8'>, 'uint0': <type 'numpy.uint64'>, 'F': <type 'numpy.complex64'>, 'bool_': <type 'numpy.bool_'>, 'uint8': <type 'numpy.uint8'>, 'c8': <type 'numpy.complex64'>, 'Int64': <type 'numpy.int64'>, 'Int8': <type 'numpy.int8'>, 'Complex32': <type 'numpy.complex64'>, 'V': <type 'numpy.void'>, 'int8': <type 'numpy.int8'>, 'uint64': <type 'numpy.uint64'>, 'b': <type 'numpy.int8'>, 'f': <type 'numpy.float32'>, 'double': <type 'numpy.float64'>, 'UInt32': <type 'numpy.uint32'>, 'clongdouble': <type 'numpy.complex256'>, 'str': <type 'numpy.string_'>, 'f16': <type 'numpy.float128'>, 'f2': <type 'numpy.float16'>, 'f4': <type 'numpy.float32'>, 'int32': <type 'numpy.int32'>, 'int': <type 'numpy.int64'>, 'longdouble': <type 'numpy.float128'>, 'Complex128': <type 'numpy.complex256'>, 'single': <type 'numpy.float32'>, 'string': <type 'numpy.string_'>, 'q': <type 'numpy.int64'>, 'Int16': <type 'numpy.int16'>, 'Float64': <type 'numpy.float64'>, 'longcomplex': <type 'numpy.complex256'>, 'UInt16': <type 'numpy.uint16'>, 'bool': <type 'numpy.bool_'>, 'Float32': <type 'numpy.float32'>, 'string0': <type 'numpy.string_'>, 'longlong': <type 'numpy.int64'>, 'i8': <type 'numpy.int64'>, 'int16': <type 'numpy.int16'>, 'str_': <type 'numpy.string_'>, 'I': <type 'numpy.uint32'>, 'object': <type 'numpy.object_'>, 'M': <type 'numpy.datetime64'>, 'i4': <type 'numpy.int32'>, 'singlecomplex': <type 'numpy.complex64'>, 'Q': <type 'numpy.uint64'>, 'string_': <type 'numpy.string_'>, 'U': <type 'numpy.unicode_'>, 'a': <type 'numpy.string_'>, 'short': <type 'numpy.int16'>, 'e': <type 'numpy.float16'>, 'i': <type 'numpy.int32'>, 'clongfloat': <type 'numpy.complex256'>, 'm': <type 'numpy.timedelta64'>, 'Object0': <type 'numpy.object_'>, 'int64': <type 'numpy.int64'>, 'Float128': <type 'numpy.float128'>, 'i2': <type 'numpy.int16'>, 'int0': <type 'numpy.int64'>}, 'Annotation': <class 'matplotlib.text.Annotation'>, 'polar': <function polar at 0x109d20b18>, 'isscalar': <function isscalar at 0x104d5d578>, 'bench': <bound method NoseTester.test of <numpy.testing.nosetester.NoseTester object at 0x104e2a650>>, 'add': <ufunc 'add'>, 'ufunc': <type 'numpy.ufunc'>, 'multinomial': <built-in method multinomial of mtrand.RandomState object at 0x104ee18d0>, 'ravel': <function ravel at 0x104d5a848>, 'real': <function real at 0x104dcd8c0>, 'int32': <type 'numpy.int32'>, 'tril_indices': <function tril_indices at 0x104de9b90>, 'around': <function around at 0x104d5c320>, 'psd': <function psd at 0x109d46de8>, 'test': <bound method NoseTester.test of <numpy.testing.nosetester.NoseTester object at 0x104e2a610>>, 'grid': <function grid at 0x109d477d0>, 'get_state': <built-in method get_state of mtrand.RandomState object at 0x104ee18d0>, 'stop_time_group_by': 0    2015-09-01 00:02:45   2015-09-01 00:02:45\n",
      "     2015-09-01 00:02:52   2015-09-01 00:02:52\n",
      "     2015-09-01 00:03:44   2015-09-01 00:03:44\n",
      "     2015-09-01 00:04:15   2015-09-01 00:04:15\n",
      "     2015-09-01 00:04:48   2015-09-01 00:04:48\n",
      "1    2015-09-01 00:05:28   2015-09-01 00:05:28\n",
      "     2015-09-01 00:06:08   2015-09-01 00:06:08\n",
      "     2015-09-01 00:06:46   2015-09-01 00:06:46\n",
      "     2015-09-01 00:07:15   2015-09-01 00:07:15\n",
      "     2015-09-01 00:08:56   2015-09-01 00:08:56\n",
      "     2015-09-01 00:08:56   2015-09-01 00:08:56\n",
      "     2015-09-01 00:09:22   2015-09-01 00:09:22\n",
      "     2015-09-01 00:09:41   2015-09-01 00:09:41\n",
      "     2015-09-01 00:09:49   2015-09-01 00:09:49\n",
      "     2015-09-01 00:09:56   2015-09-01 00:09:56\n",
      "2    2015-09-01 00:10:17   2015-09-01 00:10:17\n",
      "     2015-09-01 00:11:07   2015-09-01 00:11:07\n",
      "     2015-09-01 00:11:08   2015-09-01 00:11:08\n",
      "     2015-09-01 00:11:55   2015-09-01 00:11:55\n",
      "     2015-09-01 00:12:41   2015-09-01 00:12:41\n",
      "     2015-09-01 00:12:53   2015-09-01 00:12:53\n",
      "     2015-09-01 00:12:59   2015-09-01 00:12:59\n",
      "     2015-09-01 00:13:02   2015-09-01 00:13:02\n",
      "     2015-09-01 00:13:03   2015-09-01 00:13:03\n",
      "     2015-09-01 00:13:53   2015-09-01 00:13:53\n",
      "     2015-09-01 00:13:58   2015-09-01 00:13:58\n",
      "     2015-09-01 00:14:00   2015-09-01 00:14:00\n",
      "     2015-09-01 00:14:02   2015-09-01 00:14:02\n",
      "     2015-09-01 00:14:59   2015-09-01 00:14:59\n",
      "3    2015-09-01 00:15:08   2015-09-01 00:15:08\n",
      "                                   ...        \n",
      "120  2015-09-01 10:00:26   2015-09-01 10:00:26\n",
      "     2015-09-01 10:00:35   2015-09-01 10:00:35\n",
      "     2015-09-01 10:01:10   2015-09-01 10:01:10\n",
      "     2015-09-01 10:01:27   2015-09-01 10:01:27\n",
      "     2015-09-01 10:03:03   2015-09-01 10:03:03\n",
      "123  2015-09-01 10:16:46   2015-09-01 10:16:46\n",
      "125  2015-09-01 10:25:41   2015-09-01 10:25:41\n",
      "     2015-09-01 10:26:21   2015-09-01 10:26:21\n",
      "126  2015-09-01 10:32:49   2015-09-01 10:32:49\n",
      "     2015-09-01 10:34:31   2015-09-01 10:34:31\n",
      "132  2015-09-01 11:04:30   2015-09-01 11:04:30\n",
      "133  2015-09-01 11:05:47   2015-09-01 11:05:47\n",
      "136  2015-09-01 11:21:41   2015-09-01 11:21:41\n",
      "     2015-09-01 11:21:44   2015-09-01 11:21:44\n",
      "137  2015-09-01 11:26:04   2015-09-01 11:26:04\n",
      "141  2015-09-01 11:48:05   2015-09-01 11:48:05\n",
      "147  2015-09-01 12:18:13   2015-09-01 12:18:13\n",
      "     2015-09-01 12:18:20   2015-09-01 12:18:20\n",
      "149  2015-09-01 12:27:20   2015-09-01 12:27:20\n",
      "151  2015-09-01 12:37:34   2015-09-01 12:37:34\n",
      "156  2015-09-01 13:01:28   2015-09-01 13:01:28\n",
      "203  2015-09-01 16:59:07   2015-09-01 16:59:07\n",
      "210  2015-09-01 17:33:36   2015-09-01 17:33:36\n",
      "211  2015-09-01 17:37:03   2015-09-01 17:37:03\n",
      "212  2015-09-01 17:40:58   2015-09-01 17:40:58\n",
      "222  2015-09-01 18:31:07   2015-09-01 18:31:07\n",
      "226  2015-09-01 18:53:49   2015-09-01 18:53:49\n",
      "     2015-09-01 18:54:38   2015-09-01 18:54:38\n",
      "228  2015-09-01 19:04:16   2015-09-01 19:04:16\n",
      "417  2015-09-02 10:46:30   2015-09-02 10:46:30\n",
      "Name: stoptime, dtype: datetime64[ns], 'mod': <ufunc 'remainder'>, '_sh': <module 'IPython.core.shadowns' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/IPython/core/shadowns.pyc'>, 'getbufsize': <function getbufsize at 0x104d5db90>, 'isfortran': <function isfortran at 0x104d40938>, 'get_printoptions': <function get_printoptions at 0x104d5c6e0>, 'asarray_chkfinite': <function asarray_chkfinite at 0x104e00140>, 'pcolormesh': <function pcolormesh at 0x109d46b90>, 'findobj': <function findobj at 0x109d1c848>, 'in1d': <function in1d at 0x104e30848>, 'NullLocator': <class 'matplotlib.ticker.NullLocator'>, 'rrule': <class 'dateutil.rrule.rrule'>, 'diagflat': <function diagflat at 0x104de9848>, 'float128': <type 'numpy.float128'>, 'iinfo': <class 'numpy.core.getlimits.iinfo'>, 'kaiser': <function kaiser at 0x104e00f50>, 'inside_poly': <function inside_poly at 0x10a99f8c0>, 'is_closed_polygon': <function is_closed_polygon at 0x10a99fc08>, 'polysub': <function polysub at 0x104e2c758>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x103af2550>, 'Rectangle': <class 'matplotlib.patches.Rectangle'>, 'fromfile': <built-in function fromfile>, 'diag_indices': <function diag_indices at 0x104e0ec08>, 'nanmax': <function nanmax at 0x104e131b8>, 'LinearLocator': <class 'matplotlib.ticker.LinearLocator'>, 'tensorinv': <function tensorinv at 0x104e23320>, 'seterrobj': <built-in function seterrobj>, 'power': <ufunc 'power'>, 'zipf': <built-in method zipf of mtrand.RandomState object at 0x104ee18d0>, 'LogLocator': <class 'matplotlib.ticker.LogLocator'>, 'FPE_DIVIDEBYZERO': 1, '__name__': '__main__', '_': Empty DataFrame\n",
      "Columns: [starttime, stoptime, start station id, end station id]\n",
      "Index: [], 'mx2num': <function mx2num at 0x1060458c0>, 'nanmean': <function nanmean at 0x104e13410>, 'iscomplex': <function iscomplex at 0x104dcded8>, 'multivariate_normal': <built-in method multivariate_normal of mtrand.RandomState object at 0x104ee18d0>, '_38': 14217684, '_33': 10000, '_18': [<matplotlib.lines.Line2D object at 0x109e43610>], 'ones_like': <function ones_like at 0x104d40de8>, 'ScalarFormatter': <class 'matplotlib.ticker.ScalarFormatter'>, 'is_busday': <built-in function is_busday>, 'CLIP': 0, 'ROW_LIMIT': 10000, '__builtin__': <module '__builtin__' (built-in)>, 'annotate': <function annotate at 0x109d479b0>, 'ndenumerate': <class 'numpy.lib.index_tricks.ndenumerate'>, 'standard_cauchy': <built-in method standard_cauchy of mtrand.RandomState object at 0x104ee18d0>, 'unpackbits': <built-in function unpackbits>, 'Infinity': inf, 'log': <ufunc 'log'>, 'complex128': <type 'numpy.complex128'>, 'tick_params': <function tick_params at 0x109d47b18>, 'start': 1447098560.916639, 'broadcast_arrays': <function broadcast_arrays at 0x104e0e0c8>, 'inner': <built-in function inner>, 'var': <function var at 0x104d5c500>, 'slopes': <function slopes at 0x10a99f7d0>, 'log10': <ufunc 'log10'>, 'unwrap': <function unwrap at 0x104e00500>, 'triangular': <built-in method triangular of mtrand.RandomState object at 0x104ee18d0>, 'histogram': <function histogram at 0x104de9de8>, 'movavg': <function movavg at 0x1081d09b0>, 'squeeze': <function squeeze at 0x104d5a6e0>, 'multi_dot': <function multi_dot at 0x104e2c2a8>, 'argmin': <function argmin at 0x104d5a578>, 'fignum_exists': <function has_fignum at 0x112f71050>, 'rec_append_fields': <function rec_append_fields at 0x10a99c500>, 'deprecate_with_doc': <function <lambda> at 0x104df9c08>, 'record': <class 'numpy.record'>, 'isrealobj': <function isrealobj at 0x104dcdcf8>, 'log1p': <ufunc 'log1p'>, 'display': <function display at 0x10300bb90>, 'setxor1d': <function setxor1d at 0x104e307d0>, 'inv': <function inv at 0x104e232a8>, 'ediff1d': <function ediff1d at 0x104e30668>, 'pie': <function pie at 0x109d46c80>, 'isposinf': <function isposinf at 0x104dd3050>, 'set_cmap': <function set_cmap at 0x109d20938>, 'hsplit': <function hsplit at 0x104e13de8>, 'ScalarType': (<type 'int'>, <type 'float'>, <type 'complex'>, <type 'long'>, <type 'bool'>, <type 'str'>, <type 'unicode'>, <type 'buffer'>, <type 'numpy.uint8'>, <type 'numpy.int8'>, <type 'numpy.object_'>, <type 'numpy.complex64'>, <type 'numpy.float32'>, <type 'numpy.uint16'>, <type 'numpy.int16'>, <type 'numpy.bool_'>, <type 'numpy.complex128'>, <type 'numpy.float64'>, <type 'numpy.uint32'>, <type 'numpy.int32'>, <type 'numpy.string_'>, <type 'numpy.complex256'>, <type 'numpy.float128'>, <type 'numpy.uint64'>, <type 'numpy.int64'>, <type 'numpy.unicode_'>, <type 'numpy.datetime64'>, <type 'numpy.uint64'>, <type 'numpy.int64'>, <type 'numpy.void'>, <type 'numpy.timedelta64'>, <type 'numpy.float16'>), 'noncentral_f': <built-in method noncentral_f of mtrand.RandomState object at 0x104ee18d0>, 'inf': inf, 'fill': <function fill at 0x109d46668>, 'polyadd': <function polyadd at 0x104e2c6e0>, 'emath': <module 'numpy.lib.scimath' from '/Users/suneel0101/anaconda/envs/citi/lib/python2.7/site-packages/numpy/lib/scimath.pyc'>, 'arctan': <ufunc 'arctan'>, 'Slider': <class 'matplotlib.widgets.Slider'>, 'prism': <function prism at 0x109d49140>, 'xscale': <function xscale at 0x109d20230>, 'string0': <type 'numpy.string_'>, 'vsplit': <function vsplit at 0x104e13e60>, 'real_if_close': <function real_if_close at 0x104dcdb18>, 'repeat': <function repeat at 0x104d5a140>, 'ALLOW_THREADS': 1, 'errorbar': <function errorbar at 0x109d46578>, 'string_': <type 'numpy.string_'>, 'isinf': <ufunc 'isinf'>, 'ndarray': <type 'numpy.ndarray'>, 'clongfloat': <type 'numpy.complex256'>, 'gradient': <function gradient at 0x104e00320>, 'eigh': <function eigh at 0x104e15ed8>, 'FixedLocator': <class 'matplotlib.ticker.FixedLocator'>, 'tensorsolve': <function tensorsolve at 0x104e23410>}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/july_thru_sept.csv\", usecols=COLUMNS)\n",
    "# Convert to timestamps \n",
    "try:\n",
    "    df[\"starttime\"] = pd.to_datetime(df[\"starttime\"])\n",
    "except Exception as e:\n",
    "    import pdb; pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, y in enumerate(df[\"starttime\"]):\n",
    "    print i\n",
    "    try:\n",
    "        pd.to_datetime(y)\n",
    "    except Exception as e:\n",
    "        import pdb; pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
